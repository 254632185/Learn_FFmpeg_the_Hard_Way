## Video Filters

##### addroi 视频滤镜
- 用于在视频帧中标记感兴趣的区域。帧数据将保持不变，但是附加了包含感兴趣区域的元数据，这些区域可以影响后续编码的行为。可以通过多次应用该滤镜来标记多个区域。
- 参数如下：
    - x：感兴趣区域距离帧左边缘的像素距离。
    - y：感兴趣区域距离帧上边缘的像素距离。
    - w：感兴趣区域的宽度（以像素为单位）。
    - h：感兴趣区域的高度（以像素为单位）。
    - 参数x、y、w和h都可以是表达式，并且可以包含以下变量：
        - iw：输入帧的宽度。
        - ih：输入帧的高度。
        - qoffset：在区域内应用的量化偏移。qoffset 必须是范围在 -1 到 +1 的实数值。值为零表示不改变质量。负值表示要求更好的质量（较少的量化），而正值表示要求较差的质量（更大的量化）。
    - clear：如果设置为true，在添加新的感兴趣区域之前，删除帧上标记的任何有感兴趣区域。
- 示例：
    - 将帧的四分之一标记为感兴趣区域：  
    ```ffmpeg -i input.mp4 -c:v libx264 -vf "addroi=iw/4:ih/4:iw/2:ih/2:-1/10" output.mp4```
    - 将帧左边缘的宽度为100像素的区域标记为非常不感兴趣的区域（编码质量远低于帧的其余部分）：  
    ```ffmpeg -i input.mp4 -c:v libx264 -vf "addroi=0:0:100:ih:+1/5" output.mp4```

##### alphaextract 视频滤镜
- 用于从输入视频中提取alpha（透明度）通道，并将其作为灰度视频输出。它将输入视频的每一帧的alpha通道提取出来，生成一个灰度视频，其中每个像素的灰度值表示相应像素的透明度。
- 这个滤镜一般处理带有透明度信息的视频时较为有用。它可以将视频中的透明度信息单独提取出来，以便进行后续处理或与其他视频进行合成。特别是与alphamerge滤镜结合使用时，可以将提取的alpha通道与另一个视频合并，以实现透明度混合效果。需要注意的是，这个滤镜对视频是有要求的。
- 示例：  
```ffmpeg -i input.mp4 -vf "alphaextract" output.mp4```
- 想象有一个动画视频，其中有一个透明的火焰动画。通过应用alphaextract滤镜，可以将视频中的透明度信息提取出来，并生成一个新的灰度视频，其中像素的灰度值表示相应像素的透明度。

##### alphamerge 视频滤镜
- 用于将第二个输入的灰度值作为alpha通道添加到主要输入中，或者用第二个输入的灰度值替换主要输入的alpha通道。它主要用于与alphaextract滤镜一起使用，以在不支持alpha通道的格式中传输或存储具有透明度的帧序列。
- 例如，如果你有一个普通的YUV编码视频和一个使用的alphaextract创建的分离的视频，它可以使用以下命令将它们合并为完整的帧：  
```movie=in_alpha.mkv [alpha]; [in][alpha] alphamerge [out]```  
上述命令中，in_alpha.mkv 是包含透明度信息的第二个输入视频文件。首先，使用 movie 滤镜将第二个输入视频读取为 [alpha] 流。然后，通过 [in][alpha] alphamerge [out]，将主要输入视频 [in] 和 [alpha] 流合并，生成包含完整透明度的输出视频 [out]。这样，你就可以将具有透明度信息的视频与普通视频进行合并，生成一个支持透明度的输出视频。
- 下面是一个示例：  
```ffmpeg -i color_video.mp4 -i alpha_video.mp4 -filter_complex "[0:v][1:v]alphamerge" output_video.mp4```
- 可以这样理解，假设你有两个视频片段：一个是一个小猫在绿色背景下玩耍的彩色视频，另一个是仅有包含小猫轮廓的黑白视频。用这个滤镜可以获得一个具有透明背景的小猫视频。

##### amplify 视频滤镜
- 用于放大当前像素与相邻帧中相同像素位置的像素之间的差异。
- 假设你正在观看一个电视节目，而电视节目是以每秒30帧的速度播放的。现在你正在观看的画面中有一个运动的物体，它的像素在连续的几帧中发生了一些微小的变化。该滤波器可以帮助你放大这些微小的变化，以使它们更加明显和突出。
- 该滤波器接受以下选项：
    - radius：设置帧半径。默认值为2。允许的范围是1到63。例如，半径为3将计算7帧的平均值。
    - factor：设置放大因子。默认值为2。允许的范围是0到65535。
    - threshold：设置差异放大的阈值。任何大于或等于该值的差异都不会改变源像素。默认值为10。允许的范围是0到65535。
    - tolerance：设置差异放大的容差。任何低于该值的差异都不会改变源像素。默认值为0。允许的范围是0到65535。
    - low：设置更改源像素的下限。默认值为65535。允许的范围是0到65535。该选项控制可以降低源像素值的最大可能值。
    - high：设置更改源像素的上限。默认值为65535。允许的范围是0到65535。该选项控制可以增加源像素值的最大可能值。
    - planes：设置要过滤的平面。默认值为全部。允许的范围是0到15。
- 示例：  
```ffmpeg -i input.mp4 -vf "amplify=radius=3:factor=2:threshold=10:tolerance=0:low=65535:high=65535:planes=all" output.mp4```

##### backgroundkey 滤波器
- 该滤波器可以将静态背景转换为透明。
- 该滤波器接受以下选项：
    - threshold：场景变化检测的阈值。
    - similarity：与背景的相似度百分比。
    - blend：设置不相似像素的混合量。
- 这些选项允许你调整滤波器的行为，以便检测场景变化并将背景转换为透明。阈值控制何时触发场景变化检测，相似度百分比确定像素与背景的相似程度，混合量控制不相似像素的透明度混合。
- 使用backgroundkey滤波器可以将一个视频中固定背景去除，并创建透明效果
- 示例：
```ffmpeg -i input.mp4 -vf "backgroundkey=threshold=0.1:similarity=0.9:blend=0.2" output.mp4```

##### bilateral 滤波器
- 一种应用双边滤波算法的图像处理滤波器，它在进行空间平滑的同时保留图像边缘。具体来说，"bilateral"滤波器使用高斯函数来计算空间权重和范围权重，并将它们结合起来对图像进行滤波。它的目标是在减少噪声的同时保持图像的边缘清晰度，避免边缘模糊。
- "bilateral"滤波器在图像处理中常用于去除噪声、平滑图像、边缘保留、纹理增强等应用。它可以改善图像质量并提高视觉效果。
- "bilateral"滤波器接受以下选项：
    - sigmaS：设置用于计算空间权重的高斯函数的标准差（sigma）。允许的范围是0到512，默认值为0.1。较大的sigmaS值会导致更大的平滑效果。
    - sigmaR：设置用于计算范围权重的高斯函数的标准差（sigma）。允许的范围是0到1，默认值为0.1。较小的sigmaR值会导致更强的边缘保留效果。
    - planes：设置要过滤的图像平面。默认值是仅过滤第一个平面。
- 示例：
```ffmpeg -i input.mp4 -vf "bilateral=sigmaS=10:sigmaR=0.1" output.mp4```

##### bitplanenoise 滤波器
- 是一个在图像中显示和测量比特平面噪声的FFmpeg滤波器。比特平面噪声是指图像中每个像素的特定比特位上的噪声。
- 该滤波器具有以下选项：
    - bitplane：设置要分析的比特平面。默认值为1，表示分析最低有效位（LSB）。
    - filter：可选择是否从上述设置的比特平面中滤除噪声像素。默认值为禁用，即不进行滤波处理。
- 示例：
```ffmpeg -i input.jpg -vf "bitplanenoise=bitplane=1:filter=enabled" output.jpg```

##### blackdetect 滤波器
- 用于检测视频中几乎完全黑色的部分。它可以用于检测章节转换、广告或无效录制等情况。
- 该滤波器接受以下选项：
    - black_min_duration, d：设置检测到的最小黑色持续时间，单位为秒。必须是非负浮点数。默认值为2.0。
    - picture_black_ratio_th, pic_th：设置被视为“黑色”的图片的阈值。它表示以下比率的最小值： 
     ```nb_black_pixels / nb_pixels```  
    其中，nb_black_pixels是黑色像素的数量，nb_pixels是总像素数。默认值为0.98。
    - pixel_black_th, pix_th：设置被视为“黑色”的像素的阈值。  
    阈值表示像素的最大亮度值，用于判断像素是否为“黑色”。提供的值会根据以下公式进行缩放：  
    ```absolute_threshold = luma_minimum_value + pixel_black_th * luma_range_size```  
    luma_range_size和luma_minimum_value取决于输入视频的格式，对于YUV全范围格式，范围是[0-255]，对于YUV非全范围格式，范围是[16-235]。默认值为0.10。
- 示例：
```ffmpeg -i input.mp4 -vf "blackdetect=d=2:pix_th=0.00" -f null -```

##### blackframe 滤波器
- 用于检测视频中几乎完全黑色的帧。它可以用于检测章节转换或广告等情况。滤波器的输入行包括检测到的帧号、黑色比例、文件中的位置（如果已知）或-1以及时间戳（以秒为单位）。
- 该滤波器接受以下参数：
    - amount：必须低于阈值的像素的百分比，默认为98。
    - threshold，thresh：被视为黑色的像素的阈值，默认为32。
- 示例：假设你有一个视频文件，你想要检测其中黑色的帧，即几乎完全黑色的帧。  
```ffmpeg -i input.mp4 -vf "blackframe=amount=95:threshold=20" -f null -```

##### blend 滤波器
- 用于将两个视频帧混合在一起。
- 该滤波器接受两个输入流，并输出一个流，其中第一个输入是"顶部"层，第二个输入是"底部"层。默认情况下，输出会在最长的输入结束时终止。
- 该滤波器还支持多个选项，用于设置混合模式、混合不透明度和混合表达式等。下面是一些常用的选项：
    - c0_mode、c1_mode、c2_mode、c3_mode、all_mode：设置特定像素分量或所有像素分量（all_mode）的混合模式。默认值为normal。
    - c0_opacity、c1_opacity、c2_opacity、c3_opacity、all_opacity：在像素分量混合模式下，设置特定像素分量或所有像素分量的混合不透明度。
    - c0_expr、c1_expr、c2_expr、c3_expr、all_expr：为特定像素分量或所有像素分量设置混合表达式。表达式可以使用各种变量，如当前帧的序号、坐标、时间戳以及顶部和底部层的像素分量值等。
- 示例：假设你有两个视频，一个是上层视频（top.mp4），一个是下层视频（bottom.mp4），你想要创建一个过渡效果，让上层视频逐渐淡入并覆盖下层视频。这个效果是2秒。  
```ffmpeg -i top.mp4 -i bottom.mp4 -filter_complex "[0:v]format=yuva420p,fade=t=in:st=0:d=2:alpha=1[top];[1:v]format=yuva420p,fade=t=out:st=2:d=2:alpha=1[bottom];[bottom][top]overlay=format=yuv420[out]" -map "[out]" output.mp4```
- 示例：这个视频是10秒混合。  
```ffmpeg -i top.mp4 -i bottom.mp4 -filter_complex "blend=all_expr='A*(if(gte(T,10),1,T/10))+B*(1-(if(gte(T,10),1,T/10)))'" output.mp4```

##### blockdetect 滤波器
- 用于确定视频帧的块状程度，而不对输入帧进行修改。
- 该滤波器基于Remco Muijs和Ihor Kirenko在2005年发表的论文中提出的一种无参考块状伪影测量方法，用于自适应视频处理。
- blockdetect滤波器接受以下选项：
    - period_min：设置确定像素网格（周期）的最小值。默认值为3。
    - period_max：设置确定像素网格（周期）的最大值。默认值为24。
    - planes：设置要过滤的平面。默认值为仅过滤第一个平面。
- 示例：假设你有一个视频文件，并想要了解其中的块状程度，即视频中是否存在明显的块状伪影。  
```ffmpeg -i input.mp4 -vf "blockdetect=period_min=8:period_max=32:planes=1" -f null -```

##### blurdetect 滤波器
- 用于确定视频帧的模糊程度，而不对帧进行修改。
- 该滤波器基于Marziliano、Pina等人发表的一篇论文，提出了一种无参考感知模糊度量方法。它还允许进行基于块的缩写。
- blurdetect滤波器接受以下选项：
    - low：设置Canny阈值算法使用的低阈值。高阈值将选择“强”边缘像素，然后通过8连通性与低阈值选择的“弱”边缘像素连接。
    - high：设置Canny阈值算法使用的高阈值。
    - radius：定义在边缘像素周围搜索局部最大值的半径。
    - block_pct：仅对最显著的块确定模糊程度，以百分比表示。
    - block_width：以block_width为宽度确定块的模糊程度。如果设置为小于1的值，将不使用块，而是将整个图像作为一个块进行处理，无论block_height如何。
    - block_height：以block_height为高度确定块的模糊程度。如果设置为小于1的值，将不使用块，而是将整个图像作为一个块进行处理，无论block_width如何。
    - planes：设置要过滤的平面。默认值为仅过滤第一个平面。
- 示例：假设你有一个视频文件，并想要了解其中的模糊程度，即视频中是否存在明显的模糊。你可以使用blurdetect滤波器来实现这个任务。  
```ffmpeg -i input.mp4 -vf "blurdetect=block_width=32:block_height=32:block_pct=80" -f null -```

##### bm3d 滤波器
- 用于使用块匹配3D算法对视频帧进行降噪处理。
- 该滤波器接受以下选项：
    - sigma：设置降噪强度。默认值为1。允许的范围是0到999.9。根据视频源的情况调整该值，因为降噪算法对sigma非常敏感。
    - block：设置局部块的大小。这是在2D中设置的尺寸。
    - bstep：设置处理块时的滑动步长。默认值为4。允许的范围是1到64。较小的值允许处理更多的参考块，但处理速度较慢。
    - group：设置第三维度中相似块的最大数量。默认值为1。当设置为1时，不进行块匹配。较大的值允许在单个组中包含更多的块。允许的范围是1到256。
    - range：设置搜索块匹配的半径。默认值为9。允许的范围是1到INT32_MAX。
    - mstep：设置块匹配时两个搜索位置之间的步长。默认值为1。允许的范围是1到64。较小的值会减慢处理速度。
    - thmse：设置块匹配的均方误差阈值。有效范围是0到INT32_MAX。
    - hdthr：设置3D变换域中硬阈值滤波的阈值参数。较大的值会导致频域中更强的硬阈值滤波。
    - estim：设置滤波估计模式。可以是basic（基本）或final（最终）。默认值为basic。
    - ref：如果启用，滤波器将使用第二个流进行块匹配。对于estim选项的基本值，默认情况下禁用；如果estim的值是final，将始终启用。
    - planes：设置要过滤的平面。默认为除alpha通道外的所有可用平面。
- 以下是一些示例来说明bm3d的使用：
    - 基本的bm3d滤波：  
    ```bm3d=sigma=3:block=4:bstep=2:group=1:estim=basic```
    - 与上述示例相同，但只对亮度（luma）进行滤波：  
    ```bm3d=sigma=3:block=4:bstep=2:group=1:estim=basic:planes=1```
    - 与上述示例相同，但同时使用基本和最终两种估计模式：  
    ```split[a][b],[a]bm3d=sigma=3:block=4:bstep=2:group=1:estim=basic[a],[b][a]bm3d=sigma=3:block=4:bstep=2:group=16:estim=final:ref=1```
    - 与上述示例相同，但先使用nlmeans滤波器进行预处理：  
    ```split[a][b],[a]nlmeans=s=3:r=7:p=3[a],[b][a]bm3d=sigma=3:block=4:bstep=2:group=16:estim=final:ref=1```
    - 这些示例演示了如何使用不同的选项来配置bm3d滤波器，以达到所需的视频降噪效果。根据需要，你可以根据视频源的特点和降噪要求来调整选项的值。
- 假设你有一段名为movie.mp4的视频文件，并且想要对它进行降噪处理和提高清晰度。你可以使用以下命令：  
```ffmpeg -i movie.mp4 -vf "bm3d=sigma=2:block=8:bstep=4:group=1:estim=basic" -c:a copy output.mp4```

##### boxblur 滤波器
- 用于对输入视频应用盒状模糊算法。
- 它接受以下参数：
    - luma_radius、lr：设置应用于亮度（luma）平面的盒状模糊半径。默认值为2。半径值必须是非负数，并且不能大于表达式 min(w,h)/2，其中w和h分别代表输入的宽度和高度。
    - chroma_radius、cr：设置应用于色度（chroma）平面的盒状模糊半径。默认值与luma_radius相同。半径值的限制和计算方式与luma_radius相同，但根据色度平面的尺寸进行计算，使用表达式min(cw,ch)/2，其中cw和ch分别代表输入的色度图像宽度和高度。
    - alpha_radius、ar：设置应用于alpha通道平面的盒状模糊半径。默认值与luma_radius相同。半径值的限制和计算方式与luma_radius相同，但根据alpha通道平面的尺寸进行计算，使用表达式min(w,h)/2。
    - luma_power、lp：指定应用于亮度平面的盒状模糊滤波器的重复次数。默认值为2。0表示禁用该效果。
    - chroma_power、cp：设置应用于色度平面的盒状模糊滤波器的重复次数。默认值与luma_power相同。0表示禁用该效果。
    - alpha_power、ap：设置应用于alpha通道平面的盒状模糊滤波器的重复次数。默认值与luma_power相同。0表示禁用该效果。
- 下面是一些示例来说明boxblur的使用：
    - 应用luma、chroma和alpha平面的盒状模糊，半径都设置为2：  
    ```boxblur=luma_radius=2:luma_power=1```  
    或  
    ```boxblur=2:1```
    - 将luma半径设置为2，而alpha和chroma半径设置为0：  
    ```boxblur=2:1:cr=0:ar=0```
    -将luma和chroma半径设置为视频尺寸的一部分：  
    ```boxblur=luma_radius=min(h\,w)/10:luma_power=1:chroma_radius=min(cw\,ch)/10:chroma_power=1```
- 这些示例演示了如何使用不同的选项来配置boxblur滤波器，以实现不同的盒状模糊效果。根据需要，你可以根据视频的特点和模糊要求来调整选项的值。
- 示例：  
```ffmpeg -i input.mp4 -vf "boxblur=luma_radius=10:chroma_radius=10" output.mp4```  
```ffmpeg -i input.mp4 -vf "split=2[original][mask];[mask]boxblur=luma_radius=10:chroma_radius=10[mask_blurred];[original][mask_blurred]alphamerge" output.mp4```

##### bwdif 滤波器
- 用于对输入视频进行去隔行处理（反交错处理）。其中，"bwdif"表示"BOb Weaver Deinterlacing Filter" （鲍勃·韦弗去隔行滤波器）。
- 该滤波器基于yadif算法，并结合了w3fdif和cubic插值算法，实现运动自适应的去隔行处理。
- 它接受以下参数：
    - mode：指定去隔行处理的模式。可以选择以下值之一：
        - 0或send_frame：对于每一帧输出一帧。
        - 1或send_field：对于每一个场输出一帧。
        - 默认值为send_field。
    - parity：指定输入隔行视频的场的奇偶性。可以选择以下值之一：
        - 0或tff：假设顶场先行。
        - 1或bff：假设底场先行。
        - -1或auto：启用自动检测场奇偶性。
        - 默认值为auto。如果隔行信息未知或解码器不导出该信息，则默认假设为顶场先行。
    - deint：指定要进行去隔行处理的帧。可以选择以下值之一：
        - 0或all：对所有帧进行去隔行处理。
        - 1或interlaced：仅对标记为隔行的帧进行去隔行处理。
        - 默认值为all。
- 举例：当你观看电视或者视频时，有时候会看到画面上出现水平方向的小条纹或者闪烁现象，这是由于视频信号中的隔行扫描造成的。隔行扫描是一种视频信号处理方式，其中每一帧的图像被分为两个场，每个场只包含图像的一半线条。
- 示例：  
```ffmpeg -i input.mp4 -vf "bwdif" output.mp4```

##### ccrepack 滤波器
- 用于重新封装CEA-708闭式字幕的辅助数据（side data）。
- CEA-708是一种用于数字电视广播中的闭式字幕标准。然而，一些商业编码器可能会出现问题，导致CEA-708的辅助数据存在格式错误，具体包括元组数量不正确（针对目标帧率的cc_count错误）以及元组排序不正确（即CEA-608元组不在辅助数据的首部）。
- 示例：  
```ffmpeg -i input.mp4 -vf "ccrepack" output.mp4```

##### cas 滤镜
- Contrast Adaptive Sharpen（对比度自适应锐化）滤镜，可以应用于视频流。
- 该滤镜具有以下选项：
    - strength：设置锐化的强度。默认值为0，表示不进行锐化处理。
    - planes：设置要进行滤镜处理的平面。默认值是对除了透明度平面（alpha plane）以外的所有平面进行滤镜处理。
- 在视频处理中，锐化滤镜用于增强图像的边缘和细节，使其看起来更清晰和鲜明。Contrast Adaptive Sharpen滤镜是一种根据图像的对比度自适应调整锐化效果的算法。它会根据每个像素周围的对比度情况来调整锐化的强度，以避免过度增强或模糊图像。
- 示例：  
```ffmpeg -i input.mp4 -vf "cas=strength=0.5" output.mp4```

##### atadenoise 滤镜
- 用于应用自适应时间平均降噪器到视频输入。
- 该滤镜接受以下选项：
    - 0a：设置第一个平面的阈值 A。默认值为 0.02。有效范围是 0 到 0.3。
    - 0b：设置第一个平面的阈值 B。默认值为 0.04。有效范围是 0 到 5。
    - 1a：设置第二个平面的阈值 A。默认值为 0.02。有效范围是 0 到 0.3。
    - 1b：设置第二个平面的阈值 B。默认值为 0.04。有效范围是 0 到 5。
    - 2a：设置第三个平面的阈值 A。默认值为 0.02。有效范围是 0 到 0.3。
    - 2b：设置第三个平面的阈值 B。默认值为 0.04。有效范围是 0 到 5。
    - s：设置滤波器用于平均的帧数。默认值为 9。必须是 [5, 129] 范围内的奇数。
    - p：设置滤波器用于平均的帧的平面。默认为全部平面。
    - a：设置滤波器用于平均的算法变体。默认为并行（parallel）。也可以设置为串行（serial）。
    - 0s、1s、2s：设置第一个、第二个或第三个平面的 sigma。默认值为 32767。有效范围是从 0 到 32767。此选项控制半径内每个像素的权重。将此选项设置为 0 会有效地禁用滤波。
- 示例：  
```ffmpeg -i input.mp4 -vf "atadenoise=0a=0.05:0b=0.1:1a=0.05:1b=0.1:s=7" output.mp4```

##### avglur 滤镜
- 用于应用平均模糊滤镜。
- 该滤镜接受以下选项：
    - sizeX：设置水平半径大小。
    - planes：设置要过滤的平面。默认情况下，将过滤所有平面。
    - sizeY：设置垂直半径大小，如果为零，则与 sizeX 相同。默认值为 0。
- 通过调整 sizeX 和 sizeY 参数的值，可以控制模糊的半径大小，从而影响模糊的程度。较大的半径值将导致更强的模糊效果。
- 示例：  
```ffmpeg -i input.mp4 -vf "avgblur=sizeX=10:planes=-1" output.mp4```

##### chromahold 滤镜
- 用于移除除特定颜色以外的所有颜色信息。
- 该滤镜接受以下选项：
    - color：不会被替换为中性色度的颜色。
    - similarity：与上述颜色的相似度百分比。0.01 表示只匹配完全相同的关键颜色，而 1.0 表示匹配所有颜色。
    - blend：混合百分比。0.0 会使像素完全变成灰色，或者完全不是灰色。较高的值会保留更多的颜色。
    - yuv：表示传递的颜色已经是 YUV 格式，而不是 RGB 格式。
        - 使用文字颜色（如 "green" 或 "red"）在启用此选项后没有意义。这可以用于将精确的 YUV 值作为十六进制数传递。
- 示例：当你拍摄一张彩色照片时，你可能想要突出其中的某种颜色，而将其他颜色转换为灰度。这时，你可以使用 chromahold 滤镜来实现这个效果。  
```ffmpeg -i input.jpg -vf "chromahold=color=red:blend=0.8" output.jpg```

##### chromakey 滤镜
- 用于在YUV色彩空间中进行颜色/色度关键。
- 该滤镜接受以下选项：
    - color：将被替换为透明的颜色。
    - similarity：与关键颜色的相似度百分比。
        - 0.01 表示只匹配完全相同的关键颜色，而 1.0 表示匹配所有颜色。
    - blend：混合百分比。
        - 0.0 会使像素完全透明，或者完全不透明。
        - 较高的值会产生半透明像素，其透明度与像素颜色与关键颜色的相似性成正比。
    - yuv：表示传递的颜色已经是 YUV 格式，而不是 RGB 格式。
        - 使用文字颜色（如 "green" 或 "red"）在启用此选项后没有意义。这可以用于将精确的 YUV 值作为十六进制数传递。
- 将输入图像中的每个绿色像素变为透明：  
```ffmpeg -i input.png -vf "chromakey=color=green" out.png```
- 在静态黑色背景的顶部叠加一个绿幕视频：  
```ffmpeg -f lavfi -i color=c=black:s=1280x720 -i video.mp4 -shortest -filter_complex "[1:v]chromakey=0x70de77:0.1:0.2[ckout];[0:v][ckout]overlay[out]" -map "[out]" output.mkv```
- 假设你有一个名为 background.jpg 的静态图像，你希望将其作为背景替换绿幕。  
```ffmpeg -i input.mp4 -i background.jpg -filter_complex "[0:v]chromakey=color=green[ckout];[ckout][1:v]overlay[outv]" -map "[outv]" output.mp4```  

##### chromar 滤波器
- 用于降低色度噪声（chrominance noise）。
- 滤波器提供了以下选项：
    - thres：设置用于平均色度值的阈值。当前像素和邻近像素的Y、U和V像素分量的绝对差值之和小于此阈值时，将用于平均。亮度分量（Luma component）保持不变，并复制到输出。默认值为30。允许的范围是1到200。
    - sizew：设置用于平均的水平矩形的半径。允许的范围是1到100。默认值为5。
    - sizeh：设置用于平均的垂直矩形的半径。允许的范围是1到100。默认值为5。
    - stepw：设置水平方向上的步长。默认值为1。允许的范围是1到50。主要用于加快滤波速度。
    - steph：设置垂直方向上的步长。默认值为1。允许的范围是1到50。主要用于加快滤波速度。
    - threy：设置Y分量的阈值，用于平均色度值。对当前像素和邻近像素的Y分量之间的最大允许差异进行更精细的控制。默认值为200。允许的范围是1到200。
    - threu：设置U分量的阈值，用于平均色度值。对当前像素和邻近像素的U分量之间的最大允许差异进行更精细的控制。默认值为200。允许的范围是1到200。
    - threv：设置V分量的阈值，用于平均色度值。对当前像素和邻近像素的V分量之间的最大允许差异进行更精细的控制。默认值为200。允许的范围是1到200。
    - distance：设置在计算中使用的距离类型。
        - 'manhattan'：绝对差值。
        - 'euclidean'：差值的平方。
        - 默认的距离类型是manhattan。
- 当你拍摄一张照片时，可能会遇到色度噪声的问题。想象一下，您在拍摄一幅夜晚的城市风景照片时，照片中的黑色天空中出现了一些彩色的杂点。这些彩色的杂点就是色度噪声，它们会导致照片看起来不清晰、不真实。为了改善照片的质量，你可以使用色度噪声滤波器。
- 示例：  
```ffmpeg -i input.mp4 -vf "chromanr=thres=30:sizew=5:sizeh=5" output.mp4```

##### chromashift 滤镜
- 用于在水平和/或垂直方向上移动色度（chroma）像素。
- 该滤镜提供以下选项：
    - cbh：设置水平方向上移动色度蓝色（chroma-blue）像素的数量。
    - cbv：设置垂直方向上移动色度蓝色像素的数量。
    - crh：设置水平方向上移动色度红色（chroma-red）像素的数量。
    - crv：设置垂直方向上移动色度红色像素的数量。
    - edge：设置边缘模式，可以是"smear"、"default"或"warp"。
- 此滤镜还支持将上述选项作为命令使用。命令接受与相应选项相同的语法。
- 假设有一张照片中的蓝天和云朵，但由于某种原因，照片中的蓝天看起来稍微偏绿色，而云朵则偏紫色。你可以使用"chromashift"滤镜来移动色度通道的像素，以纠正这种颜色偏移。
- 示例：  
```ffmpeg -i input.mp4 -vf "chromashift=cbh=10:crh=-5" output.mp4```

##### ciescope 滤镜
- 用于在CIE（国际照明委员会）色彩图上显示像素。
- 该滤镜接受以下选项：
    - system：设置颜色系统。
        - 'ntsc, 470m'
        - 'ebu, 470bg'
        - 'smpte'
        - '240m'
        - 'apple'
        - 'widergb'
        - 'cie1931'
        - 'rec709, hdtv'
        - 'uhdtv, rec2020'
        - 'dcip3'
    - cie：设置CIE系统。
        - 'xyy'
        - 'ucs'
        - 'luv'
    - gamuts：设置要绘制的色域。
        - 可以参考system选项中的可用值。
    - size, s：设置ciescope的大小，默认为512。
    - intensity, i：设置用于将输入像素值映射到CIE图上的强度。
    - contrast：设置用于绘制超出活动色域色域的颜色的对比度。
    - corrgamma：校正显示在色谱图上的gamma，默认启用。
    - showwhite：在CIE图上显示白点，默认禁用。
    - gamma：设置输入gamma。仅与XYZ输入色彩空间一起使用。
    - fill：使用CIE颜色进行填充，默认启用。
- 该滤镜的作用是在CIE色彩图上显示像素，并提供了一些选项来控制绘图的外观和行为。
- 假设有一段摄像机拍摄的花朵视频，你希望了解花朵的颜色分布情况，并在CIE色彩图上显示像素以便进行分析。
- 示例：  
```ffmpeg -i input.mp4 -vf "ciescope" -frames:v 1 output.png```

##### codecview 滤镜
- 用于可视化某些编解码器通过帧的辅助数据或其他方式导出的信息。
- 该滤镜接受以下选项：
    - block：使用亮度平面显示块分区结构。
    - mv：设置要可视化的运动矢量。
        - 可用的mv选项标志有：
            - 'pf'：P帧的前向预测MV（运动矢量）
            - 'bf'：B帧的前向预测MV
            - 'bb'：B帧的后向预测MV
    - qp：使用色度平面显示量化参数。
    - mv_type, mvt：设置要可视化的运动矢量类型。除非通过frame_type选项指定，否则包括所有帧的MV。
        - 可用的mv_type选项标志有：
            - 'fp'：前向预测MV
            - 'bp'：后向预测MV
    - frame_type, ft：设置要可视化运动矢量的帧类型。
        - 可用的frame_type选项标志有：
            - 'if'：帧内编码帧（I帧）
            - 'pf'：预测帧（P帧）
            - 'bf'：双向预测帧（B帧）
- 假设你有一段视频，其中包含了一个人在跑步的场景。你想要了解视频中的运动信息，特别是人物的运动轨迹。你可以使用FFmpeg的"codecview"滤镜来可视化运动矢量，以便更直观地观察人物的运动情况。
- 示例：
    - 可视化所有帧的前向预测MV（运动矢量）：  
    ```ffplay -flags2 +export_mvs input.mp4 -vf codecview=mv_type=fp```
    - 可视化P帧和B帧的多方向MV（运动矢量）：  
    ```ffplay -flags2 +export_mvs input.mp4 -vf codecview=mv=pf+bf+bb```

##### colorbalance 滤镜
- 用于调整帧的主要颜色（红色、绿色和蓝色）的强度。
- 该滤镜允许在阴影、中间调或高光区域调整红-请、绿-洋红或蓝-黄平衡。
- 调整值为正数将平衡向主要颜色方向移动，而负数将平衡向互补颜色方向移动。
- 该滤镜接受以下选项：
    - rs、gs、bs：调整红色、绿色和蓝色阴影（最暗像素）。
    - rm、gm、bm：调整红色、绿色和蓝色中间调（中等亮度像素）。
    - rh、gh、bh：调整红色、绿色和蓝色高光（最亮像素）。
    - 选项的允许范围为[-1.0, 1.0]。默认值为0。
        - pl：在改变颜色平衡时保持亮度。默认情况下禁用。
- 这个滤镜支持以下所有选项作为命令。
- 该滤镜的作用是根据指定的选项调整输入帧的颜色平衡，以改变红色、绿色和蓝色的强度。通过调整这些主要颜色的强度，可以改变图像的色彩效果。
- 示例：
    - 将红色色调添加到阴影部分：  
    ```ffmpeg -i input.mp4 -vf "colorbalance=rs=0.3" output.mp4```

##### colorcontast 滤镜
- 调整RGB分量之间的颜色对比度。
- 该滤镜接受以下选项：
    - rc：设置红-青对比度。默认值为0.0。允许范围为-1.0到1.0。
    - gm：设置绿-洋红对比度。默认值为0.0。允许范围为-1.0到1.0。
    - by：设置蓝-黄对比度。默认值为0.0。允许范围为-1.0到1.0。
    - rcw、gmw、byw：设置每个rc、gm、by选项值的权重。默认值为0.0。允许范围为0.0到1.0。如果所有权重都为0.0，则禁用滤镜。
    - pl：设置保持亮度的程度。默认值为0.0。允许范围为0.0到1.0。
- 这些选项用于调整不同颜色通道之间的对比度，从而改变图像的色彩对比度。此外，该滤镜还支持将上述选项作为命令使用。
- 示例：
    - 我们考虑一张图像，其中包含了一朵鲜艳的红色玫瑰。如果我们想增加该图像的对比度，使红色更加鲜艳，我们可以使用"colorcontrast"滤镜。  
    ```ffmpeg -i input.jpg -vf "colorcontrast=rc=0.5" output.jpg```

##### colorcorrect 滤镜
- 用于选择地调整黑色和白色的颜色白平衡。该滤镜在YUV色彩空间中操作。
- 该滤镜接受以下选项：
    - rl：设置红色阴影点。允许范围为-1.0到1.0。默认值为0。
    - bl：设置蓝色阴影点。允许范围为-1.0到1.0。默认值为0。
    - rh：设置红色高光点。允许范围为-1.0到1.0。默认值为0。
    - bh：设置蓝色高光点。允许范围为-1.0到1.0。默认值为0。
    - saturation：设置饱和度的程度。允许范围为-3.0到3.0。默认值为1。
    - analyze：如果设置为除"manual"以外的值，它将分析每一帧并使用派生参数来过滤输出帧。可能的值有："manual"、"average"、"minmax"、"median"。默认值为"manual"。
- 这些选项用于选择地调整黑色和白色地颜色平衡，并控制饱和度。
- 该滤镜支持上述选项作为命令使用。
- 示例：
    - 假设你有一段视频，拍摄于室内环境下，但由于光照条件不佳，导致图像偏暗。你希望通过调整颜色白平衡来改善图像的亮度和色彩。这时候，你可以使用"colorcorrect"滤镜来实现这个目标。  
    ```ffmpeg -i input.mp4 -vf "colorcorrect=rl=0.2:bh=-0.1:saturation=1.2" output.mp4``` 

##### colorchannelmixer 滤镜
- 用于调整视频输入帧通过重新混合颜色通道来达到效果。
- 该滤镜会通过将同一像素的其他通道的值相加来修改某个颜色通道。例如，如果要修改的是红色通道，则输出值将为：  
```red = red * rr + blue * rb + green * rg + alpha * ra```
- 该滤镜接受以下选项：
    - rr, rg, rb, ra：调整输入红色、绿色、蓝色和alpha通道对输出红色通道的贡献。默认值为1（rr）和0（rg、rb、ra）。
    - gr, gg, gb, ga：调整输入红色、绿色、蓝色和alpha通道对输出绿色通道的贡献。默认值为1（gg）和0（gr、gb、ga）。
    - br, bg, bb, ba：调整输入红色、绿色、蓝色和alpha通道对输出蓝色通道的贡献。默认值为1（bb）和0（br、bg、ba）。
    - ar, ag, ab, aa：调整输入红色、绿色、蓝色和alpha通道对输出alpha通道的贡献。默认值为1（aa）和0（ar、ag、ab）。
    - 选项的允许范围为[-2.0, 2.0]。
        - 此外，还有一些其他的选项和命令，如：
        - pc：设置颜色保留模式，可选值包括：'none'、'lum'、'max'、'avg'、'sum'、'nrm'、'pwr'。
        - pa：在改变颜色时设置保留颜色的程度，允许范围为[0.0, 1.0]。
- 该滤镜支持上述选项作为命令使用。
- 将源视频转换为灰度图像：  
```colorchannelmixer=.3:.4:.3:0:.3:.4:.3:0:.3:.4:.3```  
```ffmpeg -i input.mp4 -vf "colorchannelmixer=.3:.4:.3:0:.3:.4:.3:0:.3:.4:.3" -c:a copy output.mp4```
- 模拟复古的棕褐色调（Sepia tones）：  
```colorchannelmixer=.393:.769:.189:0:.349:.686:.168:0:.272:.534:.131```  
```ffmpeg -i input.mp4 -vf "colorchannelmixer=.393:.769:.189:0:.349:.686:.168:0:.272:.534:.131" -c:a copy output.mp4```

##### colorize 滤镜
- 它可以在视频流上叠加一个纯色。
- 该滤镜接受以下选项：
    - hue：设置颜色的色调。允许范围是从0到360。默认值为0。
    - saturation：设置颜色的饱和度。允许范围是从0到1。默认值为0.5。
    - lightness：设置颜色的亮度。允许范围是从0到1。默认值为0.5。
    - mix：设置源亮度的混合比例。默认值为1.0。允许范围是从0.0到1.0。
- 该滤镜还支持将上述选项作为命令来使用。
- 示例：
    - 在视频上创建一个纯蓝色的叠加效果：  
    ```ffmpeg -i input.mp4 -vf "colorize=hue=240:saturation=1:lightness=0.5:mix=1.0" -c:a copy output.mp4```

##### colorkey 滤镜
- 它用于基于RGB颜色空间进行颜色键控。该滤镜通过将位于与关键颜色相似半径内的每个像素的alpha分量设置为0来操作8位RGB格式帧。对于不在相似半径内的像素，其alpha值取决于混合选项的值。
- 该滤镜接受以下选项：
    - color：设置将alpha值设置为0（完全透明）的颜色。默认为黑色。
    - similarity：设置与关键颜色在相似半径内的其他颜色完全透明的半径。计算得到的距离与关键颜色的RGB值和像素颜色之间的三维空间单位分数距离相关。范围是0.01到1.0。0.01表示在关键颜色周围的一个非常小的半径内匹配，而1.0表示匹配所有颜色。默认为0.01。
    - blend：设置在相似半径之外的像素的alpha值的计算方式。0.0使像素完全透明或完全不透明。较高的值会导致半透明像素，与关键颜色越相似，透明度越高。范围是0.0到1.0。默认为0.0。
- 该滤镜还支持将上述选项作为命令来使用。
- 示例：
    - 将视频中的绿色背景变为透明：  
    ```ffmpeg -i input.mp4 -vf "colorkey=green:similarity=0.3:blend=0.2" -c:a copy output.mp4```

##### colorhold 滤镜
- 可以除去某个特定颜色外的所有RGB颜色信息，使其变为中兴灰色。
- 该滤镜接受以下选项：
    - color：指定不被替换为中性灰色的颜色。
    - similarity：与上述颜色的相似度百分比。0.01表示只匹配完全相同的关键颜色，而1.0表示匹配所有颜色。
    - blend：混合百分比。0.0表示像素完全变为灰色，较高的值则保留更多的原色。
- 该滤镜支持与选项相同的命令。命令使用与相应选项相同的语法。如果指定的表达式无效，则保持其当前值。
- 示例：
    - 我们有一张图片，其中一个物体是一个红色的苹果，其他物体是绿色的树和蓝色的天空。我们希望将苹果保留为红色，而将树和天空的颜色转换为灰色。  
    ```ffmpeg -i input.jpg -vf "colorhold=color=red:similarity=0.5:blend=0.2" output.jpg```

##### colorlevels 滤镜
- 是一个调整视频输入帧的滤镜，使用级别进行调整。
- 该滤镜具有以下选项：
    - rimin
    - gimin
    - bimin
    - aimin
    - 调整红色、绿色、蓝色和透明度输入的黑点。选项的允许范围为[-1.0, 1.0]。默认值为0。
    - rimax
    - gimax
    - bimax
    - aimax
    - 调整红色、绿色、蓝色和透明度输入的白点。选项的允许范围为[-1.0, 1.0]。默认值为1。
    - 输入级别用于提亮高光（亮色调），加深阴影（暗色调），改变亮暗调的平衡。
    - romin
    - gomin
    - bomin
    - aomin
    - 调整红色、绿色、蓝色和透明度输出的黑点。选项的允许范围为[0, 1.0]。默认值为0。

    - romax
    - gomax
    - bomax
    - aomax
    - 调整红色、绿色、蓝色和透明度输出的白点。选项的允许范围为[0, 1.0]。默认值为1。
    - 输出级别允许手动选择受限的输出级别范围。    
    - preserve
    - 设置保留颜色模式。可接受的值为：
        - 'none'
        - 禁用颜色保留，这是默认值。
        - 'lum'
        - 保留亮度。
        - 'max'
        - 保留RGB三元组的最大值。
        - 'avg'
        - 保留RGB三元组的平均值。
        - 'sum'
        - 保留RGB三元组的总和值。
        - 'nrm'
        - 保留RGB三元组的归一化值。
        - 'pwr'
        - 保留RGB三元组的功率值。
- 该滤镜支持所有上述选项作为命令。
- 示例：
    - 使视频输出变暗：  
    ```colorlevels=rimin=0.058:gimin=0.058:bimin=0.058```
    - 增加对比度：  
    ```colorlevels=rimin=0.039:gimin=0.039:bimin=0.039:rimax=0.96:gimax=0. -96:bimax=0.96```
    - 使视频输出变亮：  
    ```colorlevels=rimax=0.902:gimax=0.902:bimax=0.902```
    - 增加亮度：  
    ```colorlevels=romin=0.5:gomin=0.5:bomin=0.5```
    - 我们有一段录制在室内的视频，但是由于光线不足，导致视频看起来有些暗淡。我们希望增加视频的亮度和对比度，使其看起来更明亮、更有层次感。  
    ```ffmpeg -i input.mp4 -vf "colorlevels=romin=0.2:gomin=0.2:bomin=0.2:romax=0.8:gimax=0.8:bimax=0.8" output.mp4```

##### colormap 滤镜
- 用于视频流的自定义颜色映射滤镜。
- 该滤镜需要三个输入视频流。第一个流是要进行滤镜处理的视频流。第二个和第三个视频流用于指定源颜色到目标颜色的映射的颜色片段。
- 该滤镜接受以下选项：
    - patch_size
        - 设置源和目标视频流颜色片段的大小（以像素为单位）。
    - nb_patches
        - 设置从源和目标视频流中使用的最大颜色片段数。默认值为附加视频流中可用的颜色片段数。最大允许的颜色片段数为64。
    - type
        - 设置用于目标颜色的调整方式。可以是相对或绝对调整。默认值是绝对调整。
    - kernel
        - 设置用于测量映射颜色之间的颜色差异的核函数。
        - 可接受的值为：
            - 'euclidean'
            - 'weuclidean'
            - 默认值为euclidean。
- 示例：
    - 假设我们有一个视频，我们希望将视频中的蓝色调整为红色，并将绿色调整为黄色。我们可以使用11.39 colormap滤镜来实现这个效果。  
    ```ffmpeg -i input.mp4 -i blue_patch.mp4 -i green_patch.mp4 -filter_complex "[0:v][1:v][2:v] colormap=type=absolute" output.mp4```

##### colormatrix 滤镜
- 用于转换颜色矩阵的滤镜。
- 该滤镜接受以下选项：
    - src
    - dst
    - 指定源和目标颜色矩阵。两个值都必须被指定。
    - 可接受的值有：
        - 'bt709'
        - BT.709
        - 'fcc'
        - FCC
        - 'bt601'
        - BT.601
        - 'bt470'
        - BT.470
        - 'bt470bg'
        - BT.470BG
        - 'smpte170m'
        - SMPTE-170M
        - 'smpte240m'
        - SMPTE-240M
        - 'bt2020'
        - BT.2020
- 例如，要从BT.601转换为SMPTE-240M，可以使用以下命令：  
```colormatrix=bt601:smpte240m```
- 示例：
    - 假设我们有一段拍摄在旧电视上的视频，它使用的是BT.601颜色空间，但我们希望在现代设备上播放时能够更准确地呈现颜色。我们可以使用colormatrix滤镜将其转换为BT.709颜色空间。  
    ```ffmpeg -i input.mp4 -vf "colormatrix=bt601:bt709" output.mp4```

##### colorspace 滤镜
- 用于转换颜色空间、传输特性或色彩主要性质的滤镜。
- 该滤镜接受以下选项：
    - all
    - 同时指定所有颜色属性。
    - 可接受的值有：
        - ‘bt470m’
        - BT.470M
        - ‘bt470bg’
        - BT.470BG
        - ‘bt601-6-525’
        - BT.601-6 525
        - ‘bt601-6-625’
        - BT.601-6 625
        - ‘bt709’
        - BT.709
        - ‘smpte170m’
        - SMPTE-170M
        - ‘smpte240m’
        - SMPTE-240M
        - ‘bt2020’
        - BT.2020
    - space
    - 指定输出颜色空间。
    - 可接受的值有：
        - ‘bt709’
        - BT.709
        - ‘fcc’
        - FCC
        - ‘bt470bg’
        - BT.470BG 或 BT.601-6 625
        - ‘smpte170m’
        - SMPTE-170M 或 BT.601-6 525
        - ‘smpte240m’
        - SMPTE-240M
        - ‘ycgco’
        - YCgCo
        - ‘bt2020ncl’
        - 非恒定亮度的 BT.2020
    - trc
    - 指定输出传输特性。
    - 可接受的值有：
        - ‘bt709’
        - BT.709
        - ‘bt470m’
        - BT.470M
        - ‘bt470bg’
        - BT.470BG
        - ‘gamma22’
        - 常量伽马为2.2
        - ‘gamma28’
        - 常量伽马为2.8
        - ‘smpte170m’
        - SMPTE-170M, BT.601-6 625 或 BT.601-6 525
        - ‘smpte240m’
        - SMPTE-240M
        - ‘srgb’
        - SRGB
        - ‘iec61966-2-1’
        - iec61966-2-1
        - ‘iec61966-2-4’
        - iec61966-2-4
        - ‘xvycc’
        - xvycc
        - ‘bt2020-10’
        - 10位内容的 BT.2020
        - ‘bt2020-12’
        - 12位内容的 BT.2020
    - primaries
    - 指定输出色彩主要性质。
    - 可接受的值有：
        - ‘bt709’
        - BT.709
        - ‘bt470m’
        - BT.470M
        - ‘bt470bg’
        - BT.470BG 或 BT.601-6 625
        - ‘smpte170m’
        - SMPTE-170M 或 BT.601-6 525
        - ‘smpte240m’
        - SMPTE-240M
        - ‘film’
        - film
        - ‘smpte431’
        - SMPTE-431
        - ‘smpte432’
        - SMPTE-432
        - ‘bt2020’
        - BT.2020
        - ‘jedec-p22’
        - JEDEC P22 磷光体
    - range
    - 指定输出色彩范围。
    - 可接受的值有：
        - ‘tv’
        - 电视（受限制）范围
        - ‘mpeg’
        - MPEG（受限制）范围
        - ‘pc’
        - PC（完整）范围
        - ‘jpeg’
        - JPEG（完整）范围
    - format
    - 指定输出颜色格式。
    - 可接受的值有：
        - ‘yuv420p’
        - YUV 4:2:0 平面 8位
        - ‘yuv420p10’
        - YUV 4:2:0 平面 10位
        - ‘yuv420p12’
        - YUV 4:2:0 平面 12位
        - ‘yuv422p’
        - YUV 4:2:2 平面 8位
        - ‘yuv422p10’
        - YUV 4:2:2 平面 10位
        - ‘yuv422p12’
        - YUV 4:2:2 平面 12位
        - ‘yuv444p’
        - YUV 4:4:4 平面 8位
        - ‘yuv444p10’
        - YUV 4:4:4 平面 10位
        - ‘yuv444p12’
        - YUV 4:4:4 平面 12位

    - fast
    - 进行快速转换，跳过伽马/主要性纠正。这样会显著减少CPU使用，但数学上是不正确的。要获得与colormatrix滤镜生成的输出兼容的结果，请使用fast=1。
    - dither
    - 指定抖动模式。
    - 可接受的值有：
        - ‘none’
        - 无抖动
        - ‘fsb’
        - Floyd-Steinberg 抖动
    - wpadapt
    - 白点适应模式。
    - 可接受的值有：
        - ‘bradford’
        - Bradford 白点适应
        - ‘vonkries’
        - von Kries 白点适应
        - ‘identity’
        - identity 白点适应（即不进行白点适应）
        - iall
        - 同时覆盖所有输入属性。与all选项接受相同的值。
        - ispace
        - 覆盖输入颜色空间。与space选项接受相同的值。
        - iprimaries
        - 覆盖输入色彩主要性质。与primaries选项接受相同的值。
        - itrc
        - 覆盖输入传输特性。与trc选项接受相同的值。
        - irange
        - 覆盖输入色彩范围。与range选项接受相同的值。
- 该滤镜将传输特性、颜色空间和色彩主要性质转换为指定的用户值。如果未指定输出值，则根据“all”属性设置为默认值。如果也未指定该属性，则滤镜将记录错误。输出色彩范围和格式默认与输入色彩范围和格式相同。输入传输特性、颜色空间、色彩主要性质和色彩范围应设置在输入数据上。如果缺少其中任何一个，滤镜将记录错误，并且不会进行转换。
- 示例：
    要将输入转换为SMPTE-240M，可以使用以下命令：  
    ```colorspace=smpte240m```

##### colortemperature 滤镜
- 用于调整视频中的色温，以模拟环境色温的变化。
- 它接受以下几个选项：
    - temperature：设置色温，单位为开尔文（Kelvin）。允许的范围是从1000到40000，缺省值为6500K（日光色温）。
    - mix：设置与滤镜输出的混合程度。允许的范围是从0到1，其中0表示完全使用滤镜输出，1表示完全使用原始输入。缺省值为1。
    - pl：设置保留亮度的程度。允许的范围是从0到1，其中0表示完全不保留亮度，1表示完全保留亮度。缺省值为0。
- 示例：
    - 调整色温：  
    ```ffmpeg -i input.mp4 -vf "colortemperature=7000" output.mp4```

##### convolution 滤镜
- 可以应用3x3、5x5、7x7或最多49个元素的卷积操作。
- 该滤镜接受以下选项：
    - 0m、1m、2m、3m：设置每个平面的矩阵。矩阵是由9、25或49个有符号整数组成的序列，用于方形模式；或者是由1到49个有符号整数组成的奇数序列，用于行模式。
    - 0rdiv、1rdiv、2rdiv、3rdiv：设置每个平面的计算值的乘法因子。如果未设置或设置为0，则将使用矩阵元素的总和作为乘法因子。
    - 0bias、1bias、2bias、3bias：设置每个平面的偏置。该值将添加到乘法结果中，可用于调整图像的亮度。默认值为0.0。
    - 0mode、1mode、2mode、3mode：设置每个平面的矩阵模式。可以是方形（square）、行（row）或列（column）模式。默认值为square。
- 除了使用选项来设置这些参数外，"convolution"滤镜还支持使用命令来实现相同的效果。你可以在运行滤镜时，在命令行中使用特定的命令来动态调整这些参数。
- 以下是应用一些常见卷积操作的示例命令：
    - 应用锐化（sharpen）效果。  
    ```ffmpeg -i input.mp4 -vf "convolution='0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0'" output.mp4```
    - 应用模糊（blur）效果。  
    ```ffmpeg -i input.mp4 -vf "convolution='1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1/9:1/9:1/9:1/9'" output.mp4```
- 示例：
    - 假设你有一张名为"input.jpg"的图片，你想要应用一个边缘检测效果，使得图像中的边缘更加明显。  
    ```ffmpeg -i input.jpg -vf "convolution='0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:5:5:5:1:0:128:128:128'" output.jpg```

##### convolve 滤镜
- 是一个在视频中应用二维卷积的滤镜。它使用第二个视频流作为冲激相应（impulse response），对视频流进行卷积操作。
- 该滤镜接受以下选项：
    - planes：设置要处理的平面（planes）。可以选择处理哪些颜色平面，默认为全部平面。
    - impulse：设置要处理的冲激响应视频帧（impulse response）。可以选择处理第一帧（first）或所有帧（all）。默认为所有帧。
- 另外，"convolve"滤镜还支持帧同步（framesync）选项。帧同步选项用于处理多个输入流之间的帧同步问题，可以在处理多个视频流时控制帧的对齐和同步。
- 使用"convolve"滤镜需要提供两个视频流，一个作为输入视频流，另一个作为冲激响应视频流。滤镜将在频域中对输入视频流进行卷积操作，产生一个新的输出视频流。
- 示例：
    - 假设你有两个视频文件，一个名为"input.mp4"的输入视频文件，另一个名为"impulse.mp4"的冲激响应视频文件。你想要将输入视频文件与冲激响应视频文件进行频域卷积，以实现一种特殊的效果。  
    ```ffmpeg -i input.mp4 -i impulse.mp4 -filter_complex "[0:v][1:v]convolve=planes=all:impulse=all" output.mp4```

##### copy 处理指令
- copy是FFmpeg工具中的一种指令，用于将输入视频源原样复制到输出中，不经过任何编码或处理。这个指令主要用于测试目的，可以用来检验输入和输出的视频文件是否一致。
- 使用该指令时，FFmpeg将不对输入视频进行任何编码操作，而是直接将输入文件的视频流复制到输出文件中。这意味着输出文件的视频部分与输入文件完全相同，没有任何质量损失或修改。
- 这个指令在某些情况下非常有用，例如当你想要快速复制一个视频文件而不改变其编码或质量时，或者在测试FFmpeg的输入输出功能时。它可以帮助你确认输入和输出视频文件的一致性，并验证其他处理指令的效果。
- 该指令只复制视频流，不会对音频流或其他元数据进行处理。如果你想要复制整个视频文件的所有内容，包括音频和其他元数据，可以使用类似的指令，但是目前这里还没有学到，后面学到了会进行补充。
- 示例：
    - 复制视频文件：  
    ```ffmpeg -i input.mp4 -c:v copy -c:a copy output.mp4```
    - 分离音频和视频流：  
    ```ffmpeg -i input.mp4 -c:v copy -an video.mp4```  
    ```ffmpeg -i input.mp4 -c:a copy -vn audio.mp3```

##### coreimage 处理指令
- coreimage是指 FFmpeg 工具中的一种处理指令，用于在 macOS 上使用苹果的 CoreImage API 对视频进行 GPU 加速的图像滤镜处理。
- CoreImage 是苹果提供的一个图像处理框架，它可以利用 GPU 进行硬件加速处理。这个指令允许你使用 CoreImage 提供的滤镜和图像生成器来对视频进行处理。你可以根据滤镜的名称和选项来指定要使用的滤镜，并设置滤镜的参数。
- 核心图像（CoreImage）滤镜接受以下选项：
    - list_filters：列出所有可用的滤镜和图像生成器，以及它们的选项、最小值、最大值和默认值。
    - filter：指定滤镜的名称和选项。可以使用 list_filters 命令来确定所有有效的滤镜名称和选项。数值选项通过浮点值指定，并自动限制在其值范围内。矢量和颜色选项必须通过一组以空格分隔的浮点值来指定。需要进行字符转义。可以使用特殊的选项名称 default 来使用滤镜的默认选项。
- 此外，还可以使用 output_rect 选项来指定输出图像的矩形区域。
- 以下是一些示例：
    - 列出所有可用的滤镜：  
    ```coreimage=list_filters=true```
    - 使用 CIBoxBlur 滤镜默认选项来模糊图像：  
    ```coreimage=filter=CIBoxBlur@default```  
    - 使用滤镜链，其中 CISepiaTone 使用默认值，CIVignetteEffect 的中心点为 100x100，半径为 50 像素：  
    ```coreimage=filter=CISepiaTone@default#CIVignetteEffect@inputCenter=100\ 100@inputRadius=50```
    - 使用 nullsrc 和 CIQRCodeGenerator 生成 FFmpeg 官网的二维码图像：  
    ```ffmpeg -f lavfi -i nullsrc=s=100x100,coreimage=filter=CIQRCodeGenerator@inputMessage=https\\\\\://FFmpeg.org/@inputCorrectionLevel=H -frames:v 1 QRCode.png```
    - 这些示例演示了如何使用 CoreImage 滤镜在 macOS 上对视频进行处理，以及如何指定滤镜和选项来实现不同的效果。

##### corr(correlation) 滤镜
- 获取两个输入视频之间的相关性。该滤镜需要两个输入视频。
- 为了使该滤镜正常工作，两个输入视频必须具有相同的分辨率和像素格式。同时，它假设两个输入视频具有相同数量的帧，这些帧逐一进行比较。
- 通过日志系统打印出每个分量、平均值、最小值和最大值的相关性。
- 该滤镜将每帧的计算相关性存储在帧元数据中。
- 该滤镜还支持帧同步选项。
- 示例：
    - 正在处理的输入文件main.mpg与参考文件ref.mpg进行比较。  
    ```ffmpeg -i main.mpg -i ref.mpg -lavfi corr -f null -```

##### cover_rect 滤镜
- 是一个在视频中覆盖矩形对象的滤镜。
- 它接受以下选项：
    - cover：可选的覆盖图像的文件路径，需要是 yuv420 格式的图像。
    - mode：设置覆盖模式。
- 它接受以下值：
    - 'cover'：使用提供的图像进行覆盖。
    - 'blur'：通过插值周围像素进行模糊覆盖。
    - 默认值是 "blur"。
- 示例：
    - 将给定视频中的矩形对象用提供的图像进行覆盖：  
    ```ffmpeg -i file.ts -vf find_rect=newref.pgm,cover_rect=cover.jpg:mode=cover new.mkv```

##### crop 滤镜
- 这是一个视频裁剪的命令，用于将输出视频裁剪到指定的尺寸。
- 它接受以下参数：
    - w, out_w
    - 输出视频的宽度。默认值为输入视频的宽度（iw）。此表达式仅在过滤器配置期间或发送“w”或“out_w”命令时计算一次。

    - h, out_h
    - 输出视频的高度。默认值为输入视频的高度（ih）。此表达式仅在过滤器配置期间或发送“h”或“out_h”命令时计算一次。

    - x
    - 输出视频左边缘在输入视频中的水平位置。默认值为（in_w-out_w）/ 2。此表达式每帧计算一次。

    - y
    - 输出视频顶边缘在输入视频中的垂直位置。默认值为（in_h-out_h）/ 2。此表达式每帧计算一次。

    - keep_aspect
    - 如果设置为1，将通过更改输出样本长宽比，强制输出显示长宽比与输入相同。默认值为0。

    - exact
    - 启用精确裁剪。如果启用，子采样视频将按照指定的精确宽度/高度/x/y进行裁剪，不会舍入为最接近的较小值。默认值为0。

    - out_w、out_h、x和y参数是包含以下常量的表达式：
    
    - x
    - y
    - x和y的计算值。它们为每个新帧计算。
    
    - in_w
    - in_h
    - 输入视频的宽度和高度。
    
    - iw
    - ih
    - 这与in_w和in_h相同。
    
    - out_w
    - out_h
    - 输出（裁剪后）的宽度和高度。
    
    - ow
    - oh
    - 这与out_w和out_h相同。
    
    - a
    - 与iw / ih相同
    
    - sar
    - 输入样本长宽比
    
    - dar
    - 输入显示长宽比，它与（iw / ih）* sar相同
    
    - hsub
    - vsub
    - 水平和垂直色度子采样值。例如，对于像素格式“yuv422p”，hsub为2，vsub为1。
    
    - n
    - 输入帧的编号，从0开始。
    
    - pos
    - 输入帧在文件中的位置，如果位置未知则为NAN；已弃用，请勿使用
    
    - t
    - 以秒为单位的时间戳。如果输入时间戳未知，则为NAN。

    - out_w的表达式可能依赖于out_h的值，而out_h的表达式可能依赖于out_w的值，但它们不能依赖于x和y，因为x和y在out_w和out_h之后计算。

    - x和y参数指定输出（非裁剪）区域左上角的位置表达式。它们每帧计算一次。如果计算出的值无效，则会近似为最近的有效值。
- 这是关于视频裁剪的一些示例和命令：
- 示例：
    - 裁剪尺寸为100x100，位置为(12,34)的区域：
    - crop=100:100:12:34
    - 或者使用命名选项：
    - crop=w=100:h=100:x=12:y=34
    
    - 裁剪中心区域，大小为100x100：
    - crop=100:100
    
    - 裁剪中心区域的大小为输入视频尺寸的2/3：
    - crop=2/3in_w:2/3in_h
    
    - 裁剪输入视频的中心正方形：
    - crop=out_w=in_h
    - 或者
    - crop=in_h
    
    - 以左上角位置为(100,100)，右下角位置与输入图像的右下角相对应的矩形：
    - crop=in_w-100:in_h-100:100:100
    
    - 从左右边框裁剪10个像素，从上下边框裁剪20个像素：
    - crop=in_w-210:in_h-220
    
    - 只保留输入图像的右下角1/4：
    - crop=in_w/2:in_h/2:in_w/2:in_h/2

    - 根据黄金比例裁剪高度：
    - crop=in_w:1/PHI*in_w
    
    - 应用颤抖效果：
    - crop=in_w/2:in_h/2:(in_w-out_w)/2+((in_w-out_w)/2)*sin(n/10):   - (in_h-out_h)/2 +((in_h-out_h)/2)*sin(n/7)
    
    - 根据时间戳应用不规则相机效果：
    - crop=in_w/2:in_h/2:(in_w-out_w)/2+((in_w-out_w)/2)sin(t10):(in_h-out_h)/2 +((in_h-out_h)/2)sin(t13)
    
    - 根据y的值设置x：
    - crop=in_w/2:in_h/2:y:10+10*sin(n/10)
- 命令：
    - w, out_w：设置输出视频的宽度。
    - h, out_h：设置输出视频的高度。
    - x：设置输出视频在输入视频中的水平位置。
    - y：设置输出视频在输入视频中的垂直位置。
- 这些命令接受与相应选项相同的语法。如果指定的表达式无效，则保持其当前值不变。
- 示例：
    - 将输入视频裁剪到100x100的尺寸，位置为(12,34)：  
    ```ffmpeg -i input.mp4 -vf "crop=100:100:12:34" output.mp4```
    - 裁剪输入视频的中心区域，大小为100x100：  
    ```ffmpeg -i input.mp4 -vf "crop=100:100" output.mp4```
    - 将输入视频裁剪为宽度和高度为输入视频的2/3：  
    ```ffmpeg -i input.mp4 -vf "crop=2/3*in_w:2/3*in_h" output.mp4```
    - 裁剪输入视频的中心正方形：  
    ```ffmpeg -i input.mp4 -vf "crop=out_w=in_h" output.mp4```

##### cropdetect 滤镜
- 用于自动检测视频中的裁剪尺寸。
- cropdetect滤镜通过计算裁剪所需的参数，并通过日志系统打印推荐的参数。检测到的尺寸对应于输入视频的非黑色或视频区域，具体取决于所选的模式。
- 它接受以下参数：
    - mode    
    - 根据模式，裁剪检测可以基于周围像素的黑色值或运动矢量和边缘像素的组合。

    - 'black'
    - 检测播放视频周围的黑色像素。可以使用选项limit进行精细控制。

    - 'mvedges'
    - 通过视频内部的运动矢量和扫描边缘像素来检测播放视频，这些边缘像素通常形成播放视频的边界。

    - limit
    - 设置较高的黑色值阈值，可以选择从0到255的值（对于8位格式）。大于设置值的亮度被认为是非黑色。默认值为24。您还可以指定一个介于0.0和1.0之间的值，该值将根据像素格式的位深度进行缩放。

    - round
    - 宽度/高度应该被整除的值。默认值为16。偏移量会自动调整以使视频居中。使用2只能得到偶数尺寸（对于4:2:2视频而言是必需的）。对于大多数视频编解码器，16是最佳选择。

    - skip
    - 设置跳过评估的初始帧数。默认值为2。范围是0到INT_MAX。

    - reset_count, reset
    - 设置计数器，确定cropdetect在多少帧之后将重置先前检测到的最大视频区域，并重新开始检测当前的最佳裁剪区域。默认值为0。
    - 这在通道标志扭曲视频区域时很有用。0表示'never reset'，并返回在播放过程中遇到的最大区域。

    - mv_threshold
    - 设置作为运动检测阈值的像素单位中的运动值。默认值为8。

    - low
    - high
    - 设置Canny阈值算法使用的低阈值和高阈值。

    - 高阈值选择“强”边缘像素，然后通过低阈值选择的“弱”边缘像素通过8连接性连接。

    - 低和高阈值必须在[0,1]范围内选择，低阈值应小于或等于高阈值。

    - 低阈值的默认值为5/255，高阈值的默认值为15/255。

    - 在文档中还提供了一些使用示例和命令，用于演示cropdetect滤镜的用法。

- 总之，cropdetect是一个在FFmpeg中用于自动检测视频裁剪尺寸的滤镜。

- 示例：
    - 找到被黑色边框包围的视频区域：  
    ```ffmpeg -i file.mp4 -vf cropdetect,metadata=mode=print -f null -```
    - 找到嵌入的视频区域，在此之前生成运动矢量：  
    ```ffmpeg -i file.mp4 -vf mestimate,cropdetect=mode=mvedges,metadata=mode=print -f null -```
    - 找到嵌入的视频区域，使用解码器提供的运动矢量：  
    ```ffmpeg -flags2 +export_mvs -i file.mp4 -vf cropdetect=mode=mvedges,metadata=mode=print -f null - ```
- 此外，cropdetect滤镜还支持一些命令。其中之一是limit命令，它接受与对应选项相同的语法。如果指定的表达式无效，则保持其当前值。这意味着您可以在命令行中使用limit命令来动态更改cropdetect滤镜的限制参数。

##### cue 过滤器
- 该过滤器允许延迟视频过滤直到特定的墙钟时间戳。过滤器首先传递指定数量的"preroll"帧，然后缓冲最多指定数量的帧并等待"cue"。达到"cue"后，它会转发缓冲的帧以及接收到的后续帧。
- 这个过滤器可用于实时输出设备（如decklink）的多个ffmpeg进程的输出同步。通过在过滤链中延迟处理并预先缓冲帧，进程可以在达到目标墙钟时间戳后几乎立即将数据传递到输出。
- 无法保证完全的帧准确性，但对于某些用例来说，结果足够好。
- 以下是该过滤器的参数说明：
    - cue：以微秒为单位表示的UNIX时间戳，表示等待的时间戳。默认值为0。
    - preroll：以秒为单位表示的要传递作为预备的内容的持续时间。默认值为0。
    - buffer：以秒为单位表示的在等待cue之前缓冲的内容的最大持续时间。默认值为0。
- 示例：
    - 当我们观看电影时，有时候希望音频和视频有一个延迟，例如在电影开始后几秒钟才开始播放背景音乐。
    ```ffmpeg -i video.mp4 -i audio.mp3 -filter_complex "[1:a]adelay=10000|10000[a];[0:v][a]sync=0:v=0:a=1[v]" -map "[v]" -map "[a]" output.mp4```

##### curves 滤镜
- curves滤镜用于应用颜色调整，类似于Adobe Photoshop和GIMP中的曲线工具。它允许您通过定义曲线上的关键点来调整图像的颜色。
- 每个颜色分量（红色、绿色和蓝色）都有自己的关键点，通过平滑的曲线将它们连接起来。x轴表示输入帧的像素值，y轴表示要设置为输出帧的新像素值。
- 默认情况下，组成曲线的两个关键点是（0;0）和（1;1）。这创建了一条直线，其中每个原始像素值都"调整"为其自身的值，这意味着图像没有变化。
- 该滤镜允许您重新定义这两个关键点并添加更多关键点。新的曲线将平滑地通过所有这些新坐标点。新定义的点需要严格按照x轴递增，并且它们的x和y值必须在[0;1]的区间内。曲线使用自然或单调样条插值来形成，取决于interp选项（默认为natural）。自然样条产生较平滑的曲线，而单调样条保证指定点之间的过渡是单调的。如果计算出的曲线超出了向量空间，值将被相应地截断。
- 该滤镜接受以下选项：
    - preset：选择可用的颜色预设之一。这个选项可以与r、g、b参数一起使用；在这种情况下，后面的选项优先于预设值。可用的预设包括：'none'、'color_negative'、'cross_process'、'darker'、'increase_contrast'、'lighter'、'linear_contrast'、'medium_contrast'、'negative'、'strong_contrast'和'vintage'。默认为none。
    - master, m：设置主关键点。这些点将定义第二次映射，有时称为"亮度"或"value"映射。它可以与r、g、b或all一起使用，因为它的作用类似于后处理的查找表（LUT）。
    - red, r：设置红色分量的关键点。
    - green, g：设置绿色分量的关键点。
    - blue, b：设置蓝色分量的关键点。
    - all：设置所有分量的关键点（不包括master）。可以与其他关键点组件选项一起使用。在这种情况下，未设置的分量将使用all设置。 
    - psfile：指定要导入设置的Photoshop曲线文件（.acv）。
    - plot：在指定的文件中保存曲线的Gnuplot脚本。
    - interp：指定插值类型。可用的算法有'natural'（自然样条插值）和'pchip'（单调样条插值）。
- curves滤镜支持与选项相同的命令。
- 以下是一些示例用法：
    - 增加蓝色通道的中间级别：  
    ```curves=blue='0/0 0.5/0.58 1/1'```  
    这个示例将轻微增加蓝色通道的中间级别。
    - Vintage（复古）效果：  
    ```curves=r='0/0.11 .42/.51 1/0.95':g='0/0 0.50/0.48 1/1':b='0/0.22 .49/.44 1/0.8'```  
    这个示例使用一组坐标点来实现Vintage效果，通过调整红色、绿色和蓝色通道的像素值。
    - 使用内置的预设实现Vintage效果：  
    ```curves=preset=vintage 或 curves=vintage```  
    这个示例使用内置的预设来实现Vintage效果。
    - 使用Photoshop预设并重新定义绿色通道的关键点：  
    ```curves=psfile='MyCurvesPresets/purple.acv':green='0/0 0.45/0.53 1/1'```  
    这个示例使用一个Photoshop曲线文件作为预设，并重新定义绿色通道的关键点。
    - 使用ffmpeg和gnuplot查看交叉处理（cross_process）配置文件的曲线：  
    ```ffmpeg -f lavfi -i color -vf curves=cross_process:plot=/tmp/curves.plt -frames:v 1 -f null - gnuplot -p /tmp/curves.plt```  
    这个示例使用ffmpeg和gnuplot来查看交叉处理配置文件的曲线。它将生成一个Gnuplot脚本，并显示曲线的图形。
- 示例：
    - 增加照片的整体亮度：  
    ```ffmpeg -i input.jpg -vf curves=all='0/0:0.5/0.7:1/1' output.jpg```

###### datascope 滤镜
- 视频数据分析滤镜，可以显示视频的部分像素的16进制值。
- 该滤镜接受以下选项：
    - size, s
    - 设置输出视频的尺寸。
    
    - x
    - 设置从哪里开始选择像素的x偏移量。
 
    - y
    - 设置从哪里开始选择像素的y偏移量。
    
    - mode
    - 设置数据显示模式，可以是以下之一：
    
    - 'mono'
    - 以白色显示黑色背景上的十六进制像素值。
    
    - 'color'
    - 以输入视频像素的颜色显示黑色背景上的十六进制像素值。

    - 'color2'
    - 以从输入视频中选择的颜色作为背景，在彩色背景上显示十六进制像素值，文本颜色会根据背景的亮暗程度自动选择。

    - axis
    - 在视频的左侧和顶部绘制行号和列号。

    - opacity
    - 设置背景的透明度。

    - format
    - 设置显示的数字格式。可以是hex（十六进制）或dec（十进制）。默认为hex（十六进制）。

    - components
    - 设置要显示的像素分量。默认情况下，会显示所有像素分量。
- 该滤镜支持与选项相同的命令，不包括size选项。这意味着可以使用与选项相同的命令来设置这些滤镜选项，而不是通过命令选项来设置他们。
- 示例：
    - 假如我们有一段视频，我们想查看视频中心区域像素的十六进制值。  
    ```ffmpeg -i input.mp4 -vf "datascope=x=320:y=240:size=320x240:mode=mono" -frames 1 output.png```

##### dctdnoiz 滤波器
- 用于在频域进行2D DCT（离散余弦变换）的图像降噪滤波器。
- 该滤波器不适用于实时处理。
- 该滤波器接受以下选项：
    - sigma, s
    - 设置噪声的标准差。
    - 该标准差定义了一个硬阈值，即3 * sigma；低于该阈值的每个DCT系数（绝对值）将被丢弃。
    - 如果需要更高级的滤波效果，请参考expr选项。
    - 默认值为0。

    - overlap
    - 设置每个块的重叠像素数。由于该滤波器可能较慢，您可能希望减小此值，以降低滤波器的效果并降低各种伪影的风险。
    - 如果重叠值不允许处理整个输入宽度或高度，则会显示警告，并且相应的边界将不会进行降噪处理。
    - 默认值为blocksize-1，这是最佳设置。

    - expr, e
    - 设置系数因子表达式。
    - 对于DCT块的每个系数，该表达式将作为系数的乘数值进行计算。
    - 如果设置了此选项，则将忽略sigma选项。
    - 系数的绝对值可以通过变量c进行访问。

    - n
    - 使用位数设置块的大小。1<<n定义了块的大小，即处理块的宽度和高度。
    - 默认值为3（8x8），可以提高到4以获得16x16的块大小。请注意，更改此设置对处理速度有巨大影响。此外，较大的块大小并不一定意味着更好的去噪效果。
- 示例：
    - 应用dctdnoiz滤波器，将噪声的标准差设置为4.5：  
    ```dctdnoiz=4.5```
    - 对DCT系数进行筛选，只保留绝对值大于等于4.5乘以3的系数：
    ```dctdnoiz=e='gte(c, 4.5*3)'```
    - 使用16x16的块大小进行强力去噪处理：
    ```dctdnoiz=15:n=4```
    - 拍摄了一段在夜晚行驶的汽车视频，由于低光照条件和摄像头噪声，视频中出现了一些可见的噪点。你想通过降噪来改善视频的质量：
    ```ffmpeg -i input.mp4 -vf "dctdnoiz=4.5" -c:a copy output.mp4```

###### deband 滤镜
- 用于去除输入视频中条纹状伪影的滤镜。它通过用参考像素的平均值替换条纹状像素来实现。
- 该滤镜接受以下选项：
    - 1thr
    - 2thr
    - 3thr
    - 4thr
    - 为每个平面设置条纹检测阈值。默认值为0.02。有效范围是0.00003到0.5。如果当前像素与参考像素之间的差异小于阈值，则将其视为条纹状。

    - range, r
    - 像素条纹检测范围。默认值为16。如果是正数，则使用范围在0到设置值之间的随机数。如果是负数，则使用绝对值。该范围定义了当前像素周围四个像素的正方形。

    - direction, d
    - 设置以弧度表示的方向，用于比较四个像素。如果是正数，则从0到设置的方向之间选择随机方向。如果是负数，则使用绝对值。例如，方向0、-PI或-2*PI将只选择同一行的像素，-PI/2将只选择同一列的像素。

    - blur, b
    - 如果启用，当前像素将与周围四个像素的平均值进行比较。默认启用。如果禁用，当前像素将与周围四个像素进行比较。只有当所有四个与周围像素的差异都小于阈值时，该像素才被视为条纹状。

    - coupling, c
    - 如果启用，仅当所有像素分量都被视为条纹状时，才会更改当前像素，例如对所有颜色分量触发了条纹检测阈值。默认禁用。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一个名为input.mp4的视频文件，其中包含一些条纹状伪影。你想使用deband滤镜来去除这些条纹，并生成一个名为output.mp4的去除条纹后的视频文件。  
    ```ffmpeg -i input.mp4 -vf "deband" -c:a copy output.mp4```

##### deblock 滤镜
- 用于去除输入视频中阻塞伪影的滤镜。它可以消除由于压缩算法或其他因素引起的图像块伪影。
- 该滤镜接受以下选项：
    - filter
    - 设置滤波器类型，可以是weak（弱滤波）或strong（强滤波）。默认为strong。这控制应用的去块滤波的类型。

    - block
    - 设置块的大小，允许的范围是4到512。默认值为8。

    - alpha
    - beta
    - gamma
    - delta
    - 设置阻塞检测阈值。允许的范围是0到1。默认值为：alpha为0.098，其余为0.05。使用更高的阈值可以提供更强的去块效果。设置alpha控制在块的确切边缘处的阈值检测。其他选项控制在边缘附近的阈值检测。每个选项用于下/上或左/右。将其中任何一个设置为0将禁用去块滤波。

    - planes
    - 设置要过滤的颜色平面。默认为过滤所有可用的平面。
- 该滤镜支持上述所有选项作为命令使用。
- 以下是使用deblock滤镜的一些示例，具体选项如下：
    - 使用弱滤波器和4像素的块大小进行去块处理：  
    ```deblock=filter=weak:block=4```
    - 使用强滤波器、4像素的块大小和自定义阈值来更好地去块：  
    ```deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05```
    - 类似于上一个示例，但仅对第一个颜色平面进行滤波：  
    ```deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05:planes=1```
    - 类似于第二个示例，但仅对第二和第三个颜色平面进行滤波：  
    ```deblock=filter=strong:block=4:alpha=0.12:beta=0.07:gamma=0.06:delta=0.05:planes=6```
- 你拍摄了一个户外的风景视频，由于低质量的压缩或传输问题，视频中出现了明显的图像块状伪影，使得整个画面看起来分块不连续。  
```ffmpeg -i input.mp4 -vf "deblock=filter=strong:block=8" -c:a copy output.mp4```

##### Decimate 滤镜
- 用于删除重复帧的滤镜，它会固定的间隔丢弃重复的帧。
- 该滤镜接受以下选项：
    - cycle
    - 设置每隔多少帧丢弃一帧。将其设置为N表示在每N帧中将丢弃一帧。默认值为5。

    - dupthresh
    - 设置重复帧检测的阈值。如果帧之间的差异度量小于或等于此值，则将其定义为重复帧。默认值为1.1。

    - scthresh
    - 设置场景变化阈值。默认值为15。

    - blockx
    - blocky
    - 设置在度量计算中使用的x和y轴块的大小。较大的块可以更好地抑制噪声，但也会较差地检测到小的运动。大小必须是2的幂。默认值为32。

    - ppsrc
    - 将主输入标记为经过预处理的输入，并激活干净源输入流。这允许对输入进行各种滤波器的预处理，以帮助度量计算，同时保持帧选择无损。当设置为1时，第一个流用于预处理的输入，第二个流是从中选择保留帧的干净源。默认值为0。

    - chroma
    - 设置是否在度量计算中考虑色度。默认值为1。

    - mixed
    - 设置输入是否仅部分包含要减少的内容。默认值为false。如果启用，视频输出流将具有可变帧率。
- 示例：
    - 录制了一个简单的动画，但由于录制设备的问题，一些帧被重复录制了，导致动画看起来不够流畅。这时可以删除重复帧，使画面流畅播放：
    ```ffmpeg -i input.mp4 -vf "decimate" -c:a copy output.mp4```

##### Dedot 滤镜
- 用于减少视频中交叉亮度（点爬行）和交叉颜色（彩虹）的滤镜。
- 它接受以下选项：
    - m
    - 设置操作模式。可以是dotcrawl（用于减少交叉亮度）和/或rainbows（用于减少交叉颜色）的组合。

    - lt
    - 设置空间亮度阈值。较低的值增加了对交叉亮度的减少程度。
     
    - tl
    - 设置时间亮度容忍度。较高的值增加了对交叉亮度的减少程度。
  
    - tc
    - 设置色度的时间变化容忍度。较高的值增加了对交叉颜色的减少程度。
 
    - ct
    - 设置时间色度阈值。较低的值增加了对交叉颜色的减少程度。
- 示例：
    - 当从老式的VHS录像带中转录了一个视频，录像带上存在交叉亮度和交叉颜色的问题，导致视频画面出现点爬行和彩虹状的颜色。  
    ```ffmpeg -i input.mp4 -vf "dedot=m=dotcrawl+rainbows" -c:a copy output.mp4```

##### deflate 滤镜
- 可以将"deflate"效果应用到视频中。
- 该滤镜通过将像素替换为周围像素的局部（3x3）平均值，只考虑比该像素值低的像素。
- 它接受以下选项：
    - threshold0：限制第一个颜色平面（Y平面）的最大变化。
    - threshold1：限制第二个颜色平面（U/Cb平面）的最大变化。
    - threshold2：限制第三个颜色平面（V/Cr平面）的最大变化。
    - threshold3：限制透明通道（如果存在）的最大变化。
    - 每个平面的默认最大变化限制为65535。如果将某个阈值设置为0，该平面将保持不变。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一个名为input.mp4的视频文件，其中包含一些画面细节过于清晰的问题，使得视频看起来不够自然。你希望应用"deflate"滤镜来减少画面的清晰度，以获得一种更柔和的效果。  
    ```ffmpeg -i input.mp4 -vf "deflate=threshold0=20000:threshold1=15000:threshold2=10000" output.mp4```

##### deflicker 滤镜
- 用于去除视频中的时间帧亮度变化的滤镜。
- 它接受以下选项：
    - size（大小）, s：设置移动平均滤波器的帧大小。默认值为5，允许的范围是2到129。
    - mode（模式）, m：将平均模式设置为平滑时间亮度变化。
- 可用的取值有：
    - 'am'：算术平均
    - 'gm'：几何平均
    - 'hm'：调和平均
    - 'qm'：平方平均
    - 'cm'：立方平均
    - 'pm'：幂平均
    - 'median'：中值
    - bypass（旁路）：不实际修改帧。当只需要元数据时很有用。
- 示例：
    - 假如你正在拍摄一个日出的时间-lapse视频，而天空中的云朵会导致视频中的亮度变化。这种亮度变化会使得视频中的每一帧看起来闪烁不稳定。  
    ```ffmpeg -i input.mp4 -vf deflicker=size=5:mode=am output.mp4```

##### dejudder 滤镜
- 用于去除部分交错电影内容产生的颤动效果的滤镜。
- 颤动效果通常由pullup滤镜引入。如果原始源是部分交错的电影内容，那么pullup和dejudder的输出将具有可变的帧率。这可能会改变容器的记录帧率。除了这种变化外，该滤镜不会影响恒定帧率的视频。
- 该滤镜提供了以下选项：
    - cycle（周期）：指定颤动重复的窗口长度。
- 可接受大于1的任何整数。常用的取值为：
    - '4'：如果原始内容是从24帧到30帧的电影（从Film转换到NTSC）。
    - '5'：如果原始内容是从25帧到30帧的电影（从PAL转换到NTSC）。
    - '20'：如果是两者的混合。
    - 默认值为 '4';
- 通过使用dejudder滤镜，可以处理部分交错电影内容中的颤动效果，使视频看起来更加平滑和稳定。
- 示例：
    - 假设你有一部电影，它是以24帧每秒的速度拍摄的，但在转换为NTSC格式时被部分交错。这可能导致播放时出现颤动。为了去除这种颤动效果，你可以使用dejudder滤镜。  
    ```ffmpeg -i input.mp4 -vf dejudder=cycle=4 output.mp4```

##### delogo 滤镜
- 一种通过对周围像素进行简单插值来抑制电视台徽标的滤镜。只需设置一个覆盖徽标的矩形区域，徽标就会消失（有时甚至会出现更难看的东西-效果因人而异）。
- 它接受以下参数：
    - x：指定徽标的左上角坐标的x值。
    - y：指定徽标的左上角坐标的y值。
    - w：指定要清除的徽标的宽度。
    - h：指定要清除的徽标的高度。
    - show：当设置为1时，在屏幕上绘制一个绿色矩形框，以简化找到正确的x、y、w和h参数。默认值为0。
- 矩形框绘制在将要（部分）替换为插值值的最外层像素上。此矩形框外部下一个像素的值在每个方向上将用于计算矩形框内的插值像素值。
- 示例：
    - 设置一个覆盖左上角坐标为0,0，大小为100x77的矩形区域：  
    ```delogo=x=0:y=0:w=100:h=77```
    - 假设你有一个视频文件，其中包含一个电视台的标志，你希望通过"delogo"滤镜将其清除。标志位于视频的左上角，宽度为200像素，高度为100像素。  
    ```ffmpeg -i input.mp4 -vf "delogo=x=0:y=0:w=200:h=100" output.mp4```

##### derain 滤镜
- 它使用卷积神经网络从输入图像或视频中去除雨水。
- 该滤镜支持不同的模型，其中之一是Recurrent Squeeze-and-Excitation Context Aggregation Net（RESCAN），详细内容可参考论文链接：http://openaccess.thecvf.com/content_ECCV_2018/papers/Xia_Li_Recurrent_Squeeze-and-Excitation_Context_ECCV_2018_paper.pdf。
- 要使用derain滤镜，您可以在该存储库中找到训练和模型生成脚本：https://github.com/XueweiMeng/derain_filter.git。
- 该滤镜接受以下选项：
    - filter_type：此选项允许您指定要使用的滤镜类型。可接受的值为'derain'和'dehaze'。默认值为'derain'，表示derain滤镜。

    - dnn_backend：此选项允许您指定用于模型加载和执行的深度神经网络（DNN）后端。该选项可接受的值为'tensorflow'。要启用TensorFlow后端，您需要安装TensorFlow for C库。您可以参考https://www.tensorflow.org/install/lang_c上的安装说明。此外，您需要使用--enable-libtensorflow标志配置FFmpeg。

    - model：此选项允许您设置指定网络架构和参数的模型文件路径。请注意，不同的DNN后端使用不同的文件格式。对于TensorFlow，它可以加载其自己的格式文件。

##### deshake 滤镜
- 用于从手持相机、碰撞三脚架、在车辆上移动等情况下去除相机抖动。
- 该滤镜接受以下选项：
    - x、y、w、h：指定矩形区域，用于限制运动矢量的搜索范围。您可以通过设置矩形区域的左上角坐标、宽度和高度来限制运动矢量的搜索范围。这些参数与drawbox滤镜具有相同的意义，drawbox滤镜可用于可视化边界框的位置。当帧内的主体同时移动时可能会被误认为是相机运动时，这一选项非常有用。如果x、y、w和h中的任何一个或全部设置为-1，则使用整个帧。这允许在不指定运动矢量搜索的边界框的情况下设置后续选项。默认值为搜索整个帧。

    - rx、ry：指定x和y方向上的最大移动范围，范围为0-64像素。默认值为16。

    - edge：指定在帧边缘填充空白位置的像素生成方式。可用值包括：
        - 'blank, 0'：在空白位置填充零值。
        - 'original, 1'：在空白位置填充原始图像。
        - 'clamp, 2'：在空白位置填充边界值。
        - 'mirror, 3'：在空白位置填充镜像边缘。
        - 默认值为'mirror'。

    - blocksize：指定用于运动搜索的块大小。范围为4-128像素，默认值为8。

    - contrast：指定块的对比度阈值。只有对比度（最暗像素和最亮像素之间的差异）大于指定的阈值的块才会被考虑。范围为1-255，默认值为125。

    - search：指定搜索策略。可用值包括：

    - 'exhaustive, 0'：设置穷举搜索。
    - 'less, 1'：设置较少穷举搜索。
    - 默认值为'exhaustive'。

    - filename：如果设置，则详细记录运动搜索的日志将写入指定的文件。
- 示例：
    - 假设你有一段手持拍摄的视频，由于相机晃动，导致画面出现了明显的抖动。你想要使用deshake滤镜来去除视频中的相机抖动，并输出一个稳定的视频文件。  
    ```ffmpeg -i input.mp4 -vf "deshake" output.mp4```

##### deshill 滤镜
- 用于去除绿幕或蓝幕反射颜色导致的前景颜色污染。当使用绿幕或蓝幕拍摄时，前景元素可能会受到背景颜色的反射影响，导致颜色污染。deshill滤镜可以帮助消除这种颜色污染，使前景颜色更加真实和自然。
- 该滤镜接受以下选项：
- 该滤镜接受以下选项：
    - type：设置要使用的去色污类型。

    - mix：设置如何生成去色污图。
    
    - expand：设置进一步去除余留污染的程度。
    
    - red：控制污染区域中红色的数量。
    
    - green：控制污染区域中绿色的数量。对于绿幕应设置为-1。
    
    - blue：控制污染区域中蓝色的数量。对于蓝幕应设置为-1。
    
    - brightness：控制污染区域的亮度，同时保持颜色。
    
    - alpha：修改生成的去色污图的alpha通道。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 去除绿幕反射的颜色：  
    ```ffmpeg -i input.mp4 -vf "deshill=type=default:green=-1" -c:a copy deshilled.mp4```
- 该滤镜不确定能不能正常使用，我在使用的时候提示该没有该滤镜。

##### detelecine 滤镜
- 用于应用与telecine操作完全相反的操作。它需要使用pattern选项指定预定义的模式，该模式必须与传递给telecine滤镜的模式相同。
- 该滤镜接受以下选项：
    - first_field：指定首个场的顺序。
        - 'top'或't'：顶场先。
        - 'bottom'或'b'：底场先。
        - 默认值为top。

    - pattern：表示要应用的pulldown模式的数字字符串。

    - start_frame：表示第一帧相对于telecine模式的位置的数字。如果流被剪辑了，则可以使用此选项。默认值为0。
- 示例：
    - 假设你有一个视频文件，该视频是通过将24帧/秒的电影转换为29.97帧/秒的电视传输来进行电视化处理的。现在你想要恢复原始的24帧/秒的电影帧率。你可以使用FFmpeg中的detelecine滤镜来应用与电视化操作完全相反的操作。  
    ```ffmpeg -i input.mp4 -vf "detelecine=pattern=23" output.mp4```

##### dilation 滤镜
- 在视频上应用了膨胀效果，它将每个像素替换为3x3邻域内的局部最大值。
- 该滤镜接受以下选项：
    - threshold0、threshold1、threshold2、threshold3：这些选项限制每个颜色平面的最大变化。默认值为65535。如果设置为0，该平面将保持不变。

    - coordinates：该标志指定膨胀操作所参考的像素。默认值为255，表示使用周围的八个像素。

    - 3x3的局部坐标与标志的映射如下：  
        1 2 3  
        4 5 6  
        7 8 9  
- 该滤镜支持上述所有选项作为命令使用。
    - 假设你有一个视频文件，你希望为该视频应用一种特殊效果，使图像看起来更加模糊和扩散。  
    ```ffmpeg -i input.mp4 -vf "dilation=threshold0=10000" output.mp4```
    
##### displace 滤镜
- 通过第二个和第三个输入流指示的位移图来位移像素。
- 它接受三个输入流并输出一个流，其中第一个输入是源图像，第二个和第三个输入是位移图。
- 第二个输入指定了沿x轴位移像素的量，而第三个输入指定了沿y轴位移像素的量。如果位移图流中的某一个提前结束，将使用该位移图的最后一帧。
- 请注意，一旦生成位移图，可以一次又一次地重复使用它们。
- 该滤镜接受以下选项：
    - edge
    - 设置超出范围的像素的位移行为。
    - 可用的值为：
        - 'blank'
        - 缺失的像素将被替换为黑色像素。
        
        - 'smear'
        - 相邻的像素将扩散以替换缺失的像素。
        
        - 'wrap'
        - 超出范围的像素将被包装，指向另一侧的像素。
        
        - 'mirror'
        - 超出范围的像素将被镜像替换。
        
        - 默认值为'smear'。
- 示例：
    - 添加波纹效果到分辨率为hd720的视频的RGB输入：  
    ```ffmpeg -i INPUT -f lavfi -i nullsrc=s=hd720,lutrgb=128:128:128 -f lavfi -i nullsrc=s=hd720,geq='r=128+30*sin(2*PI*X/400+T):g=128+30*sin(2*PI*X/400+T):b=128+30*sin(2*PI*X/400+T)' -lavfi '[0][1][2]displace' OUTPUT```
    - 添加波浪效果到分辨率为hd720的视频的RGB输入：  
    ```ffmpeg -i INPUT -f lavfi -i nullsrc=hd720,geq='r=128+80*(sin(sqrt((X-W/2)*(X-W/2)+(Y-H/2)*(Y-H/2))/220*2*PI+T)):g=128+80*(sin(sqrt((X-W/2)*(X-W/2)+(Y-H/2)*(Y-H/2))/220*2*PI+T)):b=128+80*(sin(sqrt((X-W/2)*(X-W/2)+(Y-H/2)*(Y-H/2))/220*2*PI+T))' -lavfi '[1]split[x][y],[0][x][y]displace' OUTPUT```

##### dnn_classify 滤镜
- 可以基于边界框使用深度神经网络进行分类。
- 它接受以下选项来配置其行为：
    - dnn_backend：指定用于模型加载和执行的DNN后端。目前仅支持"openvino"后端，将来还会添加TensorFlow后端。
    - model：设置模型文件的路径，该文件指定了网络架构和参数。不同的后端可能使用不同的文件格式。
    - input：设置DNN网络的输入层名称。
    - output：设置DNN网络的输出层名称。
    - confidence：设置分类结果的置信度阈值，默认值为0.5。
    - labels：设置标签文件的路径，该文件指定了标签ID和名称之间的映射关系。每个标签名称应该单独占据一行，尾随的空格和空行会被跳过。如果未提供标签文件，则标签ID将被视为标签名称。
    - backend_configs：设置要传递给后端的特定于后端的配置。
- 对于TensorFlow后端，您可以使用sess_config选项来设置其配置。您可以使用tools/python/tf_sess_config.py脚本获取适合您系统的配置。

##### dnn_processing 滤镜
- 该滤镜进行深度神经网络图像处理时。
- 它接受以下选项：
    - dnn_backend：指定用于模型加载和执行的DNN后端。有两个选项可供选择：
        - tensorflow：此后端需要安装TensorFlow for C库。您可以按照https://www.tensorflow.org/install/lang_c中的说明进行安装。安装完成后，使用`--enable-libtensorflow`选项配置FFmpeg。
        - openvino：此后端需要安装OpenVINO for C库。您可以按照https://github.com/openvinotoolkit/openvino/blob/master/build-instruction.md中的说明进行构建和安装。安装完成后，使用`--enable-libopenvino`选项配置FFmpeg。如果头文件和库未安装在系统路径中，则可能需要使用`--extra-cflags=-I...`和`--extra-ldflags=-L...`指定包含和库路径。
    - model：设置模型文件的路径，该文件指定了网络的架构和参数。请注意，不同的后端使用不同的文件格式。TensorFlow和OpenVINO后端可以加载特定格式的文件。

    - input：设置DNN网络的输入名称。这指定了网络的输入层或张量。

    - output：设置DNN网络的输出名称。这指定了网络的输出层或张量。

    - backend_configs：设置要传递给后端的配置。此选项允许您指定后端特定的配置。例如，您可以将async设置为启用异步执行（如果后端支持）。默认情况下，该值设置为set，表示如果可用，则使用异步执行，如果不支持则回退到同步执行。
- 示例：
    - 去除RGB24帧中的雨滴（使用can.pb模型，参见derain滤镜）：  
    ```ffmpeg -i rain.jpg -vf format=rgb24,dnn_processing=dnn_backend=tensorflow:model=can.pb:input=x:output=y derain.jpg```
    - 处理YUV420P格式的帧的Y通道（支持平面YUV格式），使用srcnn.pb模型（参见sr滤镜）：  
    ```ffmpeg -i 480p.jpg -vf format=yuv420p,scale=w=iw*2:h=ih*2,dnn_processing=dnn_backend=tensorflow:model=srcnn.pb:input=x:output=y -y srcnn.jpg```
    - 处理YUV420P格式的帧的Y通道（支持平面YUV格式），使用espcn.pb模型（参见sr滤镜），并更改帧大小。请使用tools/python/tf_sess_config.py脚本获取适用于您系统的TensorFlow后端配置：  
    ```ffmpeg -i 480p.jpg -vf format=yuv420p,dnn_processing=dnn_backend=tensorflow:model=espcn.pb:input=x:output=y:backend_configs=sess_config=0x10022805320e09cdccccccccccec3f20012a01303801 -y tmp.espcn.jpg```

##### drawbox 滤镜
- 可以在输入图像上绘制一个彩色的矩形框。
- 它接受以下参数：
    - x和y：指定矩形框左上角的坐标表达式。默认为0。
    - width和w：指定矩形框的宽度表达式。如果设置为0，将使用输入图像的宽度。默认为0。
    - height和h：指定矩形框的高度表达式。如果设置为0，将使用输入图像的高度。默认为0。
    - color和c：指定绘制矩形框的颜色。有关此选项的语法，请参阅FFmpeg手册中的"Color"部分。如果使用特殊值"invert"，则矩形框的边缘颜色与视频颜色相同，但亮度取反。
    - thickness和t：指定矩形框边缘的厚度表达式。如果设置为"fill"，将创建一个填充的矩形框。默认值为3。
    - replace：适用于具有Alpha通道的输入。如果设置为1，绘制的矩形框的像素将覆盖视频的颜色和Alpha像素。默认值为0，即将矩形框组合到输入上，保持视频的Alpha通道不变。
    - 参数x、y、w、h和t是包含以下常量的表达式：
        - dar：输入的显示宽高比，等于 (w / h) * sar。
        - hsub和vsub：水平和垂直色度抽样值。例如，对于像素格式"yuv422p"，hsub为2，vsub为1。
        - in_h和ih：输入图像的高度。
        - in_w和iw：输入图像的宽度。
        - sar：输入的样本宽高比。
        - x和y：矩形框绘制的x和y偏移坐标。
        - w和h：绘制的矩形框的宽度和高度。
        - box_source：如果要使用侦测边数据中的框数据作为矩形框的源，请将box_source设置为"side_data_detection_bboxes"。
- 示例：
    - 绘制一个黑色的边框框住输入图像的边缘：  
    ```drawbox```
    - 绘制一个红色的框，并设置不透明度为50%：  
    ```drawbox=10:20:200:60:red@0.5```
    - 或者可以使用具体参数名称指定：  
    ```drawbox=x=10:y=20:w=200:h=60:color=red@0.5```
    - 填充一个粉色的矩形框：  
    ```drawbox=x=10:y=10:w=100:h=100:color=pink@0.5:t=fill```
    - 绘制一个2像素宽的红色2.40:1的遮罩：  
    ```drawbox=x=-t:y=0.5*(ih-iw/2.4)-t:w=iw+t*2:h=iw/2.4+t*2:t=2:c=red```
    - 假设你有一张名为"input.jpg"的图片，你想在图片的左上角绘制一个蓝色的边框。  
    ```ffmpeg -i input.jpg -vf "drawbox=0:0:w=iw:h=ih:color=blue:t=3" -c:a copy output.jpg```
- 这个滤镜支持与选项相同。命令接受与相应选项相同的语法。
- 这意味着可以使用命令来动态修改滤镜参数的值。如果指定的命令表达式无效，参数将保持其当前值。

##### drawgraph 滤镜
- 用于绘制图表的滤镜，它使用输入视频的元数据。
- 该滤镜接受以下选项：
    - m1：设置用于绘制图表的第一个帧的元数据键。
    - fg1：设置第一个前景色表达式。
    - m2：设置用于绘制图表的第二个帧的元数据键。
    - fg2：设置第二个前景色表达式。
    - m3：设置用于绘制图表的第三个帧的元数据键。
    - fg3：设置第三个前景色表达式。
    - m4：设置用于绘制图表的第四个帧的元数据键。
    - fg4：设置第四个前景色表达式。
    - min：设置元数据值的最小值。
    - max：设置元数据值的最大值。
    - bg：设置图表的背景颜色，默认为白色。
    - mode：设置图表的模式，可选值为'bar'、'dot'和'line'，默认为'line'。
    - slide：设置滑动模式，可选值为'frame'、'replace'、'scroll'、'rscroll'和'picture'，默认为'frame'。
    - size：设置图表视频的大小。
    - rate、r：设置输出帧率。
    - 前景色表达式可以使用以下变量：
        - MIN：元数据值的最小值。
        - MAX：元数据值的最大值。
        - VAL：当前元数据键的值。
- 以下是两个示例，演示如何使用不同的元数据源绘制图表：
    - 使用signalstats滤镜的元数据示例：  
    ```signalstats,drawgraph=lavfi.signalstats.YAVG:min=0:max=255```
    - 使用ebur128滤镜的元数据示例：  
    ```ebur128=metadata=1,adrawgraph=lavfi.r128.M:min=-120:max=5```
- 示例：
    - 使用drawgraph滤镜在视频中绘制音频波形图：  
    ```ffmpeg -i input.mp4 -filter_complex "[0:a]showwaves=s=1280x720:mode=line:colors=red[graph];[0:v][graph]overlay=0:H-h[out]" -map "[out]" -c:v libx264 -c:a copy output.mp4```

##### drawgrid 滤镜
- 在输入图像上绘制网格。
- 它接受以下参数：
    - x和y：指定网格交点的坐标。默认为0。
    - width和w：指定网格单元的宽度。如果为0，则解释为输入的宽度减去线条的宽度。默认为0。
    - height和h：指定网格单元的高度。如果为0，则解释为输入的高度减去线条的宽度。默认为0。
    - color和c：指定网格的颜色。可以使用颜色选项来设置颜色。如果使用特殊值 "invert"，则网格颜色与视频的亮度反转。
    - thickness和t：指定网格线条的粗细。默认为1。
    - replace：适用于具有alpha通道的输入。如果设置为1，绘制的网格像素将覆盖视频的颜色和alpha值。默认为0，即将网格合成到输入上，保持视频的alpha通道不变。
    - 其中，参数x、y、w、h和t可以使用以下常量：
    - dar：输入的显示宽高比，等同于(w / h) * sar。
    - hsub和vsub：水平和垂直的色度子采样值。
    - in_h和ih：输入的网格单元宽度和高度。
    - in_w和iw：输入的网格单元宽度和高度。
    - sar：输入的样本宽高比。
- 示例：
    - 绘制一个100x100像素、粗细为2像素、红色透明度为50%的网格：  
    ```ffmpeg -i input.mp4 -vf "drawgrid=width=100:height=100:thickness=2:color=red@0.5" -c:v libx264 -c:a copy output.mp4```
    - 绘制一个3x3的白色网格，透明度为50%：  
    ```ffmpeg -i input.mp4 -vf "drawgrid=w=iw/3:h=ih/3:t=2:c=white@0.5" -c:v libx264 -c:a copy output.mp4```
- 滤镜支持与选项相同的命令。命令接受与相应选项相同的语法。
- 如果指定的表达式无效，那么参数会保持当前的值。

##### drawtext 滤镜
- 在视频上方绘制文本字符串或文本文件的滤镜，使用libfreetype库。
- 要启用此滤镜的编译，需要使用--enable-libfreetype和--enable-libharfbuzz选项配置FFmpeg。要启用默认字体回退和字体选项，需要使用--enable-libfontconfig选项配置FFmpeg。要启用text_shaping选项，需要使用--enable-libfribidi选项配置FFmpeg。
- 语法：
- 它接受以下参数：
    - box
    - 用于使用背景颜色绘制文本周围的框。该值必须为1（启用）或0（禁用）。box的默认值为0。

    - boxborderw
    - 设置要使用boxcolor绘制的框的边框宽度。该值必须使用以下格式之一指定：

    - boxborderw=10将所有边框的宽度设置为10
    - boxborderw=10|20将顶部和底部边框的宽度设置为10，将左侧和右侧边框的宽度设置为20
    - boxborderw=10|20|30将顶部边框的宽度设置为10，将底部边框的宽度设置为30，将左侧和右侧边框的宽度设置为20
    - boxborderw=10|20|30|40将边框宽度设置为10（顶部），20（右侧），30（底部），40（左侧）
    - boxborderw的默认值为"0"。

    - boxcolor
    - 用于绘制围绕文本的框的颜色。有关此选项的语法，请参阅ffmpeg-utils手册中的"Color"部分。

    - boxcolor的默认值为"white"。

    - line_spacing
    - 设置行间距（以像素为单位）。line_spacing的默认值为0。

    - text_align
    - 设置文本相对于框边界的垂直和水平对齐方式。该值是标志的组合，一个用于垂直对齐（T=top，M=middle，B=bottom），一个用于水平对齐（L=left，C=center，R=right）。请注意，制表符字符仅支持左对齐。

    - y_align
    - 指定y值所参考的内容。可能的值为：

    - text：第一行文本的最高字形的顶部放置在y处
    - baseline：第一行文本的基线放置在y处
    - font：第一行文本的基线放置在y加上字体度量中定义的上升部分（以像素为单位）
    - y_align的默认值为"text"，以保持向后兼容性。

    - borderw
    - 设置要使用bordercolor绘制的文本周围的边框宽度。borderw的默认值为0。

    - bordercolor
    - 设置用于绘制文本周围边框的颜色。有关此选项的语法，请参阅ffmpeg-utils手册中的"Color"部分。

    - bordercolor的默认值为"black"。

    - expansion
    - 选择如何展开文本。可以是none、strftime（已弃用）或normal（默认值）。有关详细信息，请参阅下面的文本展开部分。

    - basetime
    - 为计数器设置一个起始时间。值以微秒为单位。仅在已弃用的strftime展开模式中应用。要在normal展开模式中模拟，请使用pts函数，并将起始时间（以秒为单位）作为第二个参数。

    - fix_bounds
    - 如果为true，则检查和修正文本坐标以避免剪裁。

    - fontcolor
    - 用于绘制字体的颜色。有关此选项的语法，请参阅ffmpeg-utils手册中的"Color"部分。

    - fontcolor的默认值为"black"。

    - fontcolor_expr
    - 与text相同的方式展开字符串，以获得动态的fontcolor值。默认情况下，此选项为空值且不会处理。当设置了此选项时，它会覆盖fontcolor选项。

    - font
    - 用于绘制文本的字体系列。默认为Sans。

    - fontfile
    - 用于绘制文本的字体文件。必须包含路径。如果禁用了fontconfig支持，则此参数是强制性的。

    - alpha
    - 应用alpha混合后绘制文本。该值可以是介于0.0和1.0之间的数字。表达式还接受相同的变量x、y。默认值为1。请参阅fontcolor_expr。

    - fontsize
    - 用于绘制文本的字体大小。fontsize的默认值为16。

    - text_shaping
    - 如果设置为1，尝试在绘制文本之前对文本进行形状处理（例如，颠倒从右到左的文本顺序并连接阿拉伯字符）。否则，只是按照给定的方式绘制文本。默认值为1（如果支持）。

    - ft_load_flags
    - 用于加载字体的标志。

    - 这些标志映射到libfreetype支持的相应标志，可以是以下值的组合：
        - default
        - no_scale
        - no_hinting
        - render
        - no_bitmap
        - vertical_layout
        - force_autohint
        - crop_bitmap
        - pedantic
        - ignore_global_advance_width
        - no_recurse
        - ignore_transform
        - monochrome
        - linear_design
        - no_autohint
        - 默认值为"default"。
        - shadowcolor（阴影颜色）：用于绘制文本阴影的颜色。默认值为"black"（黑色）。可以使用FFmpeg手册中的"Color"部分中指定颜色的语法。

    - boxw（框宽度）：设置绘制文本周围框的宽度。默认情况下，该值会自动计算以匹配文本的宽度。

    - boxh（框高度）：设置绘制文本周围框的高度。默认情况下，该值会自动计算以匹配文本的高度。

    - shadowx（阴影水平偏移量）：相对于文本位置，指定文本阴影的水平偏移量。默认值为0。

    - shadowy（阴影垂直偏移量）：相对于文本位置，指定文本阴影的垂直偏移量。默认值为0。

    - start_number（起始帧编号）：设置n/frame_num变量的起始帧编号。默认值为0。

    - tabsize（制表符大小）：设置渲染制表符时的大小（以空格数表示）。默认值为4。

    - timecode（时间码）：以"hh:mm:ss[:;.]ff"格式设置初始时间码表示。可以与text参数一起使用，也可以单独使用。必须同时指定timecode_rate选项。

    - timecode_rate（时间码帧率）：设置时间码的帧率（仅适用于时间码表示）。值将四舍五入为最接近的整数。最小值为1。支持帧率为30和60的拍子时间码。

    - tc24hmax（24小时时间码环绕）：如果设置为1，时间码选项的输出将在24小时时环绕。默认值为0（禁用）。

    - text（文本字符串）：指定要绘制的文本字符串。文本必须是UTF-8编码的字符序列。如果未使用textfile参数指定文件，则此参数是必需的。

    - textfile（文本文件）：指定包含要绘制的文本的文本文件。文本必须是UTF-8编码的字符序列。如果未使用text参数指定文本字符串，则此参数是必需的。如果同时指定了text和textfile，将会引发错误。

    - text_source（文本源）：如果要使用边缘数据的检测边界框中的文本数据，则将文本源设置为"side_data_detection_bboxes"。如果设置了文本源，将忽略text和textfile参数，并使用边缘数据的检测边界框中的文本数据。如果对文本源不确定，请不要使用此参数。

    - reload（重新加载文本文件）：指定在指定的帧间隔重新加载文本文件。范围为0到INT_MAX。请确保以原子方式更新文本文件，以避免部分读取或失败。默认值为0。

    - x和y（绘制偏移量）：表达式，用于指定文本在视频帧中绘制的偏移量。这些表达式是相对于输出图像的左上边界的。x和y的默认值都为0。

    - dar： 输入显示宽高比，它与（w / h）* sar相同。

    - hsub：水平色度子采样值。

    - vsub：垂直色度子采样值。

    - line_h、lh：每行文本的高度。

    - main_h、h、H：输入的高度。

    - main_w、w、W：输入的宽度。

    - max_glyph_a、ascent：所有渲染的字形中，基线到最高/上部网格坐标的最大距离。由于网格的定向与Y轴向上，它是一个正值。

    - max_glyph_d、descent：所有渲染的字形中，基线到最低/下部网格坐标的最大距离。由于网格的定向与Y轴向上，它是一个负值。

    - max_glyph_h：最大字形高度，即渲染文本中所有字形的最大高度，等于ascent - descent。

    - max_glyph_w：最大字形宽度，即渲染文本中所有字形的最大宽度。

    - font_a：字体度量中定义的上升大小。

    - font_d：字体度量中定义的下降大小。

    - top_a：第一行文本中字形的最大上升高度。

    - bottom_d：最后一行文本中字形的最大下降高度。

    - n：输入帧的数量，从0开始计数。

    - rand(min, max)：返回介于min和max之间的随机数。

    - sar：输入样本宽高比。

    - t：时间戳，以秒为单位表示，如果输入的时间戳未知，则为NAN。

    - text_h、th：渲染文本的高度。

    - text_w、tw：渲染文本的宽度。

    - x、y：文本绘制的偏移坐标。

    - 这些参数允许x和y表达式相互引用，因此您可以指定y=x/dar等关系。

    - pict_type：当前帧图像类型的单个字符描述。

    - pkt_pos：当前数据包在输入文件或流中的位置（以字节为单位，从输入的开始计算）。值为-1表示此信息不可用。

    - duration：当前数据包的持续时间，以秒为单位。

    - pkt_size：当前数据包的大小（以字节为单位）。
- 文本扩展：
    - 这个功能已被弃用，推荐使用gmtime或localtime扩展函数进行正常的展开。

    - 如果扩展设置为none，则文本将原样打印。

    - 如果扩展设置为normal（默认值），则使用以下展开机制：

    - 反斜杠字符“\”后面跟随任意字符，总是展开为第二个字符。

    - 形式为%{...}的序列将被展开。大括号之间的文本是一个函数名，可能后面跟着以“:”分隔的参数。如果参数包含特殊字符或分隔符（“:”或“}”），它们应该被转义。

    - 请注意，它们可能还必须作为滤镜参数字符串中text选项的值以及滤镜图描述中的滤镜参数进行转义，还可能需要为shell进行转义，这就涉及到四个级别的转义；使用具有textfile选项的文本文件可以避免这些问题。

    - 以下函数可用：

        - expr、e：表达式的计算结果。
        - 它需要一个参数来指定要计算的表达式，该表达式接受与x和y值相同的常量和函数。请注意，并非所有常量都应该使用，例如在计算表达式时无法确定文本大小，因此常量text_w和text_h的值将是未定义的。

        - expr_int_format、eif：计算表达式的值并以格式化整数形式输出。

        - 第一个参数是要计算的表达式，就像expr函数一样。第二个参数指定输出格式。允许的值为“x”、“X”、“d”和“u”。它们的处理方式与printf函数完全一样。第三个参数是可选的，用于设置输出占据的位置数。它可以用于在左侧添加用零填充的填充。

        - gmtime：滤镜运行时的时间，以UTC表示。它可以接受一个参数：一个strftime C函数的格式字符串。该格式字符串扩展支持变量%[1-6]N，用于以可选指定的小数位数打印秒的分数部分。

        - localtime：滤镜运行时的时间，以本地时区表示。它可以接受一个参数：一个strftime C函数的格式字符串。该格式字符串扩展支持变量%[1-6]N，用于以可选指定的小数位数打印秒的分数部分。

        - metadata：帧的元数据。需要一个或两个参数。
        - 第一个参数是必需的，指定元数据键。
        - 第二个参数是可选的，指定当找不到或为空的元数据键时使用的默认值。
        - 可以通过运行ffprobe -show_frames来查看每个帧部分中包含的以TAG开头的条目来识别可用的元数据。
        - 还可以使用在导致drawtext滤镜的滤镜中生成的字符串元数据。

        - n、frame_num：帧编号，从0开始。

        - pict_type：当前图片类型的一个字符描述。

        - pts：当前帧的时间戳。它可以有多达三个参数。
        - 第一个参数是时间戳的格式，默认为flt，表示以秒为单位的小数形式，精确到微秒；hms表示格式化为[-]HH:MM:SS.mmm的时间戳，精确到毫秒。gmtime表示以UTC时间格式化的帧的时间戳；localtime表示以本地时区时间格式化的帧的时间戳。
        - 第二个参数是添加到时间戳的偏移量。
        - 如果格式设置为hms，则可以提供第三个参数24HH，以以24小时制（00-23）呈现格式化时间戳的小时部分。
        - 如果格式设置为localtime或gmtime，则可以提供第三个参数：一个strftimeC函数格式字符串。默认情况下，将使用YYYY-MM-DD HH:MM:SS格式。

- 命令。
- 该滤镜支持通过命令来更改参数：
    - reinit
    - 修改现有滤镜参数。

    - 参数的语法与滤镜调用的语法相同，例如：
        - fontsize=56:fontcolor=green:text='Hello World'
    - 使用sendcmd的完整滤镜调用如下所示：
        - sendcmd=c='56.0 drawtext reinit fontsize=56:fontcolor=green:text=Hello\ World'
        - 如果整个参数无法解析或应用为有效值，则滤镜将继续使用其现有参数。

    - 还支持以下选项作为命令：
        - x
        - y
        - alpha
        - fontsize
        - fontcolor
        - boxcolor
        - bordercolor
        - shadowcolor
        - box
        - boxw
        - boxh
        - boxborderw
        - line_spacing
        - text_align
        - shadowx
        - shadowy
        - borderw

- 示例：
    - 使用默认值绘制字体为FreeSerif的"Test Text"：  
    ```drawtext="fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf: text='Test Text'"```

    - 在位置x=100和y=50（从屏幕左上角开始计数）绘制大小为24的黄色文本，并用红色边框围绕。文本和边框的不透明度都为20%：
    ```drawtext="fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf: text='Test Text': x=100: y=50: fontsize=24: fontcolor=yellow@0.2: box=1: boxcolor=red@0.2"```

    - 在视频帧的中心显示文本：  
    ```drawtext="fontsize=30:fontfile=FreeSerif.ttf:text='hello world':x=(w-text_w)/2:y=(h-text_h)/2"```

    - 在随机位置显示文本，每30秒切换到新位置：  
    ```drawtext="fontsize=30:fontfile=FreeSerif.ttf:text='hello world':x=if(eq(mod(t,30),0),rand(0,(w-text_w)),x):y=if(eq(mod(t,30),0),rand(0,(h-text_h)),y)"```

    - 在视频帧的最后一行从右向左滑动文本。假设文件LONG_LINE包含一行没有换行符的文本：  
    ```drawtext="fontsize=15:fontfile=FreeSerif.ttf:text=LONG_LINE:y=h-line_h:x=-50*t"```

    - 从视频帧底部显示文件CREDITS的内容，并向上滚动：  
    ```drawtext="fontsize=20:fontfile=FreeSerif.ttf:textfile=CREDITS:y=h-20*t"```

    - 在输入视频的中心绘制一个绿色的字母"g"。字形的基线放置在屏幕高度的一半处：  
    ```drawtext="fontsize=60:fontfile=FreeSerif.ttf:fontcolor=green:text=g:x=(w-max_glyph_w)/2:y=h/2-ascent"```

    - 要了解更多关于libfreetype的信息，请访问官方网站：http://www.freetype.org/。

    - 要获取有关fontconfig的详细信息，请查阅官方文档：http://freedesktop.org/software/fontconfig/fontconfig-user.html。

    - 要了解更多关于libfribidi的信息，请访问官方网站：http://fribidi.org/。

    - 要获取有关libharfbuzz的详细信息，请参考GitHub存储库：https://github.com/harfbuzz/harfbuzz。

##### edgedetect 滤镜
- 它使用Canny边缘检测算法。
- 该滤镜接受以下选项：
    - low
    - high
    - 设置Canny阈值算法使用的低阈值和高阈值。

    - 高阈值选择“强”边缘像素，然后通过8连通性与低阈值选择的“弱”边缘像素相连。

    - 低阈值和高阈值必须在[0,1]的范围内选择，低阈值应小于等于高阈值。

    - 低阈值的默认值为20/255，高阈值的默认值为50/255。

    - mode
    - 定义绘制模式。

    - ‘wires’
    - 在黑色背景上绘制白色/灰色线框。

    - ‘colormix’
    - 混合颜色以创建绘画/卡通效果。

    - ‘canny’
    - 在所有选定的平面上应用Canny边缘检测器。

    - 默认值为wires。

    - planes
    - 选择要进行滤镜处理的平面。默认情况下，会对所有可用平面进行滤镜处理。
- 示例：
    - 使用自定义的迟滞阈值进行标准边缘检测：  
    ```edgedetect=low=0.1:high=0.4```
    - 不使用阈值的绘画效果：  
    ```edgedetect=mode=colormix:high=0```
    - 将一张名为input.jpg的图片应用边缘检测滤镜，并将结果保存为output.jpg  
    ```ffmpeg -i input.jpg -vf "edgedetect" output.jpg```

##### elbg 滤镜
- 应用ELBG（Enhanced LBG）算法的海报化效果滤镜。
- 对于每个输入图像，该滤镜将根据码书长度计算从输入到输出的最佳映射，即不同输出颜色的数量。
- 该滤镜接受以下选项：
    - codebook_length, l
    - 设置码书长度。该值必须是一个正整数，代表不同输出颜色的数量。默认值为256。

    - nb_steps, n
    - 设置计算最佳映射的最大迭代次数。值越高，结果越好，但计算时间也会增加。默认值为1。

    - seed, s
    - 设置随机种子，必须是介于0和UINT32_MAX之间的整数。如果未指定或显式设置为-1，滤镜将尽力使用一个好的随机种子。

    - pal8
    - 设置pal8输出像素格式。此选项不适用于码书长度大于256的情况。默认禁用。

    - use_alpha
    - 在量化计算中包括alpha值。允许创建带有多个alpha平滑混合的调色板输出图像（例如PNG8）。
- 示例：
    - 将一段名为input.mp4的视频应用的海报化效果，并将结果保存为output.mp4  
    ```ffmpeg -i input.mp4 -vf "elbg" output.mp4```

##### entropy 滤镜
- 用于测量视频帧颜色通道直方图中灰色值熵的滤镜。
- 它接受以下参数：
    - mode
    - 可以是normal或diff。默认值为normal。
    - diff模式测量直方图增量值的熵，即相邻直方图值之间的绝对差异。
- 示例：
    - 对一段名为input.mp4的视频测量每个视频帧颜色通道直方图的灰度值熵，并将结果输出到文本文件。  
    ```ffmpeg -i input.mp4 -vf "entropy" -f null -```

##### epx 滤镜
- 应用于像素艺术的EPX放大滤镜。
- 它接受以下选项：
    - n
    - 设置缩放维度：2表示2xEPX，3表示3xEPX。默认值是3。
- 示例：
    - 将一段名为input.mp4的视频应用2xEPX放大滤镜，并将结果保存为output.mp4。  
    ```ffmpeg -i input.mp4 -vf "epx=n=2" output.mp4```

##### eq 滤镜
- 用于设置亮度、对比度、饱和度和近似伽马调整的滤镜。
- 该滤镜接受以下选项：
    - contrast
    - 设置对比度表达式。该值必须是范围在-1000.0到1000.0之间的浮点数。默认值为"1"。

    - brightness
    - 设置亮度表达式。该值必须是范围在-1.0到1.0之间的浮点数。默认值为"0"。

    - saturation
    - 设置饱和度表达式。该值必须是范围在0.0到3.0之间的浮点数。默认值为"1"。

    - gamma
    - 设置伽马表达式。该值必须是范围在0.1到10.0之间的浮点数。默认值为"1"。

    - gamma_r
    - 设置红色通道的伽马表达式。该值必须是范围在0.1到10.0之间的浮点数。默认值为"1"。

    - gamma_g
    - 设置绿色通道的伽马表达式。该值必须是范围在0.1到10.0之间的浮点数。默认值为"1"。

    - gamma_b
    - 设置蓝色通道的伽马表达式。该值必须是范围在0.1到10.0之间的浮点数。默认值为"1"。

    - gamma_weight
    - 设置伽马权重表达式。它可以用于减少高伽马值对亮度图像区域的影响，例如防止它们过度放大并变成纯白色。该值必须是范围在0.0到1.0之间的浮点数。0.0的值将完全关闭伽马校正，而1.0将保持完整强度。默认值为"1"。

    - eval
    - 设置何时评估亮度、对比度、饱和度和伽马表达式。

    - 它接受以下值：

        - 'init'
        - 仅在滤镜初始化或处理命令时评估表达式一次。

        - 'frame'
        - 对每个输入帧评估表达式。

        - 默认值为'init'。

        - 表达式接受以下参数：

        - n
        - 从0开始的输入帧的帧计数。

        - pos
        - 输入文件中相应数据包的字节位置，如果未指定则为NAN；已弃用，请勿使用。

        - r
        - 输入视频的帧率，如果输入帧率未知，则为NAN。

        - t
        - 以秒为单位的时间戳，如果输入时间戳未知，则为NAN。
- 命令。
- 该滤镜支持以下命令：
    - contrast
    - 设置对比度表达式。
    
    - brightness
    - 设置亮度表达式。
    
    - saturation
    - 设置饱和度表达式。
    
    - gamma
    - 设置伽马表达式。
    
    - gamma_r
    - 设置红色通道的伽马表达式。
    
    - gamma_g
    - 设置绿色通道的伽马表达式。
    
    - gamma_b
    - 设置蓝色通道的伽马表达式。
    
    - gamma_weight
    - 设置伽马权重表达式。
    
    - 这些命令接受与相应选项相同的语法。
    
    - 如果指定的表达式无效，则保持其当前值不变。
- 示例：
    - 将名为input.mp4的视频应用以下调整效果：对比度增加50%，亮度降低20%，饱和度增加25%，伽马值设置为0.8。  
    ```ffmpeg -i input.mp4 -vf "eq=contrast=1.5:brightness=-0.2:saturation=1.25:gamma=0.8" output.mp4```

##### erosion 滤镜
- 应用侵蚀效果到视频的滤镜。
- 该滤镜通过局部（3x3）最小值来替换像素。
- 它接受以下选项：
    - threshold0
    - threshold1
    - threshold2
    - threshold3
        - 限制每个平面的最大变化，默认值为65535。如果设为0，则平面将保持不变。
    - coordinates
    - 指定要参考的像素的标志。默认值为255，即使用所有八个像素。
    - 局部3x3坐标映射的标志如下：  
    1 2 3  
    4 5 6  
    7 8  
- 该滤镜支持上述所有选项作为命令使用。

##### estdif 滤镜
- 是一个去错滤镜，它使用边缘斜率追踪算法来插值缺失的行。
- 它接受以下参数：
    - mode
    - 采用的交错模式。可接受以下值之一：

    - frame
    - 每帧输出一帧。

    - field
    - 每个场输出一帧。

    - 默认值为 field。

    - parity
    - 对于输入交错视频假设的图像场奇偶性。接受以下值之一：

    - tff
    - 假设顶部场先行。

    - bff
    - 假设底部场先行。

    - auto
    - 启用自动检测场奇偶性。

    - 默认值为 auto。如果交错方式未知或解码器未导出此信息，则默认假设为顶部场先行。

    - deint
    - 指定要去交错的帧。接受以下值之一：
        - all
        - 去交错所有帧。

        - interlaced
        - 仅去交错标记为交错的帧。
            - 默认值为 all。
        - rslope
        - 指定边缘斜率追踪的搜索半径。默认值为 1。允许的范围是从 1 到 15。
        
        - redge
        - 指定最佳边缘匹配的搜索半径。默认值为 2。允许的范围是从 0 到 15。
        
        - ecost
        - 指定边缘匹配的边缘成本。默认值为 2。允许的范围是从 0 到 50。
        
        - mcost
        - 指定边缘匹配的中间成本。默认值为 1。允许的范围是从 0 到 50。
        
        - dcost
        - 指定边缘匹配的距离成本。默认值为 1。允许的范围是从 0 到 50。
        
        - interp
        - 指定所使用的插值方法。默认为四点插值。可接受以下值之一：
        
        - 2p
        - 双点插值。
        
        - 4p
        - 四点插值。
        
        - 6p
        - 六点插值。
- 该滤镜支持与选项相同的命令。
- 示例：
    - 对名为input.mp4的交错视频应用 estdif 滤镜，使用四点插值进行去交错处理。  
    ```ffmpeg -i input.mp4 -vf "estdif=interp=4p" output.mp4```

##### exposure 滤镜
- 用于调整视频流曝光。
- 该滤镜接受以下选项：
    - exposure：设置EV中的曝光校正。允许的范围是从-3.0到3.0 EV。默认值为0 EV。
    - black：设置黑电平校正。允许的范围是从-1.0到1.0。默认值为0。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 对名为input.mp4的视频应用 exposure 滤镜，增加曝光量为1.5 EV，同时进行黑电平校正为-0.5。  
    ```ffmpeg -i input.mp4 -vf "exposure=1.5:black=-0.5" output.mp4```

##### extractplanes 滤镜
- 从一个输入视频流中提取颜色通道分量到单独的灰度视频流。
- 该滤镜接受以下选项：
    - planes：设置要提取的屏幕。
    - planes 可用的取值有：
        - 'y'
        - 'u'
        - 'v'
        - 'a'
        - 'r'
        - 'g'
        - 'b'
    - 选择不在输入中的平面将导致错误。这意味着你不能同时选择 y、u、v 平面和 r、g、b 平面。
- 示例：
    - 从输入视频帧中提取亮度（Y）、色度（U）和色度（V）颜色通道分量，并将它们分别保存为三个灰度输出视频：y.avi、u.avi 和 v.avi。  
    ```ffmpeg -i video.avi -filter_complex 'extractplanes=y+u+v[y][u][v]' -map '[y]' y.avi -map '[u]' u.avi -map '[v]' v.avi```
- 现在可能这个滤镜不存在了。

##### fade 滤镜
- 是一个在输入视频上应用淡入/淡出效果的FFmpeg视频滤镜。
- 它接受以下参数：
    - "type" 或 "t"：效果类型，可以是 "in" 表示淡入效果，或 "out" 表示淡出效果。默认为 "in"。
    - "start_frame" 或 "s"：指定开始应用淡入/淡出效果的帧编号。默认为 0。
    - "nb_frames" 或 "n"：淡入/淡出效果持续的帧数。在淡入效果结束时，输出视频将与输入视频具有相同的强度。在淡出过渡结束时，输出视频将被填充为所选颜色。默认为 25。
    - "alpha"：如果设置为 1，仅对输入中存在的 alpha 通道进行淡化。默认值为 0。
    - "start_time" 或 "st"：指定应用淡入/淡出效果的时间戳（以秒为单位）。如果同时指定了 "start_frame" 和 "start_time"，将使用较后的那个值为起始点。默认为 0。
    - "duration" 或 "d"：淡入/淡出效果持续的秒数。在淡入效果结束时，输出视频将与输入视频具有相同的强度。在淡出过渡结束时，输出视频将被填充为所选颜色。如果同时指定了 "duration" 和 "nb_frames"，将使用 "duration"。默认为 0（默认情况下使用 "nb_frames"）。
    - "color" 或 "c"：淡化的颜色。可以指定为命名颜色（如 "black"、"white" 等）或十六进制代码（例如 "#FF0000" 表示红色）。默认为 "black"。
- 示例：
    - 淡入视频的前30帧：  
    ```fade=in:0:30```
    - 淡出视频的最后45帧（对于一个200帧的视频）：  
    ```fade=out:155:45```
    - 淡入视频的前25帧，并淡出视频的最后25帧（对于一个1000帧的视频）：  
    ```fade=in:0:25, fade=out:975:25```
    - 将视频的前5帧设置为黄色，并从第5帧到第24帧淡入：  
    ```fade=in:5:20:color=yellow```
    - 在视频的前25帧中淡入 alpha 通道：  
    ```fade=in:0:25:alpha=1```
    - 将视频的前5.5秒设置为黑色，并在0.5秒内淡入：
    ```fade=t=in:st=5.5:d=0.5```
    - 早晨的日出。当太阳从地平线上升起时，天空逐渐变亮，直到完全明亮起来。  
    ```ffmpeg -i input.mp4 -vf "fade=in:0:50:color=white" -c:a copy output.mp4```

##### feedback 滤镜
- 该滤镜将裁剪后的输入帧传递到第二个输出。从那里，它可以与其他视频滤镜一起使用。当滤镜接收到来自第二个输入的帧时，该帧将与来自第一个输入的原始帧叠加在一起，并传递到第一个输出。
- "feedback"滤镜的典型用法是仅对帧的部分进行滤镜处理。
- 该滤镜接受以下选项：
    - "x"和"y"：设置裁剪区域的左上角位置。
    - "w"和"h"：设置裁剪区域的宽度和高度。
- 示例：
    - 使用"gblur"滤镜对视频帧的左上角100x100大小的矩形区域进行模糊处理。  
    ```[in][blurin]feedback=x=0:y=0:w=100:h=100[out][blurout];[blurout]gblur=8[blurin]```
    - 使用"drawbox"滤镜在视频帧的左上角绘制一个大小为100x100的黑色方框。  
    ```[in][blurin]feedback=x=0:y=0:w=100:h=100[out][blurout];[blurout]drawbox=x=0:y=0:w=100:h=100:t=100[blurin]```
    - 使用"pixelize"滤镜对视频帧的大小为100x100的矩形区域进行像素化处理。  
    ```[in][blurin]feedback=x=320:y=240:w=100:h=100[out][blurout];[blurout]pixelize[blurin]```
    - 假设我们有一个名为"input.mp4"的输入视频文件，我们希望在该视频的左上角放置一个透明的水印图像，水印图像的大小为200x200。  
    ```ffmpeg -i input.mp4 -i watermark.png -filter_complex "[0:v][1:v]overlay=x=0:y=0:enable='between(t,0,10)',split=2[main][feedback];[feedback][main]feedback=x=0:y=0:w=200:h=200" output.mp4```

##### fftdnoiz 滤镜
- 这是一个在频域中进行噪声降噪的滤镜，它使用3D FFT（frequency domain filtering）进行处理。
- 该滤镜提供了一些选项来控制噪声降噪的效果：
    - sigma：设置噪声的标准差常数，用于调整降噪的强度。默认值为1，允许的范围是0到30。使用过高的sigma值可能会导致阻塞伪影，特别是在低重叠的情况下。
    - amount：设置降噪的程度。默认情况下，会减少所有检测到的噪声。默认值为1，允许的范围是0到1。
    - block：设置每个块的大小（以像素为单位）。默认值为32，可设置范围为8到256。
    - overlap：设置块之间的重叠量。默认值为0.5，允许的范围为0.2到0.8。
    - method：设置降噪的方法。默认为wiener，也可以是hard。
    - prev：设置用于降噪的前一帧数量。默认情况下为0。
    - next：设置用于降噪的后续帧数量。默认情况下为0。
    - planes：设置要进行滤波的平面，默认为除alpha通道外的所有可用平面。
- 示例：
    - 假设你有一个名为"input.mp4"的输入视频文件，并且你希望降低视频中的噪声：  
    ```ffmpeg -i input.mp4 -filter_complex "[0:v]fftdnoiz=sigma=2:amount=0.5:block=32:overlap=0.5[method];[method]split=2[main][denoised];[denoised][main]overlay" output.mp4```

##### fftfilt 滤镜
- 允许在频域中对样本应用任意表达式的滤镜。
- 该滤镜支持以下选项：
    - dc_Y：调整图像的亮度平面（luma plane）的直流值（增益）。该滤镜接受一个范围在0到1000之间的整数值。默认值为0。
    - dc_U：调整图像的第一个色度平面（chroma plane）的直流值（增益）。该滤镜接受一个范围在0到1000之间的整数值。默认值为0。
    - dc_V：调整图像的第二个色度平面（chroma plane）的直流值（增益）。该滤镜接受一个范围在0到1000之间的整数值。默认值为0。
    - weight_Y：为亮度平面设置频域权重表达式。
    - weight_U：为第一个色度平面设置频域权重表达式。
    - weight_V：为第二个色度平面设置频域权重表达式。
    - eval：设置表达式的评估方式。
        - 可以使用以下值进行设置：
            - 'init'：仅在滤镜初始化期间评估表达式一次。
            - 'frame'：对每个输入帧进行表达式评估。
            - 默认值为'init'。
    - 滤镜接受以下变量：
        - X：当前样本的X坐标。
        - Y：当前样本的Y坐标。
        - W：图像的宽度。
        - H：图像的高度。
        - N：输入帧的编号，从0开始。
        - WS：水平处理的FFT数组的大小。
        - HS：垂直处理的FFT数组的大小。
- 示例：
    - 高通滤波（High-pass）：  
    ```fftfilt=dc_Y=128:weight_Y='squish(1-(Y+X)/100)'```
    - 低通滤波（Low-pass）：  
    ```fftfilt=dc_Y=0:weight_Y='squish((Y+X)/100-1)'```
    - 锐化（Sharpen）：  
    ```fftfilt=dc_Y=0:weight_Y='1+squish(1-(Y+X)/100)'```
    - 模糊（Blur）：  
    ```fftfilt=dc_Y=0:weight_Y='exp(-4 * ((Y+X)/(W+H)))'```
    - 改变视频文本的清晰度：  
    ```ffmpeg -i input.mp4 -vf "fftfilt=dc_Y=0:weight_Y='exp(-4 * ((Y+X)/(W+H)))'" output.mp4```

##### field 滤镜
- 用于从交错图像中提取单个场（field），并使用步幅算法以避免浪费CPU时间。输出帧被标记为非交错。
- 该滤镜接受以下选项：
    - type：指定提取顶部场（如果值为0或top）还是底部场（如果值为1或bottom）。
- 示例：
    - 假设你有一个交错的视频文件，并且你希望从中提取顶部场。  
    ```ffmpeg -i input.mp4 -vf "field=type=top" output.mp4```

##### fieldhint 滤镜
- 用于根据提供的提示文件中的帧号，从周围帧中复制顶部和底部场，创建新的帧。
- 该滤镜接受以下选项：
    - hint：设置包含提示的文件的路径。文件中的每一行都必须包含两个用逗号分隔的数字，可选地后跟"-"或"+"。对于绝对模式，文件中的每一行的数字不能超出[N-1,N+1]的范围，其中N是当前帧的帧号；对于相对模式，数字不能超出[-1,1]的范围。第一个数字告诉滤镜从哪一帧中获取顶部场，第二个数字告诉滤镜从哪一帧中获取底部场。如果行以"#"或";"开头，则跳过该行。
    - mode：可以是"absolute"（绝对模式）、"relative"（相对模式）或"pattern"（模式模式）。默认为"absolute"。模式模式与相对模式相同，只是在文件的最后一个条目时，如果要处理的帧数多于提示文件中的条目数，将回到文件的开头。
- 示例：
    - 以下是相对模式提示文件的前几行示例：
        - 0,0 - # 第一帧
        - 1,0 - # 第二帧，使用第三帧的顶部场和第二帧的底部场
        - 1,0 - # 第三帧，使用第四帧的顶部场和第三帧的底部场
        - 1,0 -
        - 0,0 -
        - 0,0 -
        - 1,0 -
        - 1,0 -
        - 1,0 -
        - 0,0 -
        - 0,0 -
        - 1,0 -
        - 1,0 -
        - 1,0 -
    - 假设你有一个名为"input.mp4"的输入视频文件，并且你有一个名为"hints.txt"的提示文件，其中包含了要从周围帧中复制顶部和底部场的帧号。  
    ```ffmpeg -i input.mp4 -vf "fieldhint=hint=hints.txt" output.mp4```

##### fieldmatch 滤镜
- fieldmatch是一个用于逆电影电视（inverse telecine）的场匹配滤镜。它旨在从电影电视混合流中重建出逐行扫描（progressive）帧。该滤镜不会丢弃重复的帧，因此为了实现完整的逆电影电视，fieldmatch需要在滤镜图中跟随一个像decimate这样的降帧（decimation）滤镜。
- 将场匹配（field matching）和降帧（decimation）分离开来的原因主要是为了在两者之间插入一个去交错（de-interlacing）滤镜。如果源视频中混合了逆电影电视和真实交错内容，fieldmatch将无法为交错部分匹配场。但是这些剩余的交错帧将被标记为交错，因此可以在降帧之前使用后续滤镜（如yadif）进行去交错。
- 除了各种配置选项外，fieldmatch还可以接受一个可选的第二个流，通过ppsroc选项激活。如果启用了第二个流，帧的重建将基于来自该第二个流的场和帧。这允许对第一个输入进行预处理，以帮助滤镜的各种算法，同时保持输出无损（假设场正确匹配）。通常，场感知的降噪器或亮度/对比度调整可以起到帮助作用。
- 请注意，该滤镜使用的算法与TIVTC/TFM（AviSynth项目）和VIVTC/VFM（VapourSynth项目）相同。后者是基于TFM的一个轻量级克隆，而fieldmatch则是基于VFM的。尽管语义和用法非常接近，但某些行为和选项名称可能不同。
- 目前，降帧（decimate）滤镜仅适用于恒定帧率的输入。如果您的输入中混合了逆电影电视（30fps）和帧率较低（如24fps）的逐行扫描内容，请使用以下滤镜链来生成所需的恒定帧率（cfr）流：
    - dejudder,fps=30000/1001,fieldmatch,decimate。
- 该滤镜支持以下选项：
    - order：指定输入流的假设场顺序。可用的值为：
        - 'auto'：自动检测奇偶性（使用FFmpeg的内部奇偶性值）。
        - 'bff'：假设底场优先。
        - 'tff'：假设顶场优先。
        - 请注意，有时不建议相信流中宣布的奇偶性。
        - 默认值为'auto'。
    - mode：设置匹配模式或策略。pc模式在某种意义上是最安全的，因为它在可能的情况下不会产生由重复帧引起的突兀感，但如果存在错误的编辑或混合场，则最终会输出交错帧，而实际上可能存在良好匹配的帧。另一方面，pcn_ub模式在创建突兀感方面最冒险，但几乎总能找到良好的帧。其他值在突兀感风险和创建重复帧与在具有错误编辑、孤立场、混合场等部分中找到良好匹配之间都处于pc和pcn_ub之间。
    - 有关p/c/n/u/b的更多详细信息，请参阅p/c/n/u/b含义部分。
    - 可用的值为：
        - 'pc'：强制计算p/c（前/当前）匹配的交错度量。
        - 'pc_n'：强制计算p/c（前/当前）匹配的交错度量，并尝试进行第三次匹配（带有相同的顺序），如果仍然存在交错。
        - 'pc_u'：强制计算p/c（前/当前）匹配的交错度量，并尝试进行第三次匹配（带有相同的顺序），如果仍然存在交错。
        - 'pc_n_ub'：强制计算p/c（前/当前）匹配的交错度量，并尝试进行第三次匹配，如果仍然存在交错，然后尝试进行第四次和第五次匹配。
        - 'pcn'：强制计算p/c/n（前/当前/下一个）匹配的交错度量。
        - 'pcn_ub'：强制计算p/c/n（前/当前/下一个）匹配的交错度量，并尝试进行第四次和第五次匹配，如果所有三次原始匹配都被检测为交错。
    - ppsrc：将主输入流标记为预处理输入，并启用第二个输入流作为干净源以选择场。有关更多详细信息，请参见滤镜介绍。它类似于VFM/TFM中的clip2功能。
        - 默认值为0（禁用）。
    - field：设置要匹配的场。建议将其设置为与order相同的值，除非使用该设置出现匹配失败。在某些情况下，改变用于匹配的场可能会对匹配性能产生很大影响。
    - 可用的值为：
        - 'auto'：自动（与order的值相同）。
        - 'bottom'：从底场匹配。
        - 'top'：从顶场匹配。
        - 默认值为auto。
    - mchroma：设置是否在匹配比较中包含色度。在大多数情况下，建议保持启用状态。仅当剪辑存在严重的色度问题（如严重的彩虹状或其他伪影）时，才将其设置为0。将其设置为0可能会加快处理速度，但会降低一些准确性。
        - 默认值为1。
    - y0、y1：定义一个排除带，排除y0和y1之间的行不包括在场匹配决策中。排除带可用于忽略字幕、标志或其他可能干扰匹配的内容。y0设置起始扫描行，y1设置结束行；y0和y1之间的所有行（包括y0和y1）都将被忽略。将y0和y1设置为相同的值将禁用该功能。y0和y1的默认值为0。
    - scthresh：将场景变化检测阈值设置为亮度平面上最大变化的百分比。良好的值在[8.0, 14.0]范围内。场景变化检测仅在combmatch=sc的情况下有效。scthresh的范围为[0.0, 100.0]。
        - 默认值为12.0。
    - combmatch：当combmatch不是none时，fieldmatch在决定使用哪个匹配作为最终匹配时，将考虑匹配的交错分数。可用的值为：
        - 'none'：不基于交错分数进行最终匹配。
        - 'sc'：仅在检测到场景变化时使用交错分数。
        - 'full'：始终使用交错分数。
        - 默认值为sc。
    - combdbg：强制fieldmatch计算某些匹配的交错度量并打印它们。该设置在TFM/VFM词汇中称为micout。可用的值为：
        - 'none'：不强制计算。
        - 'pcn'：强制进行p/c/n计算。
        - 'pcnub'：强制进行p/c/n/u/b计算。
        - 默认值为none。
    - cthresh：这是用于检测交错帧的交错阈值。实际上，它控制了交错必须有多“明显”或“可见”才能被检测到。较大的值意味着交错必须更明显，较小的值意味着交错可以不太明显或强烈，但仍然可以被检测到。有效设置范围为-1（每个像素都将被检测为交错）到255（没有像素会被检测为交错）。这基本上是一个像素差异值。一个好的范围是[8, 12]。
        - 默认值为9。
    - chroma：设置是否在交错帧决策中考虑色度。仅当源具有导致交错帧检测与启用色度的问题（如彩虹状等）时，才禁用此选项。实际上，使用chroma=0通常更可靠，除非源中仅存在色度交错的情况。
        - 默认值为0。
    - blockx、blocky：分别设置用于交错帧检测的窗口的x轴和y轴大小。这涉及到在帧上需要多大的区域内存在交错像素才能将帧声明为交错帧。有关更多信息，请参见combpel参数描述。可能的值是从4开始的2的幂，最大为512。
        - 默认值为16。
    - combpel：在blocky x blockx大小的块中，任何块中存在的交错像素数量，才能将帧检测为交错帧。虽然cthresh控制交错必须有多“明显”，但该设置控制帧上任何局部区域（由blockx和blocky设置定义的窗口）中必须有多少交错。最小值为0，最大值为blocky x blockx（此时将永远不会检测到帧作为交错帧）。该设置在TFM/VFM词汇中称为MI。
        - 默认值为80。

    - 关于```p/c/n/u/b```相关意思请于官网查询(https://ffmpeg.org/ffmpeg-filters.html#exposure)
- 示例：
    - 简单的逆交错（Simple IVTC）：适用于顶场优先的电视信号：  
    ```fieldmatch=order=tff:combmatch=none, decimate```
    - 高级逆交错（Advanced IVTC）：对于仍然存在交错的帧，使用yadif滤镜作为备选方案：  
    ```fieldmatch=order=tff:combmatch=full, yadif=deint=interlaced, decimate```
    - 假设我们有一个视频文件名为input.mp4，它的场匹配存在问题。我们想使用Fieldmatch滤镜来进行场匹配校正，并生成一个修复了场匹配问题的输出视频。  
    ```ffmpeg -i input.mp4 -vf "fieldmatch=order=auto" output.mp4```

##### fieldorder 滤镜
- 用于转换输入视频的场序（field order）。
- 该滤镜以下参数：
    - order：输出的场序。有效值tff（顶场优先）或bff（底场优先）。
        - 默认值为ttf（顶场优先）。
- 该滤镜通过将图像内容上下移动一行，并填充剩余行以适应所需的场序，来进行场序的转换。这种方法与大多数广播场序转换器一致。
- 如果输入视频未标记为交错扫描，或者已经标记为所需的输出场序，则该滤镜不会改变输入视频。
- 这在将视频转换为或从PAL DV格式（底场优先）非常有用。
- 示例：  
    ```ffmpeg -i in.vob -vf "fieldorder=bff" out.dv```
    - 假设我们有一个视频文件名为input.mp4，其场序为顶场优先（tff），但我们希望将其转换为底场优先（bff）的场序。  
    ```ffmpeg -i input.mp4 -vf "fieldorder=bff" output.mp4```

##### fifo和afifo 滤镜
- 用于缓冲输入图像并在请求时发送它们的滤镜。
- 这两个滤镜主要在libavfilter框架中自动插入时非常有用。
- 它们不接受任何参数，意味着它们没有额外的选项或设置。它们的作用是在滤镜链中提供一个缓冲区，以便处理器可以按需获取输入图像。
- 示例：
    - 色彩调整和模糊效果。在处理之前，我们希望使用fifo滤镜对输入图像进行缓冲，以确保图像按顺序传递给后续的滤镜。  
    ```ffmpeg -i input.mp4 -vf "fifo,colorbalance=bs=0.2:gs=0.5:rs=1.0,boxblur=5:1" output.mp4```

##### fillborders 滤镜
- 可以填充视频输入的边框，而不改变视频流的尺寸。有时视频的四个边缘可能包含垃圾像素，你可以不想裁剪视频输入以保持尺寸为某个数字的倍数。
- 该滤镜接受以下选项：
    - left：从左边框填充的像素数。
    - right：从右边框填充的像素数。
    - top：从顶部边框填充的像素数。
    - bottom：从底部边框填充的像素数。
    - mode：设置填充模式。
    - 填充模式可接受以下值：
        - smear：使用最外层的像素来填充。
        - mirror：使用镜像填充（半样本对称）。
        - fixed：使用固定值填充。
        - reflect：使用反射填充（整个样本对称）。
        - wrap：使用循环填充。
        - fade：将像素渐变为固定值。
        - margins：使用接近边框的像素的加权平均值来填充顶部和底部的像素。
        - 默认模式是smear。
    - color：设置固定或渐变模式下的像素颜色。默认为黑色。
- 该滤镜支持与选项命令相同的命令，命令的语法与相应的选项相同。
- 如果指定的表达式无效，它将保持当前值。
- 示例：
    - 假设你有一个宽度为640像素、高度为480像素的视频，你想要填充视频的边框，使其尺寸增加100像素。你想要使用白色填充边框，并将填充模式设置为fixed。  
    ```ffmpeg -i input.mp4 -vf "fillborders=left=100:right=100:top=100:bottom=100:mode=fixed:color=white" -c:a copy output.mp4```

##### find_rect 滤镜
- 用于输入视频中查找矩形对象。
- 要搜索的对象必须以gray8图像的形式通过object选项指定。
- 对于每个可能的匹配，都会计算一个分数。如果分数达到指定的阈值，就认为找到了该对象。
- 如果输入视频中包含多个对象的实例，该滤镜将只找到其中一个。
- 当找到一个对象时，在匹配帧中设置以下元数据条目：
    - lavfi.rect.w：对象的宽度。
    - lavfi.rect.h：对象的高度。
    - lavfi.rect.x：对象的x坐标位置。
    - lavfi.rect.y：对象的y坐标位置。
    - lavfi.rect.score：找到的对象的匹配分数。
- 该滤镜接受以下选项：
    - object：对象图像的文件路径，必须是gray8格式的图像。
    - threshold：检测阈值，以0-1范围内的小数表示。
        - 阈值为0.01表示仅精确匹配，阈值为0.99表示几乎所有都匹配。
        - 默认值为0.5。
    - mipmaps：mipmap的数量，默认为3。
    - xmin、ymin、xmax、ymax：指定要搜索的矩形区域。
    - discard：丢弃未检测到对象的帧，默认禁用。
- 示例：
    - 覆盖一个矩形对象：  
    ```ffmpeg -i file.ts -vf find_rect=newref.pgm,cover_rect=cover.jpg:mode=cover new.mkv```
    - 查找每个帧中对象的位置，并将其写入日志文件：  
    ```ffprobe -f lavfi movie=test.mp4,find_rect=object=object.pgm:threshold=0.3 -show_entries frame=pkt_pts_time:frame_tags=lavfi.rect.x,lavfi.rect.y -of csv -o find_rect.csv```
    - 在输入视频文件 input.mp4 中查找指定的水果图像（比如苹果），并输出匹配帧的位置信息。  
    ```ffmpeg -i input.mp4 -vf find_rect=object=apple.png:threshold=0.7:xmin=100:ymin=100:xmax=500:ymax=500 -loglevel quiet -stats -f null -```

##### floodfill 滤镜
- 用于将具有相同像素分量的区域填充为其他值。
- 该滤镜接受以下选项：
    - x：设置像素的 x 坐标。
    - y：设置像素的 y 坐标。
    - s0：设置源（原始像素）的第一个分量的值。
    - s1：设置源的第二个分量的值。
    - s2：设置源的第三个分量的值。
    - s3：设置源的第四个分量的值。
    - d0：设置目标（填充后的像素）的第一个分量的值。
    - d1：设置目标的第二个分量的值。
    - d2：设置目标的第三个分量的值。
    - d3：设置目标的第四个分量的值。
- 示例：
    - 假设你有一段视频，其中有一个红色的方块，你想将这个红色方块的颜色改变为蓝色。  
    ```ffmpeg -i input.mp4 -vf "split=2[f1][f2];[f1]colorkey=0xFF0000:0.3:0.2[f3];[f2][f3]overlay[f4];[f4]floodfill=x=100:y=100:d0=0:d1=0:d2=255" output.mp4```

##### format 滤镜
- 用于将输入视频转换为指定的像素格式。
- 该滤镜接受以下选项：
    - pix_fmts：一个以 | 分隔的像素格式名称列表，比如 "pix_fmts=yuv420p|monow|- rgb24"。这些是支持的像素格式，FFmpeg会尝试选择一个适合作为下一个滤镜输入的像素格式。
    - color_spaces：一个以 | 分隔的色彩空间名称列表，比如 "color_spaces=bt709|bt470bg|bt2020nc"。这些是支持的色彩空间，用于指定视频的色彩空间属性。
    - color_ranges：一个以 | 分隔的色彩范围名称列表，比如 "color_ranges=tv|pc"。这些是支持的色彩范围，用于指定视频的色彩范围属性。
- 示例：
    - 将输入视频转换为 yuv420p 格式：  
    ```ffmpeg -i input.mp4 -vf "format=pix_fmts=yuv420p" output.mp4```
    - 输入视频转换为 yuv420p、yuv444p 或 yuv410p 中的任意一种格式：  
    ```ffmpeg -i input.mp4 -vf "format=pix_fmts=yuv420p|yuv444p|yuv410p" output.mp4```

##### fps 滤镜
- 用于将视频转换为指定的恒定帧率，并根据需要复制或丢弃帧。
- 该滤镜接受以下选项：
    - fps：所需的输出帧率。它可以接受包含以下常量的表达式：
        - source_fps：输入的帧率。
        - ntsc：NTSC制式的帧率，为30000/1001。
        - pal：PAL制式的帧率，为25.0。
        - film：电影制式的帧率，为24.0。
        - ntsc_film：NTSC-film制式的帧率，为24000/1001。
        - 默认帧率为25.0。
    - start_time：假设第一个PTS应该是给定的值，单位为秒。这允许在流的开头进行填充/修剪。默认情况下，对于第一帧的预期PTS不做任何假设，因此不进行填充或修剪。例如，如果视频流在音频流之后开始，可以将其设置为0，以使用第一帧的副本填充开头，或者修剪具有负PTS的任何帧。
    - round：时间戳（PTS）的舍入方法。
    - 可能的取值为：
        - zero：向0舍入。
        - inf：远离0舍入。
        - down：向负无穷大舍入。
        - up：向正无穷大舍入。
        - near：四舍五入到最近的整数。
        - 默认值为near。
    - eof_action：在读取最后一帧时执行的操作。
    - 可能的取值为：
        - round：使用与其他帧相同的时间戳舍入方法。
        - pass：如果输入的持续时间尚未达到，则直接传递最后一帧。
        - 默认值为round。
    - 此外，这些选项也可以作为一个扁平字符串来指定：fps[:start_time[:round]]。
    - 请参考setpts滤镜以了解更多信息。
- 示例： 
    - 将帧率设置为25：  
    ```ffmpeg -i input.mp4 -vf "fps=fps=25" output.mp4```
    - 对于设置帧率为24，并使用缩写和舍入方法设置为四舍五入（round to nearest）：  
    ```ffmpeg -i input.mp4 -vf "fps=fps=film:round=near" output.mp4```

##### framepack 滤镜
- 用于将两个不同的视频流打包成一个立体视频，并在支持的编解码器上设置适当的元数据。这两个视图应当具有相同的大小和帧率，并且在较短的视频结束时停止处理。通过使用scale和fps滤镜，可以方便地调整视图的属性。
- 该滤镜接受以下选项：
    - format：所需的打包格式。支持的取值有：
        - sbs：视图并排显示（默认）。
        - tab：视图上下显示。
        - lines：按行打包视图。
        - columns：按列打包视图。
        - frameseq：视图在时间上交替显示。
        - 关于frameseq格式的解释：
            - frameseq格式是将两个视图在时间上交替显示的立体视频打包方式。在输出视频中，两个视图的帧按照时间顺序交错排列，例如第一个视图的第一帧，然后是第二个视图的第一帧，接着是第一个视图的第二帧，以此类推。这种方式的立体视频在播放时需要一种特殊的播放设备或软件来解码和显示。
- 示例：
    - 将左视图和右视图转换为帧顺序视频：  
    ```ffmpeg -i LEFT -i RIGHT -filter_complex framepack=frameseq OUTPUT```
    - 将左视图和右视图转换为左右并排显示的立体视频，输出的分辨率与输入相同：  
    ```ffmpeg -i LEFT -i RIGHT -filter_complex [0:v]scale=w=iw/2[left],[1:v]scale=w=iw/2[right],[left][right]framepack=sbs OUTPUT```
    - 将视频水平翻转180度  
    ```ffmpeg -i input.mp4 -vf "hflip" -c:a copy output.mp4```
    - 假设左眼视图的文件名是left.mp4，右眼视图的文件名是right.mp4，我们希望输出的立体视频文件名是output.mp4。  
    ```ffmpeg -i left.mp4 -i right.mp4 -filter_complex "[0:v]scale=320:480[left];[1:v]scale=320:480[right];[left][right]framepack=sbs" output.mp4```
    

##### framerate 滤镜
- 通过对源帧进行插值，改变视频的帧率。
- 这个滤镜的设计不适用于隔行扫描的媒体。如果你想要改变隔行扫描媒体的帧率，你需要在使用该滤镜之前进行去隔行处理，并在之后重新进行隔行处理。
- 该滤镜接受以下选项：
    - fps：指定输出的每秒帧数。这个选项也可以单独指定一个值。默认值是50。
    - interp_start：指定输出帧的创建范围的起始点，作为两个源帧的线性插值。范围是[0-255]，默认值是15。
    - interp_end：指定输出帧的创建范围的结束点，作为两个源帧的线性插值。范围是[0-255]，默认值是240。
    - scene：指定检测到场景变化的级别，其值介于0和100之间，表示新场景的概率；较低的值表示当前帧引入新场景的概率较低，而较高的值表示当前帧更有可能是新场景的一部分。默认值是8.2。    
    - flags：指定影响滤镜处理的标志。
- 可用的标志值有：
    - scene_change_detect、scd：启用使用scene选项的场景变化检测。此标志默认为启用状态。
- 示例：
    - 假设你有一段名为input.mp4的视频，其帧率为10帧每秒，你希望将其转换为帧率为30帧每秒的视频。  
    ```ffmpeg -i input.mp4 -vf "framerate=30" output.mp4```

##### framestep 滤镜
- 用于选择每隔一定帧数的帧。
- 该滤镜接受以下选项：
    - step：选择每隔多少帧选择一帧。允许的值是大于0的正整数。默认值为1。
- 示例：
    - 如果你想要跳过一些帧而只选择其中的一部分帧进行处理。  
    ```ffmpeg -i input.mp4 -vf "framestep=2" output.mp4```

##### freezedetect 滤镜
- 用于检测视频中的静止帧。
- 该滤镜在检测到输入视频在指定持续时间内内容没有显著变化时，会输出一条消息并设置帧元数据。视频静止帧检测通过计算视频帧所有分量的平均绝对差异，并将其与噪声阈值进行比较。
- 打印的时间和持续时间以秒为单位。当第一个时间戳等于或超过检测持续时间时，lavfi.freezedetect.freeze_start元数据键将设置在第一帧上，并包含冻结的第一帧的时间戳。lavfi.freezedetect.freeze_duration和lavfi.freezedetect.freeze_end元数据键将设置在冻结结束后的第一帧上。
- 该滤镜接受以下选项：
    - noise或n：设置噪声容限。可以以分贝（如果指定的值后面附加了“dB”）或作为0到1之间的差异比率来指定。默认值为-60dB或0.001。
    - duration或d：设置直到发出通知的冻结持续时间（默认为2秒）。
- 示例：
    - 对输入视频进行静止帧检测，并在控制台输出相关信息。  
    ```ffmpeg -i input.mp4 -vf "freezedetect" -f null -```
    - 假设你有一个名为input.mp4的时间-lapse视频，你想要检测其中是否存在至少持续2秒钟的静止帧。  
    ```ffmpeg -i input.mp4 -vf "freezedetect=duration=2" -f null -```

##### freezeframes 滤镜
- 用于冻结视频帧，使用第二个输入中的帧来替代。
- 该滤镜接受以下选项：
    - first：设置开始冻结的第一帧的编号。
    - last：设置结束冻结的最后一帧的编号。
    - replace：设置第二个输入中要用来替代被冻结帧的帧的编号。
- 示例：
    - 假设你有一个视频文件，你想在某个时间段内将视频冻结住，并显示一张静态图片。比如，在一个视频中，你想要在第10秒到第20秒之间将视频冻结，并在冻结期间显示一张公司logo的图片。  
    ```ffmpeg -i input.mp4 -loop 1 -i logo.jpg -filter_complex "[0:v]trim=0:10,setpts=PTS-STARTPTS[v1];[0:v]trim=10:20,setpts=PTS-STARTPTS,format=pix_fmts=yuva420p[v2];[v1][v2]concat[out]" -map "[out]" output.mp4```

##### frei0r 滤镜
- 用于在输入视频上应用frei0r效果的滤镜。
- 要启用此滤镜的编译，你需要安装frei0r头文件，并使用--enable-frei0r选项配置FFmpeg。
- frei0r滤镜接受以下参数：
    - filter_name：要加载的frei0r效果的名称。如果环境变量FREI0R_PATH已定义，那么frei0r效果将在FREI0R_PATH中指定的每个目录中搜索。否则，默认的frei0r路径将按以下顺序进行搜索：HOME/.frei0r-1/lib/、/usr/local/lib/frei0r-1/、/usr/lib/frei0r-1/。
    - filter_params：用于传递给frei0r效果的参数列表，参数之间用竖线（|）分隔。
- frei0r效果的参数可以是布尔值（取值为"y"或"n"），双精度浮点数，颜色（以R/G/B形式指定，其中R、G和B是介于0.0和1.0之间的浮点数，包括0.0和1.0），或者是在FFmpeg手册的“Color”部分中指定的颜色描述，还可以是位置（以X/Y形式指定，其中X和Y是浮点数），和/或字符串。
- 参数的数量和类型取决于加载的效果。
- 该滤镜支持上述所有选项作为命令使用。
- 示例： 
    - 对于distort0r效果，设置前两个双精度参数：  
    ```frei0r=filter_name=distort0r:filter_params=0.5|0.01```
    - 对于colordistance效果，使用颜色作为第一个参数：
        - 使用RGB值作为参数：  
        ```frei0r=colordistance:0.2/0.3/0.4```
        - 使用颜色名称作为参数：  
        ```frei0r=colordistance:violet```
        - 使用十六进制值作为参数：  
        ```frei0r=colordistance:0x112233```
    - 对于perspective效果，指定左上角和右上角的图像位置：  
    ```frei0r=perspective:0.2/0.2|0.8/0.2```

##### fspp 滤镜
- 一个快速且简单的后处理滤镜，用于视频编码中。它是spp（简单后处理）的一个更快的版本。
- 它将（I）DCT（离散余弦变换）分为水平和垂直两个步骤进行处理。与简单后处理滤镜不同，每个块只执行其中一个步骤，而不是每个像素。这样可以显著提高处理速度。
- 该滤镜接受以下选项：
    - quality：设置质量。该选项定义了平均级别的数量。它接受一个整数，范围为4-5。默认值为4。
    - qp：强制使用固定的量化参数（QP）。它接受一个整数，范围为0-63。如果未设置，滤镜将使用视频流中的QP（如果可用）。
    - strength：设置滤镜强度。它接受一个整数，范围为-15到32。较低的值意味着更多的细节但也更多的伪影，而较高的值使图像更平滑但也更模糊。默认值为0，即PSNR最优。
    - use_bframe_qp：如果设置为1，启用使用B帧的QP。使用此选项可能会导致闪烁，因为B帧通常具有较大的QP。默认值为0（未启用）。
- 示例：
    - 假设我们有一个名为input.mp4的视频文件，我们想要对它应用fspp滤镜进行快速的后处理。我们希望设置质量级别为5，强度为10，并使用B帧的QP。  
    ```ffmpeg -i input.mp4 -vf "fspp=quality=5:strength=10:use_bframe_qp=1" output.mp4```

##### fsync 滤镜
- 用于视频帧与外部映射文件进行同步。
- 对于映射文件中给定的每个输入PTS（显示时间戳），它根据需要丢弃或创建相应数量的帧，以重新生成映射文件中给定的输出帧序列。
- 该滤镜对于重新创建由fps滤镜进行的帧率转换的输出帧非常有用。可以使用ffmpeg选项-stats_mux_pre将其记录到映射文件中，并对相应的帧进行进一步处理，例如质量比较。
- 映射文件的每一行必须包含每个输入帧的三个项目：输入PTS（十进制）、输出PTS（十进制）和输出TIMEBASE（十进制/十进制），用空格分隔。这个文件格式对应于-stats_mux_pre_fmt="{ptsi} {pts} {tb}"的输出。
- 该滤镜假设映射文件按照递增的输入PTS进行排序。
- 该滤镜接受以下选项：
    - file, f：要使用的映射文件的文件名。
- 示例：    
    - 将视频转换为25 fps，并使用-stats_mux_pre选项记录映射文件（MAP_FILE）：  
    ```ffmpeg -i INPUT -vf fps=fps=25 -stats_mux_pre MAP_FILE -stats_mux_pre_fmt "{ptsi} {pts} {tb}" OUTPUT```
    - 使用sort命令对映射文件进行排序，以确保按照递增的输入PTS进行排序：  
    ```sort -n MAP_FILE```
    - 比较输入视频和输出视频中对应帧的SSIM值，其中INPUT、OUTPUT和MAP_FILE是先前命令中使用的相应文件：  
    ```ffmpeg -i INPUT -i OUTPUT -filter_complex '[0:v]fsync=file=MAP_FILE[ref];[1:v][ref]ssim' -f null -```

##### gblur 滤镜
- 应用高斯模糊滤镜
- 该滤镜接受以下选项：
    - sigma：设置水平方向的标准差（sigma），即高斯模糊的标准差。默认值为0.5。
    - steps：设置高斯近似的步骤数。默认值为1。
    - planes：设置要过滤的平面。默认情况下，所有平面都会被过滤。
    - sigmaV：设置垂直方向的标准差（sigma）。如果为负数，则与水平方向的标准差相同。默认值为-1。
- 命令：
    - 该滤镜支持与选项相同的命令。该命令接受与相应选项相同的语法。
    - 如果指定的表达式无效，则保持其当前值。
- 示例：
    - 假设我们有一个名为input.mp4的视频文件，我们希望对其应用高斯模糊滤镜。我们想要设置水平方向的标准差为2，垂直方向的标准差与水平方向相同。  
    ```ffmpeg -i input.mp4 -vf "gblur=sigma=2:sigmaV=-1" output.mp4```

##### geq 滤镜
- 用于对每个像素应用通用方程（generic equation）进行处理。
- 该滤镜接受以下选项：
    - lum_expr, lum
    - 设置亮度表达式。
    
    - cb_expr, cb
    - 设置色度蓝表达式。
    
    - cr_expr, cr
    - 设置色度红表达式。
    
    - alpha_expr, a
    - 设置透明度表达式。
    
    - red_expr, r
    - 设置红色通道表达式。
    
    - green_expr, g
    - 设置绿色通道表达式。
    
    - blue_expr, b
    - 设置蓝色通道表达式。
    - 颜色空间根据指定的选项进行选择。如果指定了lum_expr、cb_expr或cr_expr选项中的一个，滤镜将自动选择YCbCr颜色空间。如果指定了red_expr、green_expr或blue_expr选项中的一个，它将选择RGB颜色空间。
    - 如果未定义其中一个色度表达式，则会回退到另一个表达式。如果没有指定透明度表达式，它将计算为不透明值。如果未指定任何色度表达式，它们将计算为亮度表达式的值。
- 这些表达式可以使用以下变量和函数：
    - N
    - 从0开始的过滤帧的顺序号。
    
    - X
    - Y
    - 当前样本的坐标。
    
    - W
    - H
    - 图像的宽度和高度。
    
    - SW
    - SH
    - 根据当前过滤的平面选择的宽度和高度缩放。它是当前平面像素数与相应亮度平面像素数之间的比率。例如，对于YUV4:2:0，亮度平面的值为1,1，色度平面的值为0.5,0.5。

    - T
    - 当前帧的时间，以秒为单位。

    - p(x, y)
    - 返回当前平面上位置（x,y）处的像素值。

    - lum(x, y)
    - 返回亮度平面上位置（x,y）处的像素值。

    - cb(x, y)
    - 返回蓝色差异色度平面上位置（x,y）处的像素值。如果没有该平面，则返回0。

    - cr(x, y)
    - 返回红色差异色度平面上位置（x,y）处的像素值。如果没有该平面，则返回0。

    - r(x, y)
    - g(x, y)
    - b(x, y)
    - 返回红色/绿色/蓝色分量在位置（x,y）处的像素值。如果没有该分量，则返回0。

    - alpha(x, y)
    - 返回透明度平面上位置（x,y）处的像素值。如果没有该平面，则返回0。

    - psum(x,y), lumsum(x, y), cbsum(x,y), crsum(x,y), rsum(x,y), gsum(x,y), bsum(x,y), alphasum(x,y)
    - 从（0,0）到（x,y）的矩形中样本值的总和，这允许获取矩形内样本的总和。参见没有sum后缀的函数。

    - interpolation
    - 设置插值方法之一：

    - nearest, n
    - bilinear, b
    - 默认为bilinear。

- 对于函数，如果x和y在区域之外，值将自动截断到较近的边缘。
- 请注意，该滤镜可以在多个线程中使用，每个片段将具有自己的表达式状态。如果您希望仅使用单个表达式状态，因为您的表达式依赖于先前的状态，那么应将滤镜线程数限制为1。
- 示例：
    - 水平翻转图像:  
    ```geq=p(W-X\,Y)```  
    ```ffmpeg -i input.mp4 -vf "geq=p(W-X\,Y)" output.mp4```
    - 生成一个角度为PI/3，波长为100像素的二维正弦波:  
    ```geq=128 + 100*sin(2*(PI/100)*(cos(PI/3)*(X-50*T) + sin(PI/3)*Y)):128:128```  
    ```ffmpeg -i input.mp4 -vf "geq=128 + 100*sin(2*(PI/100)*(cos(PI/3)*(X-50*T) + sin(PI/3)*Y)):128:128" output.mp4```
    - 生成一个华丽的神秘移动光效果:  
    ```nullsrc=s=256x256,geq=random(1)/hypot(X-cos(N*0.07)*W/2-W/2\,Y-sin(N*0.09)*H/2-H/2)^2*1000000*sin(N*0.02):128:128```  
    ```ffmpeg -f lavfi -i nullsrc=s=256x256 -vf "geq=random(1)/hypot(X-cos(N*0.07)*W/2-W/2\,Y-sin(N*0.09)*H/2-H/2)^2*1000000*sin(N*0.02):128:128" output.mp4```
    - 生成一个快速浮雕效果:  
    ```format=gray,geq=lum_expr='(p(X,Y)+(256-p(X-4,Y-4)))/2'```  
    ```ffmpeg -i input.mp4 -vf "format=gray,geq=lum_expr='(p(X,Y)+(256-p(X-4,Y-4)))/2'" output.mp4```
    - 根据像素位置修改RGB分量:  
    ```geq=r='X/W*r(X,Y)':g='(1-X/W)*g(X,Y)':b='(H-Y)/H*b(X,Y)'```  
    ```ffmpeg -i input.mp4 -vf "geq=r='X/W*r(X,Y)':g='(1-X/W)*g(X,Y)':b='(H-Y)/H*b(X,Y)'" output.mp4```
    - 创建一个与输入相同大小的径向渐变:  
    ```geq=lum=255*gauss((X/W-0.5)*3)*gauss((Y/H-0.5)*3)/gauss(0)/gauss(0),format=gray```  
    ```ffmpeg -i input.mp4 -vf "geq=lum=255*gauss((X/W-0.5)*3)*gauss((Y/H-0.5)*3)/gauss(0)/gauss(0),format=gray" output.mp4``` 

##### gradfun 滤镜
- 用于修复由于将图像截断为8为色深而引入的带状伪影。它会插值应该出现在带状区域的渐变，并对其进行抖动处理。
- 该滤镜接受以下参数：
    - strength：滤镜将改变任何一个像素的最大程度，也是检测几乎平坦区域的阈值。可接受的值范围为0.51到64，默认值为1.2。超出范围的值将被截断为有效范围内的值。

    - radius：适用于拟合渐变的邻域大小。较大的半径会产生更平滑的渐变，但也会阻止滤镜修改接近细节区域的像素。可接受的值范围为8到32，默认值为16。超出范围的值将被截断为有效范围内的值。
- 此外，您还可以将参数选项作为一个字符串进行指定，格式为：strength[:radius]。
- 示例：
    - 要使用strength为3.5和radius为8：  
    ```ffmpeg -i input.mp4 -vf "gradfun=3.5:8" output.mp4```
    - 指定radius而忽略strength（使用默认值）：  
    ```ffmpeg -i input.mp4 -vf "gradfun=radius=8" output.mp4```

##### graphmonitor 滤镜
- 用于显示各种滤镜图的统计信息。
- 该滤镜接受以下选项：
    - size, s：设置视频输出大小。默认值为hd720。
    - opacity, o：设置视频的透明度。默认值为0.9。允许的范围是从0到1。
    - mode, m：设置输出模式标志。
    - 可用的标志值有：
        - 'full'：不进行任何过滤。默认值。
        - 'compact'：仅显示具有排队帧的滤镜。
        - 'nozero'：仅显示具有非零统计信息的滤镜。
        - 'noeof'：仅显示具有非eof（end-of-file）状态的滤镜。
        - 'nodisabled'：仅显示在时间轴中处于启用状态的滤镜。
    - flags, f：设置启用哪些统计信息在视频中显示。
        - 可用的标志值有：
        - 'none'：所有标志都关闭。
        - 'all'：所有标志都打开。
        - 'queue'：在每个链接中显示排队帧数。
        - 'frame_count_in'：显示从滤镜中获取的帧数。
        - 'frame_count_out'：显示从滤镜输出的帧数。
        - 'frame_count_delta'：显示上述两个值之间的帧数差异。
        - 'pts'：显示当前过滤帧的pts。
        - 'pts_delta'：显示当前帧与上一帧之间的pts差值。
        - 'time'：显示当前过滤帧的时间。
        - 'time_delta'：显示当前帧与上一帧之间的时间差值。
        - 'timebase'：显示滤镜链接的时间基准。
        - 'format'：显示滤镜链接使用的格式。
        - 'size'：显示视频大小或在音频情况下显示音频通道数。
        - 'rate'：显示视频帧率或在音频情况下显示采样率。
        - 'eof'：显示链接输出状态。
        - 'sample_count_in'：显示从滤镜中获取的样本数。
        - 'sample_count_out'：显示从滤镜输出的样本数。
        - 'sample_count_delta'：显示上述两个值之间的样本数差异。
        - 'disabled'：显示时间轴滤镜的状态。
    - rate, r：设置输出流的视频帧速率上限，默认值为25。这保证输出视频的帧率不会超过此值。
- 示例：
    - 将graphmonitor滤镜应用于输入视频，并在视频的左上角添加一个文本水印。同时，graphmonitor滤镜将显示每个水印帧的时间信息：  
    ```ffmpeg -i input.mp4 -vf "drawtext=text='Watermark':x=10:y=10:fontsize=30:fontcolor=white, graphmonitor" output.mp4```

##### grayworld 滤镜
- 这是一种颜色恒常性滤镜，根据灰世界假设进行颜色校正。该滤镜的作用是自动调整图像的颜色平衡，使其看起来更自然和准确。
- 更多详细内容可以自行查看：https://www.researchgate.net/publication/275213614_A_New_Color_Correction_Method_for_Underwater_Imaging
- 该算法使用线性光，因此在应用算法之前，输入数据应进行线性化处理（并可能需要正确标记）。  
```ffmpeg -i INPUT -vf zscale=transfer=linear,grayworld,zscale=transfer=bt709,format=yuv420p OUTPUT```
- 示例：
    - 假设你拍摄了一张照片，照片中有一个白色的纸杯，但由于光线的原因，照片中的纸杯看起来带有一些蓝色调。使用grayworld滤镜，它会自动检测图像中的平均颜色，并根据灰世界假设，将图像的整体颜色平衡调整为更接近真实的白色。这样，经过校正的图像中的纸杯将呈现出准确的白色，而不再带有蓝色调。  
    ```ffmpeg -i input.mp4 -vf zscale=transfer=linear,grayworld,zscale=transfer=bt709,format=yuv420p output.mp4```

##### grayedge 滤波器
- 基于边缘的颜色恒常性变体滤波器，它通过gray-edge算法估计场景的照明，并相应地矫正场景的颜色。
- 想了解更多：https://staff.science.uva.nl/th.gevers/pub/GeversTIP07.pdf
- 该滤波器接受以下选项：
    - difford：应用于场景的微分阶数。必须在范围[0,2]内选择，默认值为1。
    - minknorm：用于计算Minkowski距离的Minkowski参数。必须在范围[0,20]内选择，默认值为1。如果设置为0，则会得到最大值，而不是计算Minkowski距离。
    - sigma：应用于场景的高斯模糊的标准差。必须在范围[0,1024.0]内选择，默认值为1。如果difford大于0，则floor(sigma * break_off_sigma(3))不能等于0。
- 示例：
    - Grey Edge：
    ```greyedge=difford=1:minknorm=5:sigma=2```
    - Max Edge：  
    ```greyedge=difford=1:minknorm=0:sigma=2```

##### guided 滤镜
- 一种用于边缘保留平滑、去雾等操作的滤镜。
- 该滤镜接受以下选项：
    - radius：设置像素的盒子半径。允许的范围是1到20。默认值为3。
    - eps：设置正则化参数（平方）。允许的范围是0到1。默认值为0.01。
    - mode：设置滤波模式。可以是basic或fast。默认值为basic。
    - sub：设置快速模式的子采样比例。范围是2到64。默认值为4。在basic模式下不进行子采样。
    - guidance：设置引导模式。可以是off或on。默认值为off。如果是off，则只需要一个输入。如果是on，则需要两个分辨率和像素格式相同的输入。第二个输入用作引导图像。
    - planes：设置要过滤的平面。默认值为first only。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 边缘保留平滑（使用guided滤镜）：  
    ```ffmpeg -i input.png -vf guided out.png```
    - 去雾、结构转移滤波、细节增强（使用guided滤镜）：  
    ```ffmpeg -i in.png -i guidance.png -filter_complex guided=guidance=on out.png```

##### haldclut 滤镜
- 一种视频处理滤镜，它将Hald CLUT应用于视频流。它有两个输入：待处理的视频流和Hald CLUT，后者可以是单张图片或完整的视频流。
- 该滤镜接受以下选项：
    - clut：此选项设置从第二个输入流中要处理的CLUT视频帧。可以设置为"first"或"all"。默认值为"all"。
    - shortest：当设置为1时，滤镜将在最短输入流结束时终止。默认值为0。
    - repeatlast：当设置为1时，滤镜将在流的末尾继续应用最后一个CLUT。将其设置为0将在达到CLUT的最后一帧后禁用滤镜。默认值为1。
- haldclut滤镜还支持插值选项，类似于lut3d滤镜。这些选项控制在CLUT条目之间如何插值处理颜色。
- 该滤镜还支持帧同步选项，用于控制输入流之间的帧同步。
- 如果您需要更多关于Hald CLUT的信息，可以访问Eskil Steenberg的网站：http://www.quelsolaar.com/technology/clut.html。

- Hald CLUT 视频流
    - 生成一个带有各种效果的标识Hald CLUT流：  
    ```ffmpeg -f lavfi -i haldclutsrc=8 -vf "hue=2PIt:s=sin(2PIt)+1, curves=cross_process" -t 10 -c:v ffv1 clut.nut```
    - 注意：请确保使用无损编解码器。
    - 然后将其与haldclut一起在某个随机流上应用：  
    ```ffmpeg -f lavfi -i mandelbrot -i clut.nut -filter_complex '[0][1] haldclut' -t 20 mandelclut.mkv```
    - Hald CLUT将应用于前10秒（clut.nut的持续时间），然后将该CLUT流的最新图像应用于mandelbrot流的其余帧。

- 带有预览的 Hald CLUT
    - Hald CLUT应该是一个LevelLevelLevel乘以LevelLevelLevel像素的正方形图像。对于给定的Hald CLUT，FFmpeg将选择从图片左上角开始的最大可能正方形。剩余的填充像素（底部或右侧）将被忽略。可以使用这个区域添加Hald CLUT的预览。
    - 通常，以下生成的Hald CLUT将受到haldclut滤镜的支持：  
    ```ffmpeg -f lavfi -i haldclutsrc=8 -vf "pad=iw+320 [padded_clut];smptebars=s=320x256, split [a][b];[padded_clut][a] overlay=W-320:h, curves=color_negative [main];[main][b] overlay=W-320" -frames:v 1 clut.png```
    - 它包含了CLUT效果的原始图像和预览：右上方显示了SMPTE彩色条，下方显示了经过颜色变化处理的相同彩色条。
    - 然后，可以使用以下命令来查看此Hald CLUT的效果：  
    ```ffplay input.mkv -vf "movie=clut.png, [in] haldclut"```
- 当你拍摄一张照片时，你可以使用各种后期处理效果来改变它的外观。类似地，Hald CLUT是一种用于在视频中应用颜色效果的工具。这就像给视频图像上的每个像素应用一个特定的颜色滤镜，从而改变图像的整体外观。

##### hflip 滤镜
- 一个视频滤镜，用于将输入视频水平翻转。
- 示例：
    - 要使用FFmpeg水平翻转输入视频，可以使用以下命令：  
    ```ffmpeg -i input.avi -vf "hflip" output.avi```
    
##### histeq 滤镜
- 一个视频滤镜，它可以在每帧上应用全局颜色直方图均衡化。
- 它可以用于纠正像素强度范围压缩的视频。该滤镜重新分配像素强度，以使它们在强度范围内的分布均衡化。它可以被视为一种"自动调整对比度滤镜"。这个滤镜只适用于纠正受损或拍摄质量较差的源视频。
- 该滤镜接受以下选项：
    - strength：确定要应用的均衡化程度。随着强度的降低，像素强度的分布越来越接近输入帧的分布。该值必须是范围在[0,1]之间的浮点数，默认值为0.200。
    - intensity：设置可以生成的最大强度，并相应地缩放输出值。应根据需要设置强度，然后如果需要避免过曝，可以限制强度。该值必须是范围在[0,1]之间的浮点数，默认值为0.210。
    - antibanding：设置抗条纹级别。如果启用，滤镜将随机微调输出像素的亮度，以避免直方图的条纹状。可能的值有none（无）、weak（弱）或strong（强）。默认值为none（无）。
- 示例：
    - 当你拍摄一段视频时，有时可能会遇到亮度不均匀或颜色失真的问题。histeq滤镜可以帮助你纠正这些问题，使视频的亮度和颜色更加均衡。  
    ```ffmpeg -i input.mp4 -vf "histeq" output.mp4```

##### histogram 滤镜
- 一个视频滤镜，用于计算并绘制输入视频的颜色分布直方图。
- 计算得到的直方图是图像中颜色分量分布的表示。
- 标准直方图显示图像中颜色分量的分布情况。为每个颜色分量显示颜色图形。显示当前帧中Y、U、V、A或R、G、B分量的分布，取决于输入格式。在每个图形下方显示颜色分量刻度表。
- 该滤镜接受以下选项：
    - level_height：设置级别（level）的高度。默认值为200。允许的范围是[50, 2048]。
    - scale_height：设置颜色刻度的高度。默认值为12。允许的范围是[0, 40]。
    - display_mode：设置显示模式。可以选择以下值：
    - stack：每个颜色分量的图形放置在彼此下方。
    - parade：每个颜色分量的图形并排放置。
    - overlay：与parade相同，但颜色分量的图形直接叠加在彼此上方。
    - 默认值为stack。
    - levels_mode：设置模式。可以是线性（linear）或对数（logarithmic）。默认值为线性。
    - components：设置要显示的颜色分量。默认值为7。
    - fgopacity：设置前景不透明度。默认值为0.7。
    - bgopacity：设置背景不透明度。默认值为0.5。
    - colors_mode：设置颜色模式。可以选择以下值：
        - whiteonblack
        - blackonwhite
        - whiteongray
        - blackongray
        - coloronblack
        - coloronwhite
        - colorongray
        - blackoncolor
        - whiteoncolor
        - grayoncolor
        - 默认值为whiteonblack。
- 示例：
    - 要计算并绘制直方图，你可以使用以下FFmpeg命令：  
    ```ffplay -i input.mp4 -vf histogram```

##### hqdn3d 滤镜
- 一个高精度/高质量的3D降噪滤镜。它旨在减少图像噪点，产生平滑的图像，并使静止图像真正静止。它可以提高压缩性能。
- 该滤镜接受以下参数：
    - luma_spatial：非负浮点数，指定空间亮度强度，默认值为4.0。
    - chroma_spatial：非负浮点数，指定空间色度强度，默认值为3.0*luma_spatial/4.0。
    - luma_tmp：浮点数，指定亮度时间强度，默认值为6.0*luma_spatial/4.0。
    - chroma_tmp：浮点数，指定色度时间强度，默认值为luma_tmp*chroma_spatial/luma_spatial。
- 该滤镜支持与选项相同的命令。命令接受与相应选项相同的语法。
- 如果指定的表达式无效，它将保持当前值。
- 示例：
    - 当你拍摄一段视频时，可能会出现一些噪点或图像细节不清晰的问题。这时候可以使用hqdn3d滤镜来降噪，使图像变得更加平滑和清晰。  
    ```ffmpeg -i input.mp4 -vf "hqdn3d" output.mp4```  
    ```ffmpeg -i input.mp4 -vf "hqdn3d=luma_spatial=2.0:chroma_spatial=1.5:luma_tmp=3.0:chroma_tmp=2.0" output.mp4```

##### hwmap 滤镜
- 用于将硬件帧映射到系统内存或另一个设备上。
- hwmap滤镜有几种不同的操作模式，具体使用哪种模式取决于输入和输出的格式：
    - 硬件帧输入，普通帧输出：
        - 将输入的硬件帧映射到系统内存，并传递到输出。如果以后需要原始的硬件帧（例如，在其上叠加其他内容之后），可以再次使用hwmap滤镜以检索它。

    - 普通帧输入，硬件帧输出：
        - 如果输入实际上是一个软件映射的硬件帧，则取消映射，即返回原始的硬件帧。
        - 否则，需要提供一个设备。在该设备上创建新的硬件帧，并将它们映射回输入的软件格式，并将这些帧传递给前面的滤镜。这将类似于hwupload滤镜的操作，但在输入已经是兼容格式时可以避免额外的复制。

    - 硬件帧输入和输出：
        - 必须为输出提供一个设备，可以直接指定，也可以使用derive_device选项派生。输入和输出设备必须是不同类型且兼容的 - 具体含义取决于系统，但通常意味着它们必须引用相同的底层硬件上下文（例如，引用相同的显卡）。
        - 如果输入帧最初是在输出设备上创建的，则取消映射以检索原始帧。
        - 否则，将帧映射到输出设备 - 在输出上创建与输入帧对应的新硬件帧。
    - hwmap滤镜还接受以下附加参数：
        - mode：设置帧映射模式，可以是以下组合：
            - read：映射的帧可读取。
            - write：映射的帧可写入。
            - overwrite：映射将始终覆盖整个帧。在某些情况下，这可能会提高性能，因为不需要加载帧的原始内容。
            - direct：映射不能涉及任何复制。在某些情况下，为了避免直接映射可能导致的意外问题，可能会创建间接映射到帧副本。设置此标志可确保映射是直接的，并且如果不可能进行直接映射，则会失败。如果未指定，默认为read+write。
        - derive_device type：而不是使用初始化时提供的设备，从输入帧所在的设备中派生一个新的类型为type的设备。
        - reverse：在硬件到硬件的映射中，进行反向映射 - 在目标中创建帧，然后将其映射回源。在某些情况下，如果要求进行一种方向的映射，但只支持相反方向的设备，则可能需要使用此选项。
- 示例：
    - 假设你有一个名为"input.mp4"的视频文件，你想将其转换为YUV格式的视频，并将转换后的视频保存为"output.yuv"文件。你可以使用hwmap滤镜来实现此操作。  
    ```ffmpeg -i input.mp4 -vf "hwmap=derive_device=vaapi" -pix_fmt yuv420p output.yuv```
    - 注意，使用该命令需要相对应的硬件上下文（设备或输入帧）。

##### hwupload 滤镜
- 用于将系统内存帧上传到硬件表面。
- 在初始化过滤器时，必须提供要上传到的设备。如果使用FFmpeg，可以使用-filter_hw_device选项或derive_device选项选择适当的设备。输入和输出设备必须是不同类型且兼容的 - 具体含义取决于系统，但通常意味着它们必须引用相同的底层硬件上下文（例如，引用相同的显卡）。
- 该滤镜接受以下附加参数：
    - derive_device type：而不是使用初始化时提供的设备，从输入帧所在的设备中派生一个新的类型为type的设备。

##### hqx 滤镜
- 用于应用专为像素艺术设计的高质量放大滤镜。该滤镜最初由Maxin Stepin创建。
- 该滤镜接受以下选项：
    - n：设置缩放维度，可选的取值为2（hq2x）、3（hq3x）和4（hq4x）。默认值是3。
- 示例：
    - 假设你有一个名为"input.png"的像素艺术设计图像文件，你想将其应用hq2x滤镜进行放大处理，并将处理后的图像保存为"output.png"文件。  
    ```ffmpeg -i input.png -vf "hqx=n=2" output.png```

##### hstack 滤镜
- 用于将输入的视频水平堆叠在一起。
- 使用hstack滤镜时，所有的流必须具有相同的像素格式和相同的高度。
- 需要注意的是，相比使用overlay和pad滤镜来创建相同的输出，hstack滤镜的处理速度更快。
- 该滤镜接受以下选项：
    - inputs：设置输入流的数量。默认值为2。
    - shortest：如果设置为1，当最短的输入流结束时强制输出流也结束。默认值为0。
- 示例：
    - 假设你有两个视频文件"video1.mp4"和"video2.mp4"，你想将它们水平堆叠在一起，创建一个水平排列的视频输出。  
    ```ffmpeg -i video1.mp4 -i video2.mp4 -filter_complex "[0:v][1:v]hstack=inputs=2" output.mp4```

##### hsvhold 滤镜
- 用于将指定的HSV范围转换为灰度值。
- 该滤镜通过测量选项中设置的HSV颜色和视频流中测得的颜色之间的差异来实现。根据选项的设置，输出颜色可以被转换为灰度或保持不变。
- 该滤镜接受以下选项：
    - hue：设置用于颜色差异计算的色调值。允许的范围为-360到360。默认值为0。
    - sat：设置用于颜色差异计算的饱和度值。允许的范围为-1到1。默认值为0。
    - val：设置用于颜色差异计算的亮度值。允许的范围为-1到1。默认值为0。
    - similarity：设置与关键颜色的相似度百分比。允许的范围为0到1。默认值为0.01。
        - 值为0.00001只匹配完全相同的关键颜色，而值为1.0匹配所有颜色。
    - blend：混合百分比。允许的范围为0到1。默认值为0。
        - 值为0.0使像素完全变为灰色，或完全不变为灰色。
        - 较高的值会产生更多灰色像素，与关键颜色的相似度越高，灰色像素越多。
- 示例：
    - 假设你有一个视频文件"input.mp4"，你想将其中的蓝色部分转换为灰度值。  
    ```ffmpeg -i input.mp4 -vf "hsvhold=hue=240:sat=1:val=1:blend=0.5" output.mp4```

##### hsvkey 滤镜
- 用于将指定的HSV范围转换为透明度。
- 该滤镜通过测量选项中设置的HSV颜色和视频流中测得的颜色之间的差异来实现。根据选项的设置，输出颜色可以通过添加Alpha通道来转换为透明。
- 该滤镜接受以下选项：
    - hue：设置用于颜色差异计算的色调值。允许的范围为-360到360。默认值为0。
    - sat：设置用于颜色差异计算的饱和度值。允许的范围为-1到1。默认值为0。
    - val：设置用于颜色差异计算的亮度值。允许的范围为-1到1。默认值为0。
    - similarity：设置与关键颜色的相似度百分比。允许的范围为0到1。默认值为0.01。
        - 值为0.00001只匹配完全相同的关键颜色，而值为1.0匹配所有颜色。
    - blend：混合百分比。允许的范围为0到1。默认值为0。
        - 值为0.0使像素完全透明，或完全不透明。
        - 较高的值会产生半透明像素，与关键颜色的相似度越高，透明度越高。
- 示例：
    - 假设你有一个视频文件"input.mp4"，你想将其中的绿色部分转换为透明。  
    ```ffmpeg -i input.mp4 -vf "hsvkey=hue=120:sat=1:val=1:blend=0.5" -c:v h264 -c:a copy output.mp4```

##### hue 滤镜
- 用于修改输入图像的色调（hue）和/或饱和度（saturation）。
- 该滤镜接受以下选项：
    - h：以角度为单位指定色调角度。它可以接受表达式，并默认为"0"。
    - s：指定饱和度范围在[-10, 10]之间。它可以接受表达式，并默认为"1"。
    - H：以弧度为单位指定色调角度。它可以接受表达式，并默认为"0"。
    - b：指定亮度范围在[-10, 10]之间。它可以接受表达式，并默认为"0"。
- h和H是互斥的选项，不能同时指定。
- 参数中的b、h、H和s的值可以是包含以下常量的表达式：
    - n：从0开始的输入帧的帧数。
    - pts：以时间基为单位表示的输入帧的呈现时间戳。
    - r：输入视频的帧率，如果输入帧率未知，则为NAN。
    - t：以秒为单位表示的时间戳，如果输入时间戳未知，则为NAN。
    - tb：输入视频的时间基。
- 示例：
    - 将色调设置为90度，饱和度设置为1.0：  
    ```hue=h=90:s=1``` 
    - 使用弧度表示色调为90度，饱和度设置为1.0：  
    ```hue=H=PI/2:s=1```
    - 旋转色调并使饱和度在1秒内在0和2之间摆动：  
    ```hue="H=2*PI*t: s=sin(2*PI*t)+1"```
    - 应用一个3秒的饱和度淡入效果，从0开始：  
    ```hue="s=min(t/3,1)"```
    - 通用的淡入表达式可以写成：  
    ```hue="s=min(0, max((t-START)/DURATION, 1))"```
    - 应用一个3秒的饱和度淡出效果，从第5秒开始：  
    ```hue="s=max(0, min(1, (8-t)/3))"```
    - 通用的淡出表达式可以写成：  
    ```hue="s=max(0, min(1, (START+DURATION-t)/DURATION))"```
    - 假设你有一个视频文件"input.mp4"，你想将其中的颜色转换为黑白效果。  
    ```ffmpeg -i input.mp4 -vf "hue=s=0" -c:v h264 -c:a copy output.mp4```
- 该滤镜支持以下命令：
    - b：用于修改输入视频的亮度（brightness）。
    - s：用于修改输入视频的饱和度（saturation）。
    - h：用于修改输入视频的色调（hue）。
    - H：用于以弧度形式修改输入视频的色调。
- 这些命令接受与相应选项相同的语法。你可以使用这些命令来进一步调整输入视频的亮度、饱和度和色调。
- 如果指定的表达式无效，命令会保持其当前值不变。

##### huesaturation 滤镜
- 用于对输入的视频流应用色调-饱和度-强度调整。
- 这个滤镜在RGB色彩空间中操作。
- 该滤镜接受以下选项：
    - hue：设置要应用的色调偏移量（以角度为单位）。默认值为0。允许的范围为-180到180。
    - saturation：设置饱和度的偏移量。默认值为0。允许的范围为-1到1。
    - intensity：设置强度的偏移量。默认值为0。允许的范围为-1到1。
    - colors：设置要调整的主要颜色和互补颜色。可以通过提供一个或多个值来设置此选项。这可以一次选择多个颜色。默认情况下选择所有颜色。
        - 'r'：调整红色。
        - 'y'：调整黄色。
        - 'g'：调整绿色。
        - 'c'：调整青色。
        - 'b'：调整蓝色。
        - 'm'：调整品红色。
        - 'a'：调整所有颜色。
    - strength：设置滤波的强度。允许的范围为0到100。默认值为1。
    - rw, gw, bw：为每个RGB分量设置权重。允许的范围为0到1。默认情况下设置为0.333、0.334、0.333。这些选项用于饱和度和亮度处理。
    - lightness：启用保持亮度选项，默认禁用。调整色调可能会改变原始RGB三元组的亮度，启用此选项将保持相同的亮度值。

##### iccdetect 滤镜
- 用于从嵌入的ICC配置文件（如果存在）中检测色彩空间，并相应地更新帧地标签。
- 该滤镜接受以下选项：
    - force：如果设置为true，帧的现有色彩空间标签将始终被从ICC配置文件中检测到的值覆盖。否则，只有当标签中包含未知值时才会进行分配。默认情况下启用此选项。

##### iccgen 滤镜
- 用于生成ICC配置文件并将其附加到帧上。
- 该滤镜接受以下选项：
    - color_primaries：配置将为其生成ICC配置文件的色彩空间。默认值为"auto"，它根据输入帧的元数据自动推断值，并在适当时默认为BT.709/sRGB。
    - color_trc：配置将为其生成ICC配置文件的色彩变换特性（color transfer characteristics）。与color_primaries类似，默认值为"auto"，根据输入帧的元数据自动推断值。

##### identify 滤镜
- 用于计算两个输入视频之间地身份得分。
- 这个滤镜接受两个输入视频。
- 为了使该滤镜正常工作，两个输入视频必须具有相同的分辨率和像素格式。它还假设两个输入具有相同数量的帧，这些帧将逐一进行比较。
- 通过日志系统，会打印出每个组件的得分、平均得分、最小得分和最大得分。
- 该滤镜将每帧计算得到的身份得分存储在帧的元数据中。
- 示例：
    - 在下面的示例中，正在处理的输入文件main.mpg将与参考文件ref.mpg进行比较。  
    ```ffmpeg -i main.mpg -i ref.mpg -lavfi identity -f null -```

##### idet 滤镜
- 用于检测视频的隔行扫描类型。
- 该滤镜尝试检测输入帧是否为隔行扫描、逐行扫描、从顶部开始的场优先还是从底部开始的场优先。它还尝试检测相邻帧之间重复的场（这是电影电视化的迹象）。
- 单帧检测仅在对每帧进行分类时考虑其紧邻的相邻帧。多帧检测则考虑前一帧的分类历史。
- 该滤镜将记录以下元数据值：
    - single.current_frame：使用单帧检测确定的当前帧的类型。可能的值之一是：“tff”（从顶部开始的场优先）、“bff”（从底部开始的场优先）、“progressive”（逐行扫描）或“undetermined”（无法确定）。
    - single.tff：使用单帧检测确定为从顶部开始的场优先的累计帧数。
    - multiple.tff：使用多帧检测确定为从顶部开始的场优先的累计帧数。
    - single.bff：使用单帧检测确定为从底部开始的场优先的累计帧数。
    - multiple.current_frame：使用多帧检测确定的当前帧的类型。可能的值之一是：“tff”（从顶部开始的场优先）、“bff”（从底部开始的场优先）、“progressive”（逐行扫描）或“undetermined”（无法确定）。
    - multiple.bff：使用多帧检测确定为从底部开始的场优先的累计帧数。
    - single.progressive：使用单帧检测确定为逐行扫描的累计帧数。
    - multiple.progressive：使用多帧检测确定为逐行扫描的累计帧数。
    - single.undetermined：使用单帧检测无法分类的累计帧数。
    - multiple.undetermined：使用多帧检测无法分类的累计帧数。
    - repeated.current_frame：当前帧中重复的场。可能的值之一是：“neither”（没有重复的场）、“top”（从前一帧的顶部场重复）或“bottom”（从前一帧的底部场重复）。
    - repeated.neither：没有重复场的累计帧数。
    - repeated.top：抱歉，上述回答截断了。以下是完整的回答：
- 该滤镜接受以下选项：
    - intl_thres：设置隔行扫描阈值。
    - prog_thres：设置逐行扫描阈值。
    - rep_thres：重复场检测的阈值。
    - half_life：在该帧的贡献统计中，经过多少帧后权重减半。默认值为0，表示所有已看到的帧都将永远被给予完整的权重1.0。
    - analyze_interlaced_flag：当不为0时，idet将使用指定的帧数来确定隔行扫描标志是否准确，它不会计算无法确定的帧。如果发现标志准确，则将在不进行任何进一步计算的情况下使用它；如果发现标志不准确，则将在不进行任何进一步计算的情况下清除标志。这允许将idet滤镜作为一种低计算方法插入以清除隔行扫描标志。
- 示例：
    - 检查视频中前360帧场次顺序：  
    ```ffmpeg -i INPUT -filter:v idet,metadata=mode=print -frames:v 360 -an -f null -```

##### il 滤镜
- il滤镜用于对交错的图像场进行处理，而无需对其进行去交错处理。去交错处理会将输入帧分成2个场（也称为半图像）。奇数行被移动到输出图像的上半部分，偶数行被移动到下半部分。您可以独立地处理（过滤）它们，然后重新交错它们。
- 该滤镜接受以下选项：
    - luma_mode或l选项
    - chroma_mode或c选项
    - alpha_mode或a选项
    - luma_mode、chroma_mode和alpha_mode的可用取值为：
        - 'none'：什么都不做。
        - 'deinterleave'或'd'：去交错，将一个场放在另一个场的上方。
        - 'interleave'或'i'：交错，恢复去交错的效果。
        - 默认值为'none'。
    - luma_swap或ls选项
    - chroma_swap或cs选项
    - alpha_swap或as选项
    - 交换亮度/色度/透明度场。交换偶数行和奇数行。默认值为0。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设我们有一个交错扫描的视频，其中包含一个小球在跳动。我们希望将视频分成两个独立的场，分别处理这两个场，然后再重新交错它们，以产生一种特殊效果。  
    ```ffmpeg -i input.mp4 -vf "il=luma_mode=deinterleave:chroma_mode=deinterleave" -c:v libx264 -crf 23 -preset medium output.mp4```

##### inflate 滤镜
- 该滤镜可以应用膨胀效果到视频中。
- 该滤镜通过将像素替换为局部（3x3）平均值来实现膨胀效果，只考虑高于该像素的值。
- 该滤镜接受以下选项：
    - threshold0
    - threshold1
    - threshold2
    - threshold3
    - 限制每个平面的最大变化，默认值为65535。如果设置为0，该平面将保持不变。
- 该滤镜接受上述所有选项作为命令使用。
- 示例：
    - 假设我们有一段视频，画面中有一些细节，我们希望将这些细节进行膨胀处理，增加它们的明亮度。  
    ```ffmpeg -i input.mp4 -vf "inflate=threshold0=200:threshold1=200:threshold2=200:threshold3=200" -c:v libx264 -crf 23 -preset medium output.mp4```

##### interlace 滤镜
- 于将逐行扫描的内容进行简单交错处理。它将奇数帧的上半部分（或下半部分）与偶数帧的下半部分（或上半部分）交错在一起，从而将帧率减半并保留图像的高度。  
- 下面是一个说明交错处理过程的示例：  
    Original        Original             New Frame  
   Frame 'j'      Frame 'j+1'             (tff)  
  ==========      ===========       ==================  
    Line 0  -------------------->    Frame 'j' Line 0  
    Line 1          Line 1  ---->   Frame 'j+1' Line 1  
    Line 2 --------------------->    Frame 'j' Line 2  
    Line 3          Line 3  ---->   Frame 'j+1' Line 3  
     ...             ...                   ...  
New Frame + 1 will be generated by Frame 'j+2' and Frame 'j+3' and so on
  
- 该滤镜接受以下选项：
    - scan（扫描）
    - 确定交错帧是从逐行扫描的进度帧的偶数行（tff，默认值）还是奇数行（bff）中获取的。

    - lowpass（低通滤波器）
    - 垂直低通滤波器，用于避免twitter交错和减少moire图案。
        - '0, off'：禁用垂直低通滤波器。
        - '1, linear'：启用线性滤波器（默认值）。
        - '2, complex'：启用复杂滤波器。这会稍微减少twitter交错和moire效应，但更好地保        - 留细节和主观清晰度印象。
- 示例：
    - 假设我们有一段逐行扫描的视频，我们希望将其转换为交错扫描的视频，以便在播放时呈现出更光滑的运动效果。  
    ```ffmpeg -i input.mp4 -vf "interlace" -c:v libx264 -crf 23 -preset medium output.mp4```

##### kerdeint 滤镜
- 通过应用Donald Graft的自适应核去交错算法对输入视频进行去交错处理。它可以处理视频中的交错部分，并生成逐行扫描的连续帧。
- 该滤镜接受以下选项：
    - thresh（阈值）
    - 设置阈值，影响滤波器在确定是否处理像素行时的容限度。它必须是一个范围在[0,255]的整数，默认值为10。阈值设置为0将会对每个像素都进行处理。

    - map（映射）
    - 如果设置为1，将超过阈值的像素绘制为白色。默认值是0。

    - order（字段顺序）
    - 设置字段的顺序。如果设置为1，则交换字段；如果设置为0，则保持字段不变。默认值是0。

    - sharp（锐化）
    - 如果设置为1，则启用额外的锐化处理。默认值是0。

    - twoway（双向锐化）
    - 如果设置为1，则启用双向锐化处理。默认值是0。
- 示例：
    - 应用默认值：  
    ```kerndeint=thresh=10:map=0:order=0:sharp=0:twoway=0```
    - 启用额外的锐化处理：  
    ```kerndeint=sharp=1```
    - 将处理后的像素绘制为白色：  
    ```kerndeint=map=1```
    - 假设我们有一段交错扫描的视频，我们希望将其转换为逐行扫描的视频，以消除交错效果并获得更清晰的图像。  
    ```ffmpeg -i input.mp4 -vf "kerndeint=thresh=10:map=0:order=0:sharp=0:twoway=0" -c:v libx264 -crf 23 -preset medium output.mp4```

##### kirsch 滤镜
- 用于将Kirsch算子应用于输入视频流。
- 该滤镜接受以下选项：
    - planes（平面）
    - 设置要处理的平面，未处理的平面将被复制。默认值为0xf，表示所有平面都将被处理。

    - scale（缩放）
    - 设置要乘以过滤结果的值。

    - delta（增量）
    - 设置要添加到过滤结果的值。
- 该滤镜支持上述所有选项作为命令使用。
    - 假设我们有一段视频，我们希望应用Kirsch算子来突出显示视频中的边缘。  
    ```ffmpeg -i input.mp4 -vf "kirsch" -c:v libx264 -crf 23 -preset medium output.mp4```

##### lagfun 滤镜
- 该滤镜用于缓慢更新较暗的像素。
- 该滤镜的作用是使短暂的亮光持续时间更长。
- 该滤镜接受以下选项：
    - decay（衰减因子）
    - 设置衰减因子的值。默认值为0.95。允许的范围是从0到1。

    - planes（平面）
    - 设置要过滤的平面。默认值为全部平面。允许的范围是从0到15。
- 概滤镜接受上述所有选项作为命令使用。
- 示例：
    - 假设我们有一段视频，其中包含一些短暂的闪光效果，我们希望通过应用"lagfun"滤镜使这些闪光效果持续时间更长。  
    ```ffmpeg -i input.mp4 -vf "lagfun=decay=0.95" -c:v libx264 -crf 23 -preset medium output.mp4```

##### lenscorrection 滤镜
- 用于纠正径向镜头畸变。
- 该滤镜可以用于纠正由广角镜头使用引起的径向畸变，并重新矫正图像。为了找到合适的参数，可以使用一些可用的工具，例如OpenCV提供的工具，或者通过尝试不同的参数进行调整。使用OpenCV时，可以使用OpenCV源代码中的calibration示例（位于samples/cpp目录下），并从结果矩阵中提取k1和k2系数。
- 需要注意的是，同样的滤镜在开源工具Krita和Digikam中也可以使用，它们是KDE项目的一部分。
- 与可以用于补偿镜头错误的vignette滤镜相比，这个滤镜纠正了图像的畸变，而vignette滤镜纠正了亮度分布。因此，在某些情况下，您可能需要同时使用这两个滤镜，不过您需要注意滤镜的顺序，即在进行镜头纠正之前或之后应用vignette滤镜。
- 示例：
    - 假设我们有一段视频，其中使用了广角镜头拍摄，导致图像出现了明显的径向畸变，我们可以通过概滤镜进行纠正畸变。  
    ```ffmpeg -i input.mp4 -vf "lenscorrection=k1=0.2:k2=0.1" -c:v libx264 -crf 23 -preset medium output.mp4```

##### Options 滤镜
- 该滤镜接受以下选项：
    - cx
    - 图像焦点的相对x坐标，也是畸变中心的相对x坐标。该值的范围为[0,1]，表示为图像宽度的分数。默认值为0.5。

    - cy
    - 图像焦点的相对y坐标，也是畸变中心的相对y坐标。该值的范围为[0,1]，表示为图像高度的分数。默认值为0.5。

    - k1
    - 二次校正项的系数。该值的范围为[-1,1]。0表示无校正。默认值为0。
    
    - k2
    - 双重二次校正项的系数。该值的范围为[-1,1]。0表示无校正。默认值为0。
    
    - i
    - 设置插值类型。可选值为nearest或bilinear。默认值为nearest。
    
    - fc
    - 指定未映射像素的颜色。有关此选项的语法，请参阅ffmpeg-utils手册中的"(ffmpeg-utils)"Color"部分。默认颜色为black@0。
- 生成校正的公式为：  
```r_src = r_tgt * (1 + k1 * (r_tgt / r_0)^2 + k2 * (r_tgt / r_0)^4)```  
其中r_0是图像对角线的一半，r_src和r_tgt分别是源图像和目标图像中距离焦点的距离。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设我们有一段使用广角镜头拍摄的视频，其中图像呈现出鱼眼效果，我们可以使用该滤镜来纠正这种鱼眼畸变。  
    ```ffmpeg -i input.mp4 -vf "lenscorrection=cx=0.5:cy=0.5:k1=-0.2:k2=0.1" -c:v libx264 -crf 23 -preset medium output.mp4```

##### lensfun 滤镜
- Lensfun是一个库，可通过它来应用镜头校正。您可以使用lensfun库中的lensfun滤镜来进行镜头校正操作。您可以通过lensfun滤镜提供相机品牌、相机型号和镜头型号等信息，该滤镜将加载lensfun数据库并查询数据库以找到相应的相机和镜头条目。只要根据给定的选项可以找到这些条目，滤镜就可以对帧进行校正。请注意，如果提供的信息不完整，滤镜将选择与给定选项最匹配的结果，并将选择的相机和镜头型号记录在日志中（以"info"级别记录）。您必须提供所需的相机品牌、相机型号和镜头型号。
- 要获取可用的相机品牌和型号列表，可以省略make和/或model选项。滤镜将在日志中以INFO级别发送完整的列表。第一列是品牌，第二列是型号。要获取可用的镜头列表，请设置make和model的任意值，并省略lens_model选项。滤镜将在日志中以INFO级别发送完整的镜头列表。在打印完列表后，ffmpeg工具将退出。
- 该滤镜接受以下选项：
    - make
    - 相机的品牌（例如："Canon"）。此选项是必需的。

    - model
    - 相机的型号（例如："Canon EOS 100D"）。此选项是必需的。

    - lens_model
    - 镜头的型号（例如："Canon EF-S 18-55mm f/3.5-5.6 IS STM"）。此选项是必需的。

    - db_path
    - 镜头数据库文件夹的完整路径。如果未设置，滤镜将尝试从构建库时的安装路径加载数据库。默认未设置。

    - mode
    - 要应用的校正类型。以下值是有效选项：

    - 'vignetting'
    - 启用修复镜头暗角。

    - 'geometry'（默认值）
    - 启用修复镜头几何形状。

    - 'subpixel'
    - 启用修复色差。

    - 'vig_geo'
    - 启用修复镜头暗角和几何形状。

    - 'vig_subpixel'
    - 启用修复镜头暗角和色差。

    - 'distortion'
    - 启用修复镜头几何形状和色差。

    - 'all'
    - 启用所有可能的校正。

    - focal_length
    - 图像/视频的焦距（变焦；对于视频，预期为恒定值）。例如，一个18-55mm镜头的焦距范围是[18-55]，因此在使用该镜头时应选择该范围内的值。默认值为18。

    - aperture
    - 图像/视频的光圈（对于视频，预期为恒定值）。请注意，光圈仅用于暗角校正。默认值为3.5。

    - focus_distance
    - 图像/视频的对焦距离（对于视频，预期为恒定值）。请注意，对焦距离仅用于暗角校正，并且对暗角校正过程的影响较小。如果不知道，请将其保留为默认值（默认值为1000）。

    - scale
    - 在变换后应用的比例因子。校正后的视频不一定是矩形的。该参数控制输出图像中可见的校正图像的比例。值0表示会自动选择一个值，以使输出图像中的未映射区域很少或没有。1.0表示不进行额外的缩放。较低的值可能导致更多校正后的图像可见，而较高的值可能避免输出中的未映射区域。

    - target_geometry
    - 输出图像/视频的目标几何形状。以下值是有效选项：
        - 'rectilinear（默认值）'rectilinear（默认值）'表示矩形图像；
        - 'fisheye'表示鱼眼图像；
        - 'panoramic'表示全景图像；
        - 'equirectangular'表示全景图像（等距矩形投影）；
        - 'fisheye_orthographic'表示鱼眼图像（正交投影）；
        - 'fisheye_stereographic'表示鱼眼图像（立体投影）；
        - 'fisheye_equisolid'表示鱼眼图像（等面积投影）；
        - 'fisheye_thoby'表示鱼眼图像（Thoby投影）。

    - reverse
    - 应用图像校正的反向操作（即应用畸变而不是校正畸变）。
    
    - interpolation
    - 校正畸变时使用的插值类型。以下值是有效选项：
        - 'nearest'表示最近邻插值；
        - 'linear（默认值）'表示线性插值；
        - 'lanczos'表示Lanczos插值。
- 示例：
    - 应用make为"Canon"，相机型号为"Canon EOS 100D"，镜头型号为"Canon EF-S 18-55mm f/3.5-5.6 IS STM"，焦距为"18"，光圈为"8.0"的镜头校正。  
    ```ffmpeg -i input.mov -vf lensfun=make=Canon:model="Canon EOS 100D":lens_model="Canon EF-S 18-55mm f/3.5-5.6 IS STM":focal_length=18:aperture=8 -c:v h264 -b:v 8000k output.mov```
    - 与前面的示例相同，但仅对视频的前5秒应用镜头校正。  
    ```ffmpeg -i input.mov -vf lensfun=make=Canon:model="Canon EOS 100D":lens_model="Canon EF-S 18-55mm f/3.5-5.6 IS STM":focal_length=18:aperture=8:enable='lte(t\,5)' -c:v h264 -b:v 8000k output.mov```

##### libplacebo 滤镜
- 一个灵活的基于libplacebo库的GPU加速处理滤镜。
- 具体请前往官网查询使用说明。

##### libvmaf 滤镜
- 一个用于计算视频多方法评估融合（Video Multi-Method Assessment Fusion）分数的库。它通过比较参考视频和失真视频的内容来评估视频质量，并通过日志系统打印得到的VMAF分数。
- libvmaf需要Netflix的vmaf库（libvmaf）作为前提条件。安装库后，可以使用"./configure --enable-libvmaf"命令启用它。
- 该滤镜接受以下选项：
    - model: vmaf模型的列表，以'|'分隔。每个模型都可以配置多个参数。默认值为"version=vmaf_v0.6.1"。
    - feature: 特征的列表，以'|'分隔。每个特征都可以配置多个参数。
    - log_path: 设置用于存储日志文件的文件路径。
    - log_fmt: 设置日志文件的格式（xml、json、csv或sub）。
    - pool: 设置用于计算vmaf的池方法。选项为min、harmonic_mean或mean（默认为mean）。
    - n_threads: 设置在初始化libvmaf时要使用的线程数。默认值为0，即无线程。
    - n_subsample: 设置要使用的帧子采样间隔。
- 此滤镜还支持framesync选项，用于同步处理视频帧。
- 以下是使用libvmaf的一些示例，通过比较失真视频distorted.mpg与参考文件reference.mpg来计算VMAF分数。
    - 基本用法：  
    ```ffmpeg -i distorted.mpg -i reference.mpg -lavfi libvmaf=log_path=output.xml -f null -```
    - 使用多个模型的示例：  
    ```ffmpeg -i distorted.mpg -i reference.mpg -lavfi libvmaf='model=version=vmaf_v0.6.1\\:name=vmaf|version=vmaf_v0.6.1neg\\:name=vmaf_neg' -f null -```
    - 使用多个附加特征的示例：  
    ```ffmpeg -i distorted.mpg -i reference.mpg -lavfi libvmaf='feature=name=psnr|name=ciede' -f null -```
    - 带有选项和不同容器的示例：  
    ```ffmpeg -i distorted.mpg -i reference.mkv -lavfi "[0:v]settb=AVTB,setpts=PTS-STARTPTS[main];[1:v]settb=AVTB,setpts=PTS-STARTPTS[ref];[main][ref]libvmaf=log_fmt=json:log_path=output.json" -f null -```

##### limitdiff 滤镜
- 用于根据第二个（可选第三个）视频流应用有限差异过滤。
- 该滤镜接受以下选项：
    - threshold：设置在允许视频流之间的某些差异时使用的阈值。任何绝对差异值小于等于该阈值的像素组件将从第一个视频流中选择。

    - elasticity：设置处理视频流时软阈值的弹性。该值乘以第一个阈值来设置第二个阈值。任何绝对差异值大于等于第二个阈值的像素组件将从第二个视频流中选择。对于介于这两个阈值之间的值，将使用第一个和第二个视频流之间的线性插值。

    - reference：启用参考（第三个）视频流的处理。默认情况下禁用。如果设置，将使用该视频流与第一个视频流计算绝对差异。

    - planes：指定要处理的平面。默认为所有可用平面。
- 除了选项reference外，此滤镜还支持将上述所有选项作为命令使用。

##### limiter 滤镜
- 用于将像素组件的值限制在指定的范围[min, max]内。
- 该滤镜接受以下选项：
    - min：下限。默认为输入允许的最低值。
    - max：上限。默认为输入允许的最高值。
    - planes：指定要处理的平面。默认为所有可用平面。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一个视频文件 input.mp4，其中的像素值范围在0到1023之间。你希望将像素值限制在0到255的范围内，以便在输出视频中显示更明亮和对比度更高的图像。  
    ```ffmpeg -i input.mp4 -vf "limiter=min=0:max=255" output.mp4```

##### loop 滤镜
- 用于循环播放视频帧。
- 该滤镜接受以下选项：
    - loop：设置循环的次数。将该值设置为-1将导致无限循环。默认值为0。
    - size：设置循环的最大帧数。默认值为0。
    - start：设置循环的第一帧。默认值为0。
    - time：设置循环开始的时间（以秒为单位）。仅当选项start设置为-1时使用。
- 示例：
    - 无限循环播放单个第一帧：  
    ```loop=loop=-1:size=1:start=0```
    - 循环播放单个第一帧10次：  
    ```loop=loop=10:size=1:start=0```
    - 循环播放前10帧5次：  
    ```loop=loop=5:size=10:start=0```
    - 假设你有一个视频文件input.mp4，你希望将视频循环播放3次，即播放完一次后再次重复播放两次。  
    ```ffmpeg -i input.mp4 -filter_complex "[0:v]loop=loop=2:size=1:start=0[out]" -map "[out]" output.mp4```

##### lut1d 滤镜
- 用于将一维查色表（1D LUT）应用于输入视频。
- 该滤镜接受以下选项：
    - file：设置1D LUT文件的名称。
    - 目前支持的格式有：
        - cube：Iridas格式
        - csp：cineSpace格式
        - interp：选择插值模式。
    - 可用的取值有：
        - nearest：使用最近定义的点的值。
        - linear：使用线性插值来插值值。
        - cosine：使用余弦插值来插值值。
        - cubic：使用立方插值来插值值。
        - spline：使用样条插值来插值值。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一个视频文件input.mp4，你希望应用一个1D LUT来增加视频的对比度和饱和度。  
    ```ffmpeg -i input.mp4 -vf "lut1d=file=contrast_lut.cube:interp=linear" output.mp4```

##### lut3d 滤镜
- 用于将3D LUT应用于输入视频。
- 该滤镜接受以下选项：
    - file：设置3D LUT文件名。
    - 目前支持的格式有：
        - 3dl：AfterEffects格式。
        - cube：Iridas格式。
        - dat：DaVinci格式。
        - m3d：Pandora格式。
        - csp：cineSpace格式。
        - interp：选择插值模式。
    - 可用的取值有：
        - nearest：使用最近定义的点的值。
        - trilinear：使用定义一个立方体的8个点进行插值计算。
        - tetrahedral：使用四面体进行插值计算。
        - pyramid：使用金字塔进行插值计算。
        - prism：使用棱柱进行插值计算。
- 该滤镜支持上述interp选项作为命令使用。
- 示例：  
    ```ffmpeg -i input.mp4 -vf "lut3d=file=adjustment_lut.cube:interp=trilinear" output.mp4```

##### lumakey 滤镜
- 用于将特定亮度值转换为透明度。
- 该滤镜接受以下选项：
    - threshold：设置用作透明度基础的亮度值。默认值为0。
    - tolerance：设置要键掉的亮度值范围。默认值为0.01。
    - softness：设置软化范围。默认值为0。使用此选项可以控制从零到完全透明的逐渐过渡。
- 命令接受与相应选项相同的语法。
- 如果指定的表达式无效，那么选项的值将保持不变，即保持其当前值。
- 示例：
    - 假设你有一个名为input.mp4的视频文件，其中包含一个绿色背景。你希望将绿色背景转换为透明度，并将结果保存为output.mp4。  
    ```ffmpeg -i input.mp4 -vf "lumakey=color=green:similarity=0.1" -c:a copy -c:v libx264 -preset fast -crf 18 -pix_fmt yuv420p -movflags +faststart output.mp4```

##### lut、lutrgb和lutyuv 滤镜
- 用于计算并应用查找表（look-up table）到输入视频的像素分量。
- 该滤镜接受以下参数：
    - c0：设置第一个像素分量的表达式。
    - c1：设置第二个像素分量的表达式。
    - c2：设置第三个像素分量的表达式。
    - c3：设置第四个像素分量的表达式，对应于透明度分量。
    - r：设置红色分量的表达式。
    - g：设置绿色分量的表达式。
    - b：设置蓝色分量的表达式。
    - a：设置透明度分量的表达式。
    - y：设置Y/luma分量的表达式。
    - u：设置U/Cb分量的表达式。
    - v：设置V/Cr分量的表达式。
- 每个参数都指定用于计算相应像素分量值的查找表的表达式。
- 具体与每个c*选项关联的分量取决于输入的格式。
- lut滤镜要求输入为YUV或RGB像素格式，lutrgb要求输入为RGB像素格式，lutyuv要求输入为YUV像素格式。
- 这些表达式可以包含以下常量和函数：
    - w：输入的宽度。
    - h：输入的高度。
    - val：像素分量的输入值。
    - clipval：输入值，剪裁到minval-maxval范围内。
    - maxval：像素分量的最大值。
    - minval：像素分量的最小值。
    - negval：像素分量值的负值，剪裁到minval-maxval范围内；它对应于表达式“maxval-clipval+minval”。
    - clip(val)：将计算值val剪裁到minval-maxval范围内。
    - gammaval(gamma)：像素分量值的计算伽马校正值，剪裁到minval-maxval范围内。它对应于表达式“pow((clipval-minval)/(maxval-minval),gamma)*(maxval-minval)+minval”。
    -所有表达式默认为"clipval"
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 反转输入视频：  
    ```lutrgb="r=negval:g=negval:b=negval"```  
    ```lutyuv="y=negval:u=negval:v=negval"```
    - 反转亮度（luma）：  
    ```lutyuv=y=negval```
    - 移除色度分量，将视频转为灰度图像：  
    ```lutyuv="u=128:v=128"```
    - 应用亮度烧焦效果：  
    ```lutyuv="y=2*val"```
    - 移除绿色和蓝色分量：  
    ```lutrgb="g=0:b=0"```
    - 在输入上设置一个恒定的透明度通道值：  
    ```format=rgba,lutrgb=a="maxval-minval/2"```
    - 使用0.5的因子校正亮度伽马：  
    ```lutyuv=y=gammaval(0.5)```
    - 丢弃亮度的最低有效位：  
    ```lutyuv=y='bitand(val, 128+64+32)'```
    - Technicolor（技术彩色）效果：  
    ```lutyuv=u='(val-maxval/2)*2+maxval/2':v='(val-maxval/2)*2+maxval/2'```

##### lut2和tlut2 滤镜
- 用于处理两个输入流的像素，并生成一个输出流。
- lut2滤镜接受两个输入流，并根据指定的表达式计算像素分量的查找表，然后将结果输出为一个流。
- tlut2（time lut2）滤镜从单个输入流中获取两个连续的帧，并根据指定的表达式计算像素分量的查找表，然后将结果输出为一个流。
- 该滤镜接受以下参数：
    - c0：设置第一个像素分量的表达式。
    - c1：设置第二个像素分量的表达式。
    - c2：设置第三个像素分量的表达式。
    - c3：设置第四个像素分量的表达式，对应于透明度分量。
    - d：设置输出的位深度（仅适用于lut2滤镜）。默认值为0，表示位深度将根据第一个输入的格式自动选择。
- 每个参数都指定用于计算相应像素分量值的查找表的表达式。
- 与每个c*选项关联的分量取决于输入的格式。
- 这些表达式可以包含以下常量：
    - w：输入的宽度。
    - h：输入的高度。
    - x：像素分量的第一个输入值。
    - y：像素分量的第二个输入值。
    - bdx：第一个输入视频的位深度。
    - bdy：第二个输入视频的位深度。
    - 所有表达式默认为“x”。
- 选项 d（设置输出的位深度）以外，该滤镜支持上述所有选项作为命令来使用。
- 示例：
    - 突出显示两个RGB视频流之间的差异：  
    ```lut2='ifnot(x-y,0,pow(2,bdx)-1):ifnot(x-y,0,pow(2,bdx)-1):ifnot(x-y,0,pow(2,bdx)-1)'```
    - 突出显示两个YUV视频流之间的差异：  
    ```lut2='ifnot(x-y,0,pow(2,bdx)-1):ifnot(x-y,pow(2,bdx-1),pow(2,bdx)-1):ifnot(x-y,pow(2,bdx-1),pow(2,bdx)-1)'```
    - 显示两个视频流之间的最大差异：  
    ```lut2='if(lt(x,y),0,if(gt(x,y),pow(2,bdx)-1,pow(2,bdx-1))):if(lt(x,y),0,if(gt(x,y),pow(2,bdx)-1,pow(2,bdx-1))):if(lt(x,y),0,if(gt(x,y),pow(2,bdx)-1,pow(2,bdx-1)))'```

##### maskedclamp 滤镜
- 用于将第一个输入流限制在第二个输入流和第三个输入流之间。
- 该滤镜将第一个流的值限制在第二个流的值（减去undershoot）和第三个流的值（加上overshoot）之间。
- 该滤镜接受以下选项：
    - undershoot：默认值为0。表示下限，即第二个输入流的值减去的偏移量。
    - overshoot：默认值为0。表示上限，即第三个输入流的值加上的偏移量。
    - planes：设置要作为位图处理的平面，未处理的平面将从第一个输入流复制。默认值为0xf，表示所有平面都将被处理。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设原始视频文件的路径是input.mp4，掩码视频文件的路径是mask.mp4，我们希望将原始视频的像素值限制在掩码视频的像素值加上10和减去20之间。  
    ```ffmpeg -i input.mp4 -i mask.mp4 -filter_complex "[0:v][1:v]maskedclamp=undershoot=20:overshoot=10[outv]" -map "[outv]" output.mp4```

##### maskedmax 滤镜
- 用于将第二个输入流和第三个输入流合并成输出流。合并的方式是根据第二个输入流与第一个输入流的绝对差异和第三个输入流与第一个输入流的绝对差异来选择值。如果第二个绝对差异大于第一个绝对差异，则选取第二个输入流的值；否则，选取第三个输入流的值。
- 该滤镜接受以下选项：
    - planes：设置要作为位图处理的平面，未处理的平面将从第一个输入流复制。默认值为0xf，表示所有平面都将被处理。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设原始视频文件的路径是input.mp4，修复视频文件的路径是repair.mp4，我们希望在生成的合成视频中，如果修复视频的像素值与原始视频的像素值的差异大于原始视频与修复视频的差异，那么选择修复视频的像素值；否则，选择原始视频的像素值。  
    ```ffmpeg -i input.mp4 -i repair.mp4 -filter_complex "[1:v][0:v][0:v]maskedmax[outv]" -map "[outv]" output.mp4```

##### maskedmerge 滤镜
- 用于将第一个输入流与第二个输入流进行合并，使用第三个输入流中的每个像素权重。
- 第三个输入流中的像素分量为0表示保持第一个流的像素分量不变，而最大值（例如8位视频的255）表示保持第二个流的像素分量不变。中间值定义了两个输入流像素分量之间的合并程度。
- 该滤镜接受以下选项：
    - planes：设置要作为位图处理的平面，未处理的平面将从第一个流复制。默认值为0xf，表示所有平面都将被处理。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 当使用maskedmerge滤镜时，一个通俗的例子可以是将两个视频叠加在一起，并使用掩码视频来控制每个像素的叠加权重。这可以用来创建一个视频效果，其中一个视频在另一个视频上以不透明度的方式显示出来。
    - 我们将使用maskedmerge滤镜将video2.mp4叠加在video1.mp4上，其中mask.mp4将控制叠加的不透明度。  
    ```ffmpeg -i video1.mp4 -i video2.mp4 -i mask.mp4 -filter_complex "[0:v][1:v][2:v]maskedmerge=planes=0xf" output.mp4```

##### maskedmin 滤镜
- 用于将第二个输入流和第三个输入流合并到输出流中。合并过程基于第二个输入流与第一个输入流的绝对差异，以及第三个输入流与第一个输入流的绝对差异。如果第二个绝对差异小于第一个绝对差异，则选择第二个输入流的值；否则选择第三个输入流的值。
- 该滤镜接受以下选项：
    - planes：设置要作为位图处理的平面，未处理的平面将从第一个流复制。默认值为0xf，表示所有平面都将被处理。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 当使用maskedmin滤镜时，一个通俗易懂的例子可以是将两个视频进行混合，并根据像素之间的差异选择合适的像素值。这可以用于创建一个视频效果，其中两个视频的像素根据它们与参考视频之间的差异进行混合。
    - 在这个例子中，我们将使用maskedmin滤镜将video1.mp4和video2.mp4混合在一起，根据它们与reference.mp4之间的差异选择合适的像素值。  
    ```ffmpeg -i reference.mp4 -i video1.mp4 -i video2.mp4 -filter_complex "[1:v][2:v][0:v]maskedmin=planes=0xf" output.mp4```

##### maskedthreshold 滤镜
- 用于根据两个视频流之间的绝对差异和用于提供的阈值选择像素。
- 如果第一个视频流和第二个视频流的像素分量的绝对差异小于等于用户提供的阈值，则选择第一个视频流的像素分量；否则选择第二个视频流的像素分量。
- 该滤镜接受以下选项：
    - threshold：设置用于从两个输入视频流的绝对差异中选择像素时使用的阈值。
    - planes：设置要作为位图处理的平面，未处理的平面将从第二个流复制。默认值为0xf，表示所有平面都将被处理。
    - mode：设置滤镜操作的模式。可以是“abs”（绝对值）或“diff”（差异）。默认值为“abs”。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 当使用maskedthreshold滤镜时，一个通俗易懂的例子可以是将两个视频进行混合，并根据像素之间的差异选择合适的像素值，只有当差异小于等于给定的阈值时才选择第一个视频的像素。
    - 我们将使用maskedthreshold滤镜将video1.mp4和video2.mp4混合在一起，根据它们之间的像素差异选择合适的像素值。  
    ```ffmpeg -i video1.mp4 -i video2.mp4 -filter_complex "[0:v][1:v]maskedthreshold=threshold=20:planes=0xf:mode=abs" output.mp4```

##### maskfun 滤镜
- 用于从输入视频创建掩码（mask）。
- 例如，在使用tblend滤镜后创建运动掩码是很有用的。
- 该滤镜接受以下选项：
    - low：设置低阈值。低于或等于该值的任何像素分量将被设置为0。
    - high：设置高阈值。高于该值的任何像素分量将被设置为当前像素格式允许的最大值。
    - planes：设置要过滤的平面，默认情况下，将过滤所有可用的平面。
    - fill：用该值填充所有帧像素。
    - sum：设置帧的最大平均像素值。如果所有像素分量的总和超过此平均值，则输出帧将完全填充为由fill选项设置的值。通常与tblend滤镜结合使用时，在场景变化时非常有用。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 当使用maskfun滤镜时，一个通俗易懂的例子可以是创建一个运动掩码，用于标识视频中的运动区域。
    - 在这个例子中，我们将使用maskfun滤镜从video.mp4创建一个运动掩码。  
    ```ffmpeg -i video.mp4 -vf "tblend=average,maskfun=low=30:high=220:planes=0xf:fill=255:sum=500" output.mp4```

##### mcdeint 滤镜
- 用于应用运动补偿去隔行。
- 它需要每帧一个场的输入，并且必须与yadif=1/3或等效的滤镜一起使用。
- 该滤镜接受以下选项：
    - mode：设置去隔行模式。可以接受以下值之一：
        - 'fast'：快速模式
        - 'medium'：中等模式
        - 'slow'：慢速模式，使用迭代运动估计
        - 'extra_slow'：类似于慢速模式，但使用多个参考帧
        - 默认值为'fast'。
    - parity：设置输入视频的图像场奇偶性。必须是以下值之一：
        - '0, tff'：假设顶场先
        - '1, bff'：假设底场先
        - 默认值为'bff'。
    - qp：设置内部编码器使用的每个块的量化参数（QP）。
        - 较高的值应该会产生更平滑的运动矢量场，但较不理想的单个矢量。
        - 默认值为1。

##### median 滤镜
- 用于从由半径定义的矩形区域中选择中位数像素。
- 该滤镜接受以下选项：
    - radius：设置水平半径大小。默认值为1。允许的范围是1到127之间的整数。
    - planes：设置要处理的平面。默认值为15，表示所有可用的平面。
    - radiusV：设置垂直半径大小。默认值为0。允许的范围是0到127之间的整数。如果设置为0，则将使用水平半径选项的值。
    - percentile：设置中位数百分位数。默认值为0.5。0.5表示始终选择中位数值，0表示选择最小值，1表示选择最大值。
- 滤镜支持与选项相同的命令。通过命令，您可以在运行时动态地更改滤镜的参数值。
- 如果指定的表达式无效，滤镜将保持当前的值，不会进行修改。
- 示例：
    - 当使用median滤镜时，一个通俗易懂的例子可以是在视频中应用中值滤波器，以减少图像中的噪点。
    - 在这个例子中，我们将使用median滤镜对noisy_video.mp4中的图像进行中值滤波。  
    ```ffmpeg -i noisy_video.mp4 -vf "median=radius=2:planes=15" -c:v libx264 -preset medium -crf 23 -c:a copy denoised_video.mp4```

##### mergeplanes 滤镜
- 用于将多个视频流中的颜色通道分量合并。
- 该滤镜最多接受4个输入流，并将选定的输入平面合并到输出视频中。
- 该滤镜接受以下选项：
    - mapping：设置输入到输出平面的映射关系。默认值为0。
    - 映射关系以位图的形式指定。它应该以十六进制数的形式表示，格式为0xAa[Bb[Cc[Dd]]]。'Aa'描述输出流的第一个平面的映射。'A'设置要使用的输入流的编号（从0到3），'a'设置要使用的相应输入的平面编号（从0到3）。其余的映射关系类似，'Bb'描述输出流的第二个平面的映射，'Cc'描述输出流的第三个平面的映射，'Dd'描述输出流的第四个平面的映射。
    - format：设置输出像素格式。默认值为yuva444p。
    - map0s、map1s、map2s、map3s：设置输出的第N个平面的输入到输出流的映射关系。默认值为0。
    - map0p、map1p、map2p、map3p：设置输出的第N个平面的输入到输出平面的映射关系。默认值为0。
- 示例：
    - 将三个相同宽度和高度的灰度视频流合并为单个视频流，输出为yuv444p格式：  
    ```[a0][a1][a2]mergeplanes=0x001020:yuv444p```
    - 将第一个yuva444p流和第二个灰度视频流合并为yuva444p视频流：  
    ```[a0][a1]mergeplanes=0x00010210:yuva444p```
    - 在yuva444p流中交换Y和A平面：  
    ```format=yuva444p,mergeplanes=0x03010200:yuva444p```
    - 在yuv420p流中交换U和V平面：  
    ```format=yuv420p,mergeplanes=0x000201:yuv420p```
    - 将rgb24剪辑转换为yuv444p格式：  
    ```format=rgb24,mergeplanes=0x000102:yuv444p```
    - 当使用mergeplanes滤镜时，一个通俗易懂的例子可以是将红色、绿色和蓝色通道的图像合并为彩色图像。
    - 在这个例子中，我们将使用mergeplanes滤镜将这三个通道的图像合并为彩色图像。  
    ```ffmpeg -i red_channel.mp4 -i green_channel.mp4 -i blue_channel.mp4 -filter_complex "[0:v][1:v][2:v]mergeplanes=0x001020:yuv444p" -c:v libx264 -preset medium -crf 23 -c:a copy color_image.mp4```

##### mestimate 滤镜
- 用于使用块匹配算法估计和导出运动矢量。运动矢量存储在帧边数据中，供其他滤镜使用。
- 该滤镜接受以下选项：
    - method：指定运动估计方法。可接受以下值：
        - 'esa'：穷举搜索算法（Exhaustive search algorithm）。
        - 'tss'：三步搜索算法（Three step search algorithm）。
        - 'tdls'：二维对数搜索算法（Two dimensional logarithmic search algorithm）。
        - 'ntss'：新的三步搜索算法（New three step search algorithm）。
        - 'fss'：四步搜索算法（Four step search algorithm）。
        - 'ds'：菱形搜索算法（Diamond search algorithm）。
        - 'hexbs'：基于六边形的搜索算法（Hexagon-based search algorithm）。
        - 'epzs'：增强预测区域搜索算法（Enhanced predictive zonal search algorithm）。
        - 'umh'：不均匀多六边形搜索算法（Uneven multi-hexagon search algorithm）。
        - 默认值为'esa'。
    -   mb_size：宏块大小。默认值为16。
    - search_param：搜索参数。默认值为7。

##### midequalizer 滤镜
- 用于应用中间图像均衡化效果，通过使用两个视频流来调整图像的直方图，同时尽可能保持它们的动态范围。这对于匹配来自一堆独立相机的曝光非常有用。
- 该滤镜有两个输入和一个输出，输出必须具有相同的像素格式，但可以具有不同的尺寸。滤镜的输出是第一个输入图像与两个输入图像的中间直方图调整后的结果。
- 该滤镜接受以下选项：
    - planes：设置要处理的平面。默认值为15，表示所有可用平面。
- 示例：
    - 一个通俗易懂的例子是使用 midequalizer 滤镜来匹配一对立体相机拍摄的图像的曝光。  
    ```ffmpeg -i left_image.jpg -i right_image.jpg -filter_complex "[0:v][1:v]midequalizer" -c:v libx264 -preset medium -crf 23 -c:a copy output.mp4```

##### minterpolate 滤镜
- 用于使用运动插值将视频转换为指定的帧率。
- 该滤镜接受以下选项：
    - fps：指定输出帧率。可以使用有理数表示，例如 60000/1001。如果输出帧率低于源帧率，则会丢帧。默认值为 60。
    - mi_mode：运动插值模式。可以使用以下值：
        - 'dup'：为插值的新帧复制前一帧或后一帧。
        - 'blend'：对源帧进行混合。插值的帧是前一帧和后一帧的平均值。
        - 'mci'：运动补偿插值。当选择这个模式时，以下选项生效：
        - mc_mode：运动补偿模式。可以使用以下值：
        - 'obmc'：重叠块运动补偿。
        - 'aobmc'：自适应重叠块运动补偿。根据相邻运动矢量的可靠性自适应地控制窗口加权系数，以减少过度平滑。
        - 默认模式是 'obmc'。
    - me_mode：运动估计模式。可以使用以下值：
        - 'bidir'：双向运动估计。对于每个源帧，在正向和反向方向上估计运动矢量。
        - 'bilat'：双边运动估计。直接为插值帧估计运动矢量。
        - 默认模式是 'bilat'。
    - me：用于运动估计的算法。可以使用以下值：
        - 'esa'：穷举搜索算法。
        - 'tss'：三步搜索算法。
        - 'tdls'：二维对数搜索算法。
        - 'ntss'：新的三步搜索算法。
        - 'fss'：四步搜索算法。
        - 'ds'：钻石搜索算法。
        - 'hexbs'：基于六边形的搜索算法。
        - 'epzs'：增强预测区域搜索算法。
        - 'umh'：不均匀多六边形搜索算法。
        - 默认算法是 'epzs'。
    - mb_size：宏块大小。默认值为 16。
    - search_param：运动估计搜索参数。默认值为 32。
    - vsbmc：启用变尺寸块运动补偿。在对象边界处，使用较小的块大小应用运动估计，以减少模糊。默认值为 0（禁用）。
    - scd：场景变化检测方法。场景变化会导致运动矢量随机分布。场景变化检测会用复制的帧替换插值帧。对于其他模式可能不需要此选项。可以使用以下值：
    - 'none'：禁用场景变化检测。
    - 'fdiff'：帧差异。对应像素值进行比较，如果满足 scd_threshold，则检测到场景变化。
    - 默认方法是 'fdiff'。
    - scd_threshold：场景变化检测阈值。默认值为 10。
- 示例;
    - 假设你有一个源视频文件 input.mp4，它的帧率是 30 帧每秒，你想将其转换为 60 帧每秒的视频，使用运动插值来平滑动画。  
    ```ffmpeg -i input.mp4 -filter_complex "minterpolate=fps=60:mi_mode=blend" -c:v libx264 -preset medium -crf 23 -c:a copy output.mp4```

##### mix 滤镜
- 将多个视频输入流混合成一个视频流。
- 该滤镜接受以下选项：
    - inputs：这是指定输入的视频流数量的选项。如果没有指定，默认为 2。
    - weights：这是指定每个输入视频流的权重的选项。每个权重之间用空格分隔。如果权重的数量小于指定的帧数，则剩余的权重将使用最后一个设置的权重。
    - scale：这是指定缩放值的选项。如果设置了缩放值，它将与每个权重乘以像素值的总和相乘，得到最终的目标像素值。默认情况下，缩放值将自动缩放为权重的总和。
    - planes：这是指定要过滤的平面的选项。默认为全部平面。允许的范围是从 0 到 15。
    - duration：这是指定如何确定流的结束的选项。
    - 'longest'：最长输入的持续时间。（默认）
    - 'shortest'：最短输入的持续时间。
    - 'first'：第一个输入的持续时间。
- 该混合滤镜支持以下选项：
    - weights
    - scale
    - planes
    - 这些命令的语法与之前提到的选项相同。
- 示例：
    - 假设你有两个视频文件，一个是一只猫在玩耍，另一个是一只狗在奔跑。你想将这两个视频混合成一个视频，即同时显示猫和狗的画面。  
    ```ffmpeg -i cat.mp4 -i dog.mp4 -filter_complex "[0:v]setpts=PTS-STARTPTS, scale=640x480 [cat]; [1:v]setpts=PTS-STARTPTS, scale=640x480 [dog]; [cat][dog]overlay=shortest=1" -c:v libx264 -preset medium -crf 23 -c:a copy output.mp4```

##### monochrome 滤镜
- 可以将视频转换为灰度图像，并使用自定义的颜色滤镜。
- 该滤镜接受以下选项：
    - cb：设置色度蓝色通道的偏移。允许的范围是从 -1 到 1。默认值为 0。
    - cr：设置色度红色通道的偏移。允许的范围是从 -1 到 1。默认值为 0。
    - size：设置颜色滤镜的大小。允许的范围是从 0.1 到 10。默认值为 1。
    - high：设置高亮强度。允许的范围是从 0 到 1。默认值为 0。
- 该滤镜支持上述所有选项作为命令使用。
    - 但是再最新版本的ffmpeg中没有了monochrome滤镜，可以使用colorchannelmixer滤镜来实现。
    - 假设你有一段彩色视频，你想将其转换为灰度图像，并增强高亮部分的强度，使它们更加突出。  
    ```ffmpeg -i input.mp4 -vf "colorchannelmixer=0.299:0.587:0.114" -c:v libx264 -crf 23 -c:a copy output.mp4```

##### morpho 滤镜
- 可以应用主要的形态学灰度变换，如腐蚀和膨胀，并使用第二个输入流中设置的任意结构。
- 与腐蚀和膨胀滤镜的朴素实现和更慢的性能不同，当速度至关重要时，应使用morpho滤镜。
- 该滤镜接受以下选项：
    - mode：设置要应用的形态学变换，可以是以下之一：
        - erode：腐蚀
        - dilate：膨胀
        - open：开运算
        - close：闭运算
        - gradient：梯度
        - tophat：顶帽
        - blackhat：黑帽
        - 默认值为 erode。
    - planes：设置要过滤的平面，默认情况下除了 alpha 之外的所有平面都会被过滤。
    - structure：设置视频帧将从第二个输入流中处理的结构，可以是 first 或 all。默认值为 all。
    - 该滤镜还支持framesync选项，这些选项用于处理帧同步。
- 该滤镜支持上述所有选项作为命令使用。

##### mpdecimate 滤镜
- 用于根据前一帧的差异来丢弃不显著的帧，从而降低帧率。
- 这个滤镜的主要用途是在非常低比特率的编码中（例如通过拨号调制解调器进行流媒体传输），但也可以用于修复错误逆电视化的电影。
- 该滤镜接受以下选项：
    - max：设置连续可丢弃的最大帧数（如果为正数），或连续丢弃帧之间的最小间隔（如果为负数）。如果值为0，则不考虑前面连续丢弃的帧数。
    - 默认值为0。
    - keep：设置在开始丢弃之前要忽略的连续相似帧的最大数量。如果值为0，则不考虑前面连续相似的帧数。
    - 默认值为0。
    - hi、lo、frac：设置丢弃的阈值。
    - hi 和 lo 的值是针对 8x8 像素块的，并表示实际像素值之间的差异。因此，阈值为 64 相当于每个像素的 1 个单位的差异，或者在整个块上以不同方式分布的相同差异。
    - 如果没有任何 8x8 块的差异超过 hi 的阈值，并且没有超过 lo 的阈值的块数（1 表示整个图像）超过 frac 的块数，则该帧有可能被丢弃。 
    - hi 的默认值为 6412，lo 的默认值为 645，frac 的默认值为 0.33。
- 示例：
    - 当使用 mpdecimate 滤镜时，一个常见的例子是去除视频中的重复帧，以降低帧率并减小文件大小。让我们假设你有一个输入视频文件，其中包含一些静止画面或者连续播放的图像相似的帧。你可以使用 mpdecimate 滤镜来删除这些相似的帧。  
    ```ffmpeg -i input.mp4 -vf mpdecimate out.mp4```

##### msad 滤镜
- 用于计算两个输入视频之间的平均绝对差（Mean Sum of Absolute Differences， MSAD）。
- 该滤镜需要两个输入视频。为了正确工作，这两个输入视频必须具有相同的分辨率和像素格式。它还假设两个输入视频具有相同数量的帧，这些帧将逐一进行比较。
- 通过日志系统，该滤镜会输出每个分量的平均、最小和最大 MSAD 值。
- 该滤镜将每帧计算得到的 MSAD 值存储在帧元数据中。
- 该滤镜还支持帧同步（framesync）选项。
- 示例：
    ```ffmpeg -i main.mpg -i ref.mpg -lavfi msad -f null -```

##### mutiply 滤镜
- 用于将第一个视频流的像素值与第二个视频流的像素值相乘。
- 该滤镜接受以下选项：
    - scale：设置应用于第二个视频流的缩放因子。默认值为1。允许的范围是从0到9。
    - offset：设置应用于第二个视频流的偏移量。默认值为0.5。允许的范围是从-1到1。
    - planes：指定要处理的输入视频流的平面。默认情况下，会处理所有平面。
- 该滤镜支持上述选项作为命令使用。
- 示例：
    - 当使用 multiply 滤镜时，一个通俗易懂的例子是将一个视频的像素值与另一个视频的像素值相乘，从而实现视频的叠加效果。例如，假设我们有两个视频，一个是一个蓝色矩形，另一个是一个红色圆形，我们想要将这两个视频叠加在一起，即将红色圆形覆盖在蓝色矩形上。  
    ```ffmpeg -i blue_rectangle.mp4 -i red_circle.mp4 -filter_complex "[0:v][1:v]multiply[outv]" -map "[outv]" output.mp4```

##### negate 滤镜
- 用于对输入视频进行取反（反转操作）。
- 该滤镜接受以下选项：
    - components：设置要取反的分量。
    - 可用的取值有：
        - 'y'：取反亮度（对于YUV色彩空间）。
        - 'u'：取反色度U（对于YUV色彩空间）。
        - 'v'：取反色度V（对于YUV色彩空间）。
        - 'a'：取反透明度（如果存在）。
        - 'r'：取反红色分量（对于RGB色彩空间）。
        - 'g'：取反绿色分量（对于RGB色彩空间）。
        - 'b'：取反蓝色分量（对于RGB色彩空间）。
    - negate_alpha：如果设置为1，则取反透明度分量（如果存在）。默认值为0。
- 该滤镜支持上述选项作为命令使用。

##### nlmeans 滤镜
- 使用非局部均值算法对视频帧进行降噪处理。
- 该算法通过比较像素周围的大小为 pxp 的补丁（patch）来确定上下文相似性，并调整每个像素的值。这些补丁是在像素周围的大小为 rxr 的区域内搜索的。
- 该滤镜接受以下选项：
    - s：设置降噪强度。默认值为 1.0。必须在范围 [1.0, 30.0] 内。
    - p：设置补丁大小。默认值为 7。必须是奇数，在范围 [0, 99] 内。
    - pc：与 p 相同，但适用于色度平面。
    - 默认值为 0，表示自动选择。
    - r：设置研究区域大小。默认值为 15。必须是奇数，在范围 [0, 99] 内。
    - rc：与 r 相同，但适用于色度平面。
    - 默认值为 0，表示自动选择。
- 示例：
    - 当使用 nlmeans 滤镜时，一个通俗易懂的例子是对视频进行降噪处理，以减少视频中的噪点和图像失真。这对于修复低光照条件下的视频或者压缩引起的图像质量损失很有帮助。  
    ```ffmpeg -i input.mp4 -vf "nlmeans=s=2:p=7:r=15" output.mp4```

##### nnedi 滤镜
- 一种使用神经网络边缘导向插值进行视频去隔行的滤镜。
- 该滤镜接受以下选项：
    - weights（权重）：这是一个必填选项，需要提供一个二进制文件。如果没有该文件，滤镜将无法正常工作。可以在指定的URL中找到二进制文件。

    - deint（去隔行）：该选项用于指定要去隔行的帧。默认值为"all"，表示对所有帧进行去隔行处理。或者，您可以将其设置为"interlaced"，仅对隔行帧进行去隔行处理。

    - field（场）：该选项确定操作模式。它可以具有以下值：
        - af：使用帧标志来处理两个场。
        - a：使用帧标志来处理单个场。
        - t：仅使用顶场。
        - b：仅使用底场。
        - tf：使用两个场，先顶场。
        - bf：使用两个场，先底场。

    - planes（平面）：该选项指定要处理的平面。默认情况下，滤镜处理所有帧。

    - nsize（邻域大小）：该选项设置每个像素周围的局部邻域的大小，这是预测神经网络使用的参数。它可以具有以下值：
        - s8x6
        - s16x6
        - s32x6
        - s48x6
        - s8x4
        - s16x4
        - s32x4

    - nns（神经网络神经元数）：该选项确定预测神经网络中的神经元数。它可以具有以下值：
        - n16
        - n32
        - n64
        - n128
        - n256

    - qual（质量）：该选项控制将多个不同的神经网络预测混合在一起以计算最终输出值的数量。它可以具有以下值：
        - fast
        - default
        - slow

    - etype（误差类型）：该选项指定在预测中使用的权重集。它可以具有以下值：
        - a, abs：用于最小化绝对误差的权重。
        - s, mse：用于最小化平方误差的权重。

    - pscrn（预筛选器）：该选项控制是否使用预筛选器神经网络来确定哪些像素应由预测神经网络处理，哪些可以通过简单的三次样条插值处理。它可以具有以下值：
        - none
        - original
        - new
        - new2
        - new3
        - 默认值为"new"。
- 这个滤镜支持与选项相同的命令，不包括weights选项。

##### noformat 滤镜
- 它用于强制libavfilter不要为下一个滤镜选择特定的像素格式。
- 它接受以下选项：
    - pix_fmts：一个由竖线（|）分隔的像素格式名称列表，例如pix_fmts=yuv420p|monow|rgb24。
- 示例：
    - 强制libavfilter在传递给vflip滤镜的输入中使用与yuv420p不同的格式：  
    ```noformat=pix_fmts=yuv420p,vflip```
    - 将输入视频转换为不包含在列表中的任何格式：  
    ```noformat=yuv420p|yuv444p|yuv410p```
- 示例：
    - 假设你有一个名为"input.mp4"的视频文件，你想强制libavfilter不使用yuv420p格式作为vflip滤镜的输入格式。
    - 你有一个视频文件，其中包含一个垂直翻转的镜像效果。然而，你希望在进行垂直翻转之前，强制将输入视频转换为除了yuv420p之外的其他像素格式，以避免某些兼容性问题。  
    ```ffmpeg -i input.mp4 -vf "noformat=pix_fmts=yuv420p,vflip" output.mp4```

##### noise 滤镜
- 用于再视频输入帧上添加噪声。
- 它接受以下选项：
    - all_seed：设置特定像素分量或所有像素分量（在all_seed情况下）的噪声种子。默认值为123457。
    - c0_seed、c1_seed、c2_seed、c3_seed：设置特定像素分量的噪声种子。
    - all_strength、alls：设置特定像素分量或所有像素分量（在all_strength情况下）的噪声强度。默认值为0，允许的范围为[0, 100]。
    - c0_strength、c1_strength、c2_strength、c3_strength：设置特定像素分量的噪声强度。
    - all_flags、allf：设置像素分量的标志，或在all_flags情况下设置所有分量的标志。可用的标志值包括：
        - a：平均时间噪声（更平滑）
        - p：将随机噪声与（半）规则模式混合
        - t：时间噪声（噪声模式在帧之间变化）
        - u：均匀噪声（否则为高斯噪声）
- 示例：
    - 在输入视频上添加时间噪声和均匀噪声效果。  
    ```ffmpeg -i input.mp4 -vf "noise=alls=20:allf=t+u" output.mp4```

##### normalize 滤镜
- 图像处理中的归一化（Normalization）是指改变像素强度值范围的过程，用于增强图像的对比度。在RGB视频中，归一化也被称为直方图拉伸（histogram stretching）或对比度拉伸（contrast stretching）。
- 为了减少由于小的暗或亮物体进入或离开场景而引起的闪烁（亮度的快速变化），可以在输入范围上进行时间平滑处理。这类似于视频摄像机上的自动曝光（自动增益控制），并且与视频摄像机一样，它可能会导致视频的过曝光或欠曝光。
- R、G、B通道可以独立归一化，这可能会导致一些颜色偏移，也可以将它们联接在一起作为单个通道进行归一化，这样可以避免颜色偏移。联接归一化保持色调不变，而独立归一化不会，因此可以用于去除一些色偏。独立归一化和联接归一化可以以任意比例组合使用。
- 该滤镜接受以下选项：
    - blackpt：定义输出范围的颜色，最小输入值映射到blackpt。默认为黑色。
    - whitept：定义输出范围的颜色，最大输入值映射到whitept。默认为白色。
    - smoothing：用于时间平滑的前一帧数量。每个通道的输入范围使用当前帧和前几帧的滚动平均进行平滑处理。默认值为0（无时间平滑）。
    - independence：控制独立（颜色偏移）通道归一化和联接（颜色保持）归一化的比例。0.0表示完全联接，1.0表示完全独立。默认值为1.0（完全独立）。
    - strength：滤镜的总体强度。1.0表示完全强度，0.0表示无操作。默认值为1.0（完全强度）。
- 该滤镜支持与选项相同的命令，不包括平滑选项。
- 命令接受与相应选项相同的语法。
- 示例：
    - 将视频对比度拉伸到使用完整的动态范围，没有时间平滑；根据源内容的不同可能会出现闪烁：  
    ```normalize=blackpt=black:whitept=white:smoothing=0```
    - 与上述相同，但使用50帧的时间平滑；根据源内容的不同，闪烁应该会减少：  
    ```normalize=blackpt=black:whitept=white:smoothing=50```
    - 与上述相同，但使用保持色调的联接通道归一化：  
    ```normalize=blackpt=black:whitept=white:smoothing=50:independence=0```
    - 与上述相同，但强度减半：  
    ```normalize=blackpt=black:whitept=white:smoothing=50:independence=0:strength=0.5```
    - 将最暗的输入颜色映射到红色，最亮的输入颜色映射到青色：  
    ```normalize=blackpt=red:whitept=cyan```
    - 当我们拍摄一段视频时，有时候由于光线条件不好或者其他原因，视频的对比度可能会很低，导致图像看起来暗淡无力。这时我们可以使用归一化来增强视频的对比度，使图像更加清晰明亮。  
    ```ffmpeg -i input.mp4 -vf "normalize=blackpt=black:whitept=white:independence=0" -c:a copy output.mp4```

##### null
- 视频源不经过任何处理地传递到输出中。

##### ocr 滤镜
- 光学字符识别（Optical Character Recognition，OCR）是一种将图像中的文字转换为可编辑文本的技术。在FFmpeg中，有一个OCR滤镜可用于执行OCR操作，并使用Tesseract作为OCR引擎。以下是有关OCR滤镜的一些解释和选项说明：
    - 要启用该滤镜，您需要在编译FFmpeg时使用--enable-libtesseract参数进行配置。
    - 该滤镜接受以下选项：
        - datapath：设置Tesseract数据的路径。默认情况下，滤镜将使用安装时设置的路径。您可以使用此选项来手动设置数据路径。

        - language：设置OCR的语言。默认为"eng"（英语）。您可以根据需要设置其他语言，例如"chi_sim"（简体中文）或"deu"（德语）等。

        - whitelist：设置字符的白名单。只有白名单中的字符将被识别，其他字符将被忽略。这可以用于限制识别的字符范围。

        - blacklist：设置字符的黑名单。黑名单中的字符将被忽略，不会被识别。这可以用于排除某些特定字符的识别。
    - 滤镜将识别到的文本作为帧元数据lavfi.ocr.text导出。您可以使用FFmpeg的其他功能或命令来提取或处理这些元数据。

    - 滤镜还导出了识别到的单词的置信度作为帧元数据lavfi.ocr.confidence。置信度表示Tesseract对识别结果的置信程度。

##### ocv 滤镜

##### oscilloscope 滤镜
- 2D视频示波器是一种用于测量空间脉冲相应、阶跃响应、色度延迟等的工具。
- 它接受以下参数：
    - x：设置示波器的中心位置的x坐标。
    - y：设置示波器的中心位置的y坐标。
    - s：设置示波器的大小，相对于帧对角线的比例。
    - t：设置示波器的倾斜/旋转角度。
    - o：设置示波器轨迹的不透明度。
    - tx：设置示波器轨迹的中心位置的x坐标。
    - ty：设置示波器轨迹的中心位置的y坐标。
    - tw：设置示波器轨迹的宽度，相对于帧宽度的比例。
    - th：设置示波器轨迹的高度，相对于帧高度的比例。
    - c：设置要跟踪的分量。默认情况下，它会跟踪前三个分量。
    - g：绘制轨迹网格。默认情况下启用。
    - st：绘制一些统计信息。默认情况下启用。
    - sc：绘制示波器。默认情况下启用。
- 该滤镜支持与选项相同的命令。
- 命令接受与相应选项相同的语法。
- 如果指定的表达式无效，它将保持当前值。
- 示例：
    - 检查视频帧的第一行（full first row）：  
    ```oscilloscope=x=0.5:y=0:s=1```
    - 检查视频帧的最后一行（full last row）：  
    ```oscilloscope=x=0.5:y=1:s=1```
    - 检查视频帧高度为1080像素时的第5行（full 5th line of video frame of height 1080）：  
    ```oscilloscope=x=0.5:y=5/1080:s=1```
    - 检查视频帧的最后一列（full last column）：  
    ```oscilloscope=x=1:y=0.5:s=1:t=1```
    - 当您想要检查视频帧的左上角区域时，可以使用oscilloscope滤镜的命令来设置示波器的参数。
    - 假设你有一个名为"input.mp4"的视频文件，分辨率为1920x1080。你想要检查视频帧左上角的100x100像素区域。  
    ```ffmpeg -i input.mp4 -vf "oscilloscope=x=0.05:y=0.05:s=0.05" output.mp4``` 

##### overlay 滤镜
- 用于在一个视频的顶部叠加另一个视频。
- 它有两个输入和一个输出，第一个输入是"主"视频，第二个输入是叠加在主视频上的视频。
- 该滤镜接受以下参数：
    - x和y：设置叠加视频在主视频上的x和y坐标的表达式。默认值为"x=0"和"y=0"。如果表达式无效，它将被设置为一个巨大的值（意味着叠加将不会在输出可见区域内显示）。
    - eof_action：参见framesync。
    - eval：设置x和y表达式何时进行评估。它接受以下值：
        - 'init'：仅在滤镜初始化或处理命令时评估表达式一次。
        - 'frame'：为每个输入帧评估表达式。默认值为'frame'。
    - shortest：参见framesync。
    - format：设置输出视频的格式。它接受以下值。
        - 'yuv420'：强制使用YUV 4:2:0 8-bit平面输出。
        - 'yuv420p10'：强制使用YUV 4:2:0 10-bit平面输出。
        - 'yuv422'：强制使用YUV 4:2:2 8-bit平面输出。
        - 'yuv422p10'：强制使用YUV 4:2:2 10-bit平面输出。
        - 'yuv444'：强制使用YUV 4:4:4 8-bit平面输出。
        - 'yuv444p10'：强制使用YUV 4:4:4 10-bit平面输出。
        - 'rgb'：强制使用RGB 8-bit打包输出。
        - 'gbrp'：强制使用RGB 8-bit平面输出。
        - 'auto'：自动选择格式。默认值为'yuv420'。
    - repeatlast：参见framesync。
    - alpha：设置叠加视频的alpha通道格式，可以是straight（直接）或premultiplied（预乘）。默认值为straight（直接）。
    - x和y表达式可以包含以下参数：
        - main_w、W：主输入的宽度。
        - main_h、H：主输入的高度。
        - overlay_w、w：叠加输入的宽度。
        - overlay_h、h：叠加输入的高度。
        - x：计算得到的x值。
        - y：计算得到的y值。
        - hsub：输出格式的水平色度子采样值。
        - vsub：输出格式的垂直色度子采样值。
        - n：输入帧的编号，从0开始。
        - pos：输入帧在文件中的位置，如果未知则为NAN（不推荐使用）。
        - t：时间戳，以秒为单位。如果输入时间戳未知，则为NAN。
    - 此滤镜还支持framesync选项。
    - 请注意，当每帧进行评估时，变量n和t仅可用，并且在eval设置为'init'时将评估为NAN。
    - 请注意，帧是按照时间戳的顺序从每个输入视频中获取的，因此，如果它们的初始时间戳不同，建议通过setpts=PTS-STARTPTS滤镜将两个输入的时间戳调整为相同的零时间戳，就像movie滤镜的示例一样。
    - 你可以链接更多的overlay滤镜，但是您应该测试此方法的效率。
- 该滤镜支持以下命令：
    - x：修改叠加视频的x坐标。
    - y：修改叠加视频的y坐标。
    - 可以使用与x和y选项相同的语法来修改叠加视频的x和y坐标。
    - 如果指定的表达式无效，它将保持当前值不变。
- 示例：
    - 将叠加视频放置在主视频的右下角，距离边缘10像素：  
    ```overlay=main_w-overlay_w-10:main_h-overlay_h-10```
    - 使用命名选项来实现上述示例：  
    ```overlay=x=main_w-overlay_w-10:y=main_h-overlay_h-10```
    - 在输入视频的左下角插入一个透明的PNG标志，使用ffmpeg工具和-filter_complex选项：  
    ```ffmpeg -i input -i logo -filter_complex 'overlay=10:main_h-overlay_h-10' output```
    - 使用ffmpeg工具在底部左侧插入两个不同的透明PNG标志（第二个标志在右下角）：  
    ```ffmpeg -i input -i logo1 -i logo2 -filter_complex 'overlay=x=10:y=H-h-10,overlay=x=W-w-10:y=H-h-10' output```
    - 在主视频的顶部添加一个透明的颜色层：  
    ```color=color=red@.3:size=WxH [over]; [in][over] overlay [out]```
    - 使用ffplay工具同时播放原始视频和经过滤镜处理的版本（此处使用deshake滤镜）：
    ```ffplay input.avi -vf 'split[a][b]; [a]pad=iw*2:ih[src]; [b]deshake[filt]; [src][filt]overlay=w'```
    - 使一个滑动的叠加层从左侧滑动到右上角的屏幕上方，从时间2开始：  
    ```overlay=x='if(gte(t,2), -w+(t-2)*20, NAN)':y=0```
    - 通过将delogo滤镜应用于视频的一部分，屏蔽10-20秒的视频：  
    ```ffmpeg -i test.avi -codec:v:0 wmv2 -ar 11025 -b:v 9000k -vf '[in]split[split_main][split_delogo];[split_delogo]trim=start=360:end=371,delogo=0:0:640:480[delogoed];[split_main][delogoed]overlay=eof_action=pass[out]' masked.avi```
    - 将多个叠加层级联在一起：  
    ```nullsrc=s=200x200 [bg];testsrc=s=100x100, split=4 [in0][in1][in2][in3];[in0] lutrgb=r=0, [bg] overlay=0:0 [mid0];[in1] lutrgb=g=0,[mid0] overlay=100:0 [mid1];[in2] lutrgb=b=0, [mid1]overlay=0:100   [mid2];[in3] null,[mid2] overlay=100:100 [out0]```

##### owdenoise 滤镜
- 一种过完备小波降噪器，用于降低视频中的噪声。
- 该滤镜接受以下选项：
    - depth：设置降噪的深度。较大的深度值将更好地降低低频成分的噪声，但会降低滤波的速度。该值必须是8到16之间的整数，默认值为8。
    - luma_strength或ls：设置亮度强度。该值必须是0到1000之间的双精度值，默认值为1.0。
    - chroma_strength或cs：设置色度强度。该值必须是0到1000之间的双精度值，默认值为1.0。
- 示例：
    - 当你拍摄一个视频时，有时候可能会受到光线不足或摄像机本身的噪声等因素的影响，导致视频中出现一些噪点，可以使用该滤镜对其降低噪声。  
    ```ffmpeg -i input.mp4 -filter_complex "owdenoise=depth=12:luma_strength=0.5:chroma_strength=0.8" output.mp4```

##### pad 滤镜
- 用于在输入图像上添加填充，并将原始输入放置在指定的x、y坐标位置。
- 该滤镜接受以下选项：
    - width或w：指定添加填充后输出图像的宽度表达式。如果width的值为0，则输出的宽度与输入图像的宽度相同。width表达式可以引用height表达式的值，反之亦然。
    - height或h：指定添加填充后输出图像的高度表达式。如果height的值为0，则输出的高度与输入图像的高度相同。height表达式可以引用width表达式的值，反之亦然。
    - x：指定将输入图像放置在填充区域内的水平偏移量，相对于输出图像的左边界。
    - y：指定将输入图像放置在填充区域内的垂直偏移量，相对于输出图像的上边界。
    - color：指定填充区域的颜色。颜色的语法可以参考ffmpeg-utils手册中的"Color"部分。
    - eval：指定何时评估width、height、x和y表达式的值。可选值包括'init'（仅在滤镜初始化或处理命令时评估表达式）和'frame'（对每个输入帧评估表达式）。默认值为'init'。
    - aspect：按照宽高比进行填充，而不是按照分辨率进行填充。
    - width、height、x和y选项的值可以是包含以下常量的表达式：
        - in_w、in_h：输入视频的宽度和高度。
        - iw、ih：与in_w和in_h相同。
        - out_w、out_h：输出（填充区域）的宽度和高度，由width和height表达式指定。
        - ow、oh：与out_w和out_h相同。
        - x、y：由x和y表达式指定的水平和垂直偏移量，如果尚未指定，则为NAN。
        - a：等同于iw/ih。
        - sar：输入的样本宽高比。
        - dar：输入的显示宽高比，等同于(iw/ih)*sar。
        - hsub、vsub：用于色度采样。
- 示例：
    - 添加填充到输入视频，输出视频的尺寸为640x480，将输入视频的左上角放置在列0、行40的位置，并使用颜色"violet"作为填充区域的颜色。  
    ```pad=640:480:0:40:violet```
    - 这个示例等同于以下命令：  
    ```pad=width=640:height=480:x=0:y=40:color=violet```
    - 对输入视频进行填充，使输出图像的尺寸增加3/2倍，并将输入视频放置在填充区域的中心位置。  
    ```pad="3/2iw:3/2ih:(ow-iw)/2:(oh-ih)/2"```
    - 对输入视频进行填充，使输出图像成为一个正方形，尺寸等于输入宽度和高度的最大值，并将输入视频放置在填充区域的中心位置。  
    ```pad="max(iw,ih):ow:(ow-iw)/2:(oh-ih)/2"```
    - 对输入视频进行填充，使输出图像的宽高比为16:9。  
    ```pad="ih*16/9:ih:(ow-iw)/2:(oh-ih)/2"```
    - 在处理非等比例视频时，为了正确设置输出的显示宽高比，需要根据以下关系使用sar参数：  
    ```(ih * X / ih) * sar = output_dar```  
    ```X = output_dar / sar```
    - 当你想要在视频的周围添加黑色边框时，你可以使用pad滤镜。下面是一个通俗易懂的例子：假设你有一个输入视频文件名为"input.mp4"，分辨率为1280x720，你想要在视频周围添加一个宽度为100像素的黑色边框。输出视频的分辨率将是1480x920，黑色边框将均匀地分布在视频周围。  
    ```ffmpeg -i input.mp4 -vf "pad=1480:920:100:100:black" output.mp4```

##### palettegen 滤镜
- 用于为整个视频流生成一个调色板（palette）。
- 该滤镜接受以下选项：
    - max_colors
    - 设置在调色板中进行量化的最大颜色数量。注意：调色板仍然会包含256种颜色；未使用的调色板条目将会是黑色。

    - reserve_transparent
    - 创建一个最多包含255种颜色的调色板，并将最后一种颜色保留为透明色。保留透明色对于GIF优化非常有用。如果不设置此选项，默认调色板中的最大颜色数将为256。对于独立图像，你可能希望禁用此选项。默认情况下，此选项已启用。

    - transparency_color
    - 设置将用作透明背景的颜色。

    - stats_mode
    - 设置统计模式。
    - 可接受的值有：
        - 'full'：计算完整帧的直方图。
        - 'diff'：仅计算与前一帧不同的部分的直方图。如果背景是静态的，这可能会更加重视输入中的移动部分。
        - 'single'：为每一帧计算新的直方图。
        - 默认值为'full'。
- 示例：
    - 生成给定视频的代表性调色板。  
    ```ffmpeg -i input.mkv -vf palettegen palette.png```
    - 该调色板可以用于后续的处理，比如生成一个GIF动画。

##### paletteuse 滤镜
- 用于使用调色板对输入视频流进行降采样。
- 该滤镜需要两个输入：一个视频流和一个调色板。调色板必须是一个包含256个像素的图像。
- 该滤镜接受以下选项：
    - dither:选择抖动模式。可用的算法有：
        - 'bayer'：有序的8x8 Bayer抖动（确定性）
        - 'heckbert'：Paul Heckbert在1982年定义的抖动（简单误差扩散）。注意：这种抖动有时被认为是“错误的”，它作为一个参考被包含在内。
        - 'floyd_steinberg'：Floyd和Steingberg误差扩散
        - 'sierra2'：Frankie Sierra抖动v2（误差扩散）
        - 'sierra2_4a'：Frankie Sierra抖动v2 "Lite"（误差扩散）
        - 'sierra3'：Frankie Sierra抖动v3（误差扩散）
        - 'burkes'：Burkes误差扩散
        - 'atkinson'：Bill Atkinson在Apple Computer上的Atkinson抖动（误差扩散）
        - 'none'：禁用抖动
        - 默认值为'sierra2_4a'。
    - bayer_scale:当选择bayer抖动时，此选项定义了图案的比例（交叉线图案的可见程度）。较低的值意味着更明显的图案以减少条纹效果，较高的值意味着较不明显的图案，但代价是更多的条纹效果。
    - diff_mode:如果设置了该选项，则定义要处理的区域。
        - 'rectangle'：只有变化的矩形将被重新处理。这类似于GIF的裁剪/偏移压缩机制。如果只有图像的一部分发生变化，这个选项可以提高处理速度，并且适用于限制误差扩散抖动的范围，以边界移动场景（如果场景变化不大，则会产生更确定的输出，从而减少移动噪声和更好的GIF压缩）。
    - 默认值为'none'。
    - new:为每个输出帧使用新的调色板。
    - alpha_threshold:设置透明度的阈值。超过此阈值的Alpha值将被视为完全不透明，低于此阈值的值将被视为完全透明。
        - 该选项必须是范围[0,255]内的整数值。默认值为128。
- 示例：
    - 使用FFmpeg将调色板（例如使用palettegen生成的调色板）来编码为GIF格式。  
    ```ffmpeg -i input.mkv -i palette.png -lavfi paletteuse output.gif```

##### perspective 滤镜
- 用于纠正视频的透视效果，特别是在录制时与屏幕垂直的情况。
- 该滤镜接受以下选项：
    - x0, y0, x1, y1, x2, y2, x3, y3
    - 设置左上角、右上角、左下角和右下角的坐标表达式。默认值为0:0:W:0:0:H:W:H，表示透视效果保持不变。如果sense选项设置为source，则指定的点将被发送到目标的四个角落。如果sense选项设置为destination，则源的四个角落将被发送到指定的坐标。
    - 表达式可以使用以下变量：
        - W：视频帧的宽度
        - H：视频帧的高度
        - in：输入帧计数
        - on：输出帧计数
    - interpolation
    - 设置透视校正的插值方法。
    - 可接受的值有：
        - 'linear'：线性插值
        - 'cubic'：三次插值
        - 默认值为'linear'。
    - sense
    - 设置坐标选项的解释方式。
    - 可接受的值有：
        - '0, source'：将源中由给定坐标指定的点发送到目标的四个角落。
        - '1, destination'：将源的四个角落发送到由给定坐标指定的目标点。
        - 默认值为'source'。
    - eval
    - 设置何时评估x0、y0、...、x3、y3的坐标表达式。
    - 可接受的值有：
        - 'init'：仅在滤镜初始化或处理命令时评估表达式一次。
        - 'frame'：为每个传入帧评估表达式。
        - 默认值为'init'。
- 示例：
    - 假设你有一段视频，其中一面墙被以一定的角度拍摄，使得墙看起来倾斜了。你想要使用FFmpeg的perspective滤镜来校正这个透视效果，使得墙恢复垂直。
        - 假设你的视频文件名为input.mp4，宽度为1280像素，高度为720像素。
        - 假设你想要将视频的左上角定位到(100, 100)、右上角定位到(1180, 150)、左下角定位到(100, 620)、右下角定位到(1180, 570)。
        - 你想要使用线性插值进行透视校正。  
        ```ffmpeg -i input.mp4 -vf "perspective=x0=100:y0=100:x1=1180:y1=150:x2=100:y2=620:x3=1180:y3=570:interpolation=linear" -c:a copy output.mp4```

##### phase 滤镜
- 用于延迟隔行扫描视频的一个场时间，从而改变场次序。
- 该滤镜的主要用途是修复以与电影到视频转换相反的场次序捕获的PAL电影。
- 该滤镜接受以下选项：
    - 't'：捕获时场次序为从上到下，转换时场次序为从下到上。滤镜将延迟下场。
    - 'b'：捕获时场次序为从下到上，转换时场次序为从上到下。滤镜将延迟上场。
    - 'p'：捕获和转换时使用相同的场次序。这个模式只是为了在文档中引用其他选项而存在，但如果你实际选择了它，滤镜将不做任何处理。
    - 'a'：根据场标志自动确定捕获场次序，转换时使用相反的场次序。滤镜根据场标志在每个帧上选择't'和'b'模式之一。如果没有场信息可用，则它的行为与'u'相同。
    - 'u'：捕获未知或变化的场次序，转换时使用相反的场次序。滤镜通过分析图像并选择产生场次序最佳匹配的备选方案，在每个帧上选择't'和'b'。
    - 'T'：捕获场次序为从上到下，转换时场次序为未知或变化。滤镜使用图像分析，在't'和'p'之间进行选择。
    - 'B'：捕获场次序为从下到上，转换时场次序为未知或变化。滤镜使用图像分析，在'b'和'p'之间进行选择。
    - 'A'：根据场标志确定捕获场次序，转换时场次序为未知或变化。滤镜根据场标志和图像分析，在't'、'b'和'p'之间进行选择。如果没有场信息可用，则它的行为与'U'相同。这是默认模式。
    - 'U'：捕获和转换都是未知或变化的场次序。滤镜仅使用图像分析，在't'、'b'和'p'之间进行选择。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一段视频，这段视频是以PAL制式拍摄的电影，但是在转换为视频时，场次序被错误地捕获为相反的顺序。现在你想使用FFmpeg的phase滤镜来修复这个问题，将场次序恢复为正确的顺序。
        - 假设视频的场次序被错误地捕获为从下到上，而实际顺序应该是从上到下。  
        ```ffmpeg -i input.mp4 -vf "phase=b" -c:a copy output.mp4```

##### photosensitivity 滤镜
- 用于减少视频中的各种闪光，以帮助患有癫痫病的用户。
- 该滤镜接受以下选项：
    - frames, f：设置过滤时使用的帧数。默认为30帧。
    - threshold, t：设置检测阈值因子。默认为1。较低的值表示更严格的检测。
    - skip：设置采样帧时要跳过的像素数。默认为1。允许的范围是1到1024。
    - bypass：不修改帧。默认为禁用状态。
- 示例：
    - 假设你有一段视频，其中包含一些闪光效果，这可能对癫痫病患者产生不良影响。现在你想使用FFmpeg的Photosensitivity滤镜来减少这些闪光效果，以保护观众的健康。
        - 假设你想使用30帧进行过滤，设置较低的阈值因子为0.8，跳过采样时每隔2个像素进行采样。  
        ```ffmpeg -i input.mp4 -vf "photosensitivity=frames=30:threshold=0.8:skip=2" -c:a copy output.mp4```

##### pixdesctest 滤镜
- 用于内部测试。输出视频应该与输入视频相同。
- 例如  
```format=monow, pixdesctest```
- 这个用于测试monowwhite像素格式描述符的定义。
- 示例：
    - pixdesctest滤镜主要用于内部测试和调试，通常不是用于常规视频处理和转码任务的滤镜。因此，在提供一个通俗易懂的例子方面会有一定的挑战性。
    - 假设你有一段名为input.mp4的视频，你想测试RGB555像素格式的定义是否正确，并确保输出视频与输入视频具有相同的像素格式。  
    ```ffmpeg -i input.mp4 -vf "format=rgb555, pixdesctest" -c:a copy output.mp4```

##### pixelize 滤镜
- 用于对视频流应用像素化效果。
- 该滤镜接受以下选项：
    - width, w
    - 设置用于像素化的块的宽度。默认值为16。
    - height, h
    - 设置用于像素化的块的高度。默认值为16。
    - mode, m
    - 设置像素化的模式。
    - 可能的取值有：
        - 'avg'：使用块内像素的平均值进行像素化。
        - 'min'：使用块内像素的最小值进行像素化。
        - 'max'：使用块内像素的最大值进行像素化。
        - 默认值为'avg'。
    - planes, p
    - 设置要过滤的平面。
    - 可能的取值有：
        - 'all'：过滤所有平面（默认）。
        - 'y'：只过滤亮度平面。
        - 'u'：只过滤色度平面（U）。
        - 'v'：只过滤色度平面（V）。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一段名为input.mp4的视频，你想对其应用像素化效果，使用块尺寸为20x20，并选择使用平均值进行像素化。  
    ```ffmpeg -i input.mp4 -vf "pixelize=width=20:height=20:mode=avg" -c:a copy output.mp4```

##### pixscope 滤镜
- 用于显示颜色通道的样本值，主要用于检查颜色和亮度级别，最小支持的分辨率是640x480。
- 该滤镜接受以下选项：
    - x
    - 设置范围在X轴上的相对偏移的位置。
    - y
    - 设置范围在Y轴上的相对偏移的位置。
    - w
    - 设置范围的宽度。
    - h
    - 设置范围的高度。
    - o
    - 设置窗口的不透明度。该窗口还显示有关像素区域的统计信息。
    - wx
    - 设置窗口在X轴上的相对偏移的位置。
    - wy
    - 设置窗口在Y轴上的相对偏移的位置。
- 该滤镜的命令支持与选项相同的用法。

##### pp 滤镜
- 用于启用libpostproc库中指定的一系列后处理子滤镜。使用GPL构建（--enable-gpl）时，应自动选择该库。子滤镜之间需要用斜杠（/）分隔，并可以通过在前面加上减号（-）来禁用。每个子滤镜和一些选项都有一个短名称和一个长名称，可以互换使用，例如dr/dering是相同的。
- 该滤镜接受以下选项：
    - subfilters：设置后处理子滤镜字符串。
- 所有子滤镜共享一些用于确定其作用范围的公共选项：
    - a/autoq
    - 遵循此子滤镜的质量命令。
    - c/chrom
    - 进行色度过滤（默认）。
    - y/nochrom
    - 仅进行亮度过滤，不进行色度过滤。
    - n/noluma
    - 仅进行色度过滤，不进行亮度过滤。
- 可以在子滤镜名称后附加这些选项，用竖线（|）分隔。
- 可用的子滤镜包括：
    - hb/hdeblock[|difference[|flatness]]
    - 水平去块滤波器。
        - difference
        - 差异因子，较高的值表示更强的去块（默认值：32）。
        - flatness
        - 平坦度阈值，较低的值表示更强的去块（默认值：39）。
    - vb/vdeblock[|difference[|flatness]]
    - 垂直去块滤波器。
        - difference
        - 差异因子，较高的值表示更强的去块（默认值：32）。
        - flatness
        - 平坦度阈值，较低的值表示更强的去块（默认值：39）。
    - ha/hadeblock[|difference[|flatness]]
    - 准确的水平去块滤波器。
        - difference
        - 差异因子，较高的值表示更强的去块（默认值：32）。
        - flatness
        - 平坦度阈值，较低的值表示更强的去块（默认值：39）。
    - va/vadeblock[|difference[|flatness]]
    - 准确的垂直去块滤波器。
        - difference
        - 差异因子，较高的值表示更强的去块（默认值：32）。
        - flatness
        - 平坦度阈值，较低的值表示更强的去块（默认值：39）。
    - 水平和垂直去块滤波器共享差异和平坦度值，因此无法设置不同的水平和垂直阈值。
    - h1/x1hdeblock
    - 实验性水平去块滤波器。
    - v1/x1vdeblock
    - 实验性垂直去块滤波器。
    - dr/dering
    - 去环滤波器。
    - tn/tmpnoise[|threshold1[|threshold2[|threshold3]]]
    - 时域降噪器。
        - threshold1
        - 阈值1，较大的值表示更强的滤波。
        - threshold2
        - 阈值2，较大的值表示更强的滤波。
        - threshold3
        - 阈值3，较大的值表示更强的滤波。
    - al/autolevels[:f/fullyrange]
    - 自动亮度/对比度校正。
        - f/fullyrange
        - 将亮度拉伸到0-255。
    - lb/linblenddeint
    - 线性混合去隔行滤波器，使用（1 2 1）滤波器对所有行进行滤波。
    - -ci/cubicipoldeint
    - 使用三次插值去隔行滤波器，通过对每隔一行进行三次插值来去隔行。
    - md/mediandeint
    - 中值去隔行滤波器，通过对每隔一行应用中值滤波来去隔行。
    - fd/ffmpegdeint
    - FFmpeg去隔行滤波器，通过使用（-1 4 2 4 -1）滤波器对每隔一行进行滤波来去隔行。
    - l5/lowpass5
    - 用于垂直应用的FIR低通去隔行滤波器，通过使用（-1 2 6 2 -1）滤波器对所有行进行滤波来去隔行。
    - fq/forceQuant[|quantizer]
    - 使用指定的恒定量化器覆盖输入的量化器表。
        - quantizer
        - 要使用的量化器。
    - de/default
    - 默认的pp滤镜组合（hb|a,vb|a,dr|a）。
    - fa/fast
    - 快速的pp滤镜组合（h1|a,v1|a,dr|a）。
    - ac
    - 高质量的pp滤镜组合（ha|a|128|7,va|a,dr|a）。
- 示例：
    - 应用水平和垂直去块、去环和自动亮度/对比度：  
    ```pp=hb/vb/dr/al```
    - 应用默认滤镜，但不进行亮度/对比度校正：  
    ```pp=de/-al```
    - 应用默认滤镜和时域降噪器：  
    ```pp=default/tmpnoise|1|2|3```
    - 仅在亮度上应用去块，并根据可用的CPU时间自动开启或关闭垂直去块：  
    ```pp=hb|y/vb|a```
    - 当你拍摄的视频存在一些噪点和图像模糊时，你可以使用pp滤镜来改善视频质量。例如，假设你有一个名为"input.mp4"的视频文件，你想应用水平去块、去环和自动亮度/对比度校正来改善视频的清晰度和亮度。  
    ```ffmpeg -i input.mp4 -vf "pp=hb/dr/al" -c:a copy output.mp4```

##### pp7 滤镜
- 一种后处理率极高，它是ssp（简单后处理）滤镜的变体。它类似于ssp=6，但使用了7点离散余弦变换（DCT），在逆DCT（IDCT）后只使用中心样本。
- 该滤镜接受以下选项：
    - qp：此选项允许您强制设置一个恒定的量化参数。您可以设置一个0到63之间的整数值。如果未设置，滤镜将使用视频流中的QP（量化参数）（如果可用）。
    - mode：此选项用于设置滤镜的阈值模式。可用的模式有：
        - 'hard'：设置硬阈值，对噪点进行严格的阈值处理。
        - 'soft'：设置软阈值，提供更好的去环效果，但图像可能稍微模糊。
        - 'medium'：设置中等阈值，平衡了降噪和图像锐度。这是默认模式。
- 示例：
    - 假设有一个名为"input.mp4"的视频文件，你想使用pp7滤镜来改善视频的质量，使用恒定的量化参数为25，并选择软阈值模式。  
    ```ffmpeg -i input.mp4 -vf "pp7=qp=25:mode=soft" -c:a copy output.mp4```

##### premultiply 滤镜
- 可以在输入视频流上应用alpha预乘效果，其中第二个流的第一个平面将被用作alpha通道。
- 两个流必须具有相同的尺寸和像素格式。
- 该滤镜接受以下选项：
    - planes：设置将被处理的平面，未处理的平面将被复制。默认值为0xf，表示所有平面都将被处理。
    - inplace：不需要第二个输入进行处理，而是使用输入流中的alpha平面。

##### prewitt 滤镜
- 可以将prewitt算子应用于输入视频流。
- 该滤镜接受以下选项：
    - planes：设置将被处理的平面，未处理的平面将被复制。默认值为0xf，表示所有平面都将被处理。
    - scale：设置将与过滤结果相乘的值。
    - delta：设置将添加到过滤结果的值。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 假设你有一段视频，其中包含一辆汽车在道路上行驶的场景。你想突出显示视频中的车辆边缘，以便更清楚地看到车辆的形状和边界。  
    ```ffmpeg -i input.mp4 -vf "prewitt=planes=0xf:scale=2:delta=10" -c:a copy output.mp4```

##### pseudocolor 滤镜
- 可以在视频中使用伪彩色来改变帧的颜色。
- 该滤镜接受以下选项：
    - c0：设置第一个像素分量的表达式。
    - c1：设置第二个像素分量的表达式。
    - c2：设置第三个像素分量的表达式。
    - c3：设置第四个像素分量的表达式，对应于alpha分量。
    - index或i：设置用作改变颜色基础的分量。
    - preset或p：选择内置的查找表（LUT）。默认值为none。
    - 可用的LUT包括：
        - 'magma'
        - 'inferno'
        - 'plasma'
        - 'viridis'
        - 'turbo'
        - 'cividis'
        - 'range1'
        - 'range2'
        - 'shadows'
        - 'highlights'
        - 'solar'
        - 'nominal'
        - 'preferred'
        - 'total'
        - 'spectral'
        - 'cool'
        - 'heat'
        - 'fiery'
        - 'blues'
        - 'green'
        - 'helix'
    - opacity：设置输出颜色的不透明度。允许范围为0到1，默认值为1。
    - 每个表达式选项指定用于计算相应像素分量值的查找表的表达式。
    - 这些表达式可以包含以下常量和函数：
        - w：输入宽度。
        - h：输入高度。
        - val：像素分量的输入值。
        - ymin、umin、vmin、amin：允许的最小分量值。
        - ymax、umax、vmax、amax：允许的最大分量值。
        - 所有表达式默认为"val"。
- 该滤镜支持上述所有选项作为命令使用。
- 示例：
    - 表达式将把亮度值过高的像素转换成渐变效果。  
    ```'if(between(val,ymax,amax),lerp(ymin,ymax,(val-ymax)/(amax-ymax)),-1):if(between(val,ymax,amax),lerp(umax,umin,(val-ymax)/(amax-ymax)),-1):if(between(val,ymax,amax),lerp(vmin,vmax,(val-ymax)/(amax-ymax)),-1):-1'```

##### psnr 滤镜
- 衡量两个视频之间质量差异的指标。FFmpeg提供了一个滤镜来计算两个输入视频之间的平均、最大和最小PSNR值。
- 这个滤镜需要两个输入视频，第一个输入被认为是“主”源，它将不变地传递到输出。第二个输入被用作计算PSNR的“参考”视频。
- 为了使该滤镜正常工作，两个视频输入必须具有相同的分辨率和像素格式。它还假设两个输入具有相同的帧数，这些帧逐一进行比较。
- 滤镜会存储每帧的累积均方误差（MSE），在处理结束时，这些误差将在所有帧中进行平均，并应用以下公式来计算PSNR：
    - PSNR = 10 * log10(MAX^2 / MSE)
    - 其中，MAX是图像每个分量的最大值的平均值。
- 该滤镜接受以下参数：
    - stats_file, f
    - 如果指定了该参数，滤镜将使用指定的文件保存每个单独帧的PSNR。当文件名设置为"-"时，数据将被发送到标准输出。

    - stats_version
    - 指定要使用的统计文件格式的版本。每个格式的详细信息如下所述。默认值为1。

    - stats_add_max
    - 确定是否将最大值输出到统计日志。默认值为0。要求stats_version >= 2。如果设置了该参数且stats_version < 2，滤镜将返回错误。

    - 该滤镜还支持framesync选项。

    - 如果选择了stats_file参数，输出的文件将包含每个比较的帧的键/值对序列，每个帧对应一行。

    - 如果指定了大于1的stats_version，那么在每帧对比统计数据之前，将有一行包含以下参数的头信息:

    - psnr_log_version
    - 日志文件格式的版本。与stats_version相同。

    - fields
    - 以逗号分隔的每帧对参数的列表。
- 下面是每个帧对参数的描述：
    - n
    - 输入帧的顺序号，从1开始。

    - mse_avg
    - 比较帧之间的逐像素均方误差，对所有图像分量进行平均。

    - mse_y, mse_u, mse_v, mse_r, mse_g, mse_b, mse_a
    - 比较帧之间指定后缀的分量的逐像素均方误差。
    
    - psnr_y, psnr_u, psnr_v, psnr_r, psnr_g, psnr_b, psnr_a
    - 比较帧之间指定后缀的分量的峰值信噪比。
    
    - max_avg, max_y, max_u, max_v
    - 每个通道的最大允许值，以及所有通道的平均值。
- 示例：  
    ```movie=ref_movie.mpg, setpts=PTS-STARTPTS [main];[main][ref] psnr="stats_file=stats.log" [out]```
    - 在这个例子中，正在处理的输入文件与参考文件ref_movie.mpg进行比较。每个单独帧的PSNR值将存储在stats.log文件中。
    - 以下是另一个示例，使用不同的容器格式：  
    ```ffmpeg -i main.mpg -i ref.mkv -lavfi "[0:v]settb=AVTB,setpts=PTS-STARTPTS[main];[1:v]settb=AVTB,setpts=PTS-STARTPTS[ref];[main][ref]psnr" -f null -```
    - 假设你有两个视频文件，一个是原始视频文件，另一个是经过压缩处理的视频文件，可以使用该滤镜计算他们之间的平均psnr  
    ```ffmpeg -i original.mp4 -i compressed.mp4 -lavfi "psnr" -f null -```